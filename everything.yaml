apiVersion: v1
items:
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2025-12-14T19:27:54Z"
    generateName: clm-58888847cd-
    generation: 1
    labels:
      app: clm
      pod-template-hash: 58888847cd
    name: clm-58888847cd-8kg4d
    namespace: suite
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: clm-58888847cd
      uid: 3ced13b9-8b4a-43ae-98e3-b04d420f2190
    resourceVersion: "61875472"
    uid: 7a4d87ac-203b-44c3-ba83-b89ff113496f
  spec:
    containers:
    - image: allenwayne/clm
      imagePullPolicy: Always
      name: clm-clean
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-8cd2f
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    imagePullSecrets:
    - name: ghcr-allenwayne
    nodeName: w2
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-8cd2f
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-12-27T12:46:59Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-12-14T19:27:55Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2026-01-01T15:02:59Z"
      message: 'containers with unready status: [clm-clean]'
      reason: ContainersNotReady
      status: "False"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2026-01-01T15:02:59Z"
      message: 'containers with unready status: [clm-clean]'
      reason: ContainersNotReady
      status: "False"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-12-14T19:27:54Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://7d40c4bfd232a535d6cb23405c7ad7db7c334277eb2e0c80c856eefd378eda02
      image: docker.io/allenwayne/clm:latest
      imageID: docker.io/allenwayne/clm@sha256:f58198fd25384686cdda6ba88482e02176b58b1b17f793ad6dc4ff8f4ca2f570
      lastState:
        terminated:
          containerID: containerd://7d40c4bfd232a535d6cb23405c7ad7db7c334277eb2e0c80c856eefd378eda02
          exitCode: 255
          finishedAt: "2026-01-01T15:33:51Z"
          reason: Error
          startedAt: "2026-01-01T15:33:51Z"
      name: clm-clean
      ready: false
      resources: {}
      restartCount: 5044
      started: false
      state:
        waiting:
          message: back-off 5m0s restarting failed container=clm-clean pod=clm-58888847cd-8kg4d_suite(7a4d87ac-203b-44c3-ba83-b89ff113496f)
          reason: CrashLoopBackOff
      user:
        linux:
          gid: 0
          supplementalGroups:
          - 0
          - 1
          - 2
          - 3
          - 4
          - 6
          - 10
          - 11
          - 20
          - 26
          - 27
          uid: 0
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-8cd2f
        readOnly: true
        recursiveReadOnly: Disabled
    hostIP: 192.168.50.4
    hostIPs:
    - ip: 192.168.50.4
    phase: Running
    podIP: 10.42.4.135
    podIPs:
    - ip: 10.42.4.135
    qosClass: BestEffort
    startTime: "2025-12-14T19:27:55Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubectl.kubernetes.io/restartedAt: "2025-11-22T14:22:52-06:00"
    creationTimestamp: "2025-12-27T13:32:26Z"
    generateName: homebridge-7b5b8cdf94-
    generation: 1
    labels:
      app: homebridge
      pod-template-hash: 7b5b8cdf94
    name: homebridge-7b5b8cdf94-v5b9d
    namespace: suite
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: homebridge-7b5b8cdf94
      uid: edd9bb2c-2cd8-49c4-a40b-5a9d5558d4fe
    resourceVersion: "58635262"
    uid: 7c210124-8e76-4821-883a-c229163a4c59
  spec:
    containers:
    - env:
      - name: TZ
        value: America/Chicago
      - name: HOMEBRIDGE_CONFIG_UI
        value: "1"
      - name: HOMEBRIDGE_CONFIG_UI_PORT
        value: "8581"
      - name: HOMEBRIDGE_CONFIG_UI_HOST
        value: 0.0.0.0
      - name: HOMEBRIDGE_DISABLE_IPV6
        value: "1"
      - name: NODE_OPTIONS
        value: --dns-result-order=ipv4first
      - name: HOMEBRIDGE_ADVERTISER
        value: ciao
      - name: HOMEBRIDGE_MDNS_INTERFACE
        value: eth0
      - name: HOMEBRIDGE_ENABLE_IPV6
        value: "0"
      image: homebridge/homebridge:latest
      imagePullPolicy: Always
      name: homebridge
      ports:
      - containerPort: 8581
        hostPort: 8581
        name: ui
        protocol: TCP
      - containerPort: 51443
        hostPort: 51443
        name: hap
        protocol: TCP
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /homebridge
        name: data
      - mountPath: /etc/avahi/avahi-daemon.conf
        name: avahi-config
        subPath: avahi-daemon.conf
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-5kbs9
        readOnly: true
    dnsConfig:
      nameservers:
      - 1.1.1.1
      - 8.8.8.8
    dnsPolicy: ClusterFirstWithHostNet
    enableServiceLinks: true
    hostNetwork: true
    imagePullSecrets:
    - name: ghcr-allenwayne
    nodeName: w0
    nodeSelector:
      homekit: bridge
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - configMap:
        defaultMode: 420
        name: homebridge-avahi
      name: avahi-config
    - name: data
      persistentVolumeClaim:
        claimName: homebridge-data-longhorn
    - name: kube-api-access-5kbs9
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-12-27T13:33:27Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-12-27T13:32:26Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-12-27T13:33:27Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-12-27T13:33:27Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-12-27T13:32:26Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://b871c6fda9da6b02765fefadf4e1d2bdda47b05a1e0acc67c85ec534e3be5a16
      image: docker.io/homebridge/homebridge:latest
      imageID: docker.io/homebridge/homebridge@sha256:ac49b1ae860468c2fa3cba6a7e543beb1ab93bf0f6eb620bfb736895a9430018
      lastState: {}
      name: homebridge
      ready: true
      resources: {}
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-12-27T13:33:27Z"
      user:
        linux:
          gid: 0
          supplementalGroups:
          - 0
          uid: 0
      volumeMounts:
      - mountPath: /homebridge
        name: data
      - mountPath: /etc/avahi/avahi-daemon.conf
        name: avahi-config
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-5kbs9
        readOnly: true
        recursiveReadOnly: Disabled
    hostIP: 192.168.50.9
    hostIPs:
    - ip: 192.168.50.9
    phase: Running
    podIP: 192.168.50.9
    podIPs:
    - ip: 192.168.50.9
    qosClass: BestEffort
    startTime: "2025-12-27T13:32:26Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2025-12-26T10:00:00Z"
    finalizers:
    - batch.kubernetes.io/job-tracking
    generateName: homebridge-backup-prune-29445720-
    generation: 1
    labels:
      batch.kubernetes.io/controller-uid: 8c14086f-168a-4f6b-9e75-b8c785fa5370
      batch.kubernetes.io/job-name: homebridge-backup-prune-29445720
      controller-uid: 8c14086f-168a-4f6b-9e75-b8c785fa5370
      job-name: homebridge-backup-prune-29445720
    name: homebridge-backup-prune-29445720-xphrg
    namespace: suite
    ownerReferences:
    - apiVersion: batch/v1
      blockOwnerDeletion: true
      controller: true
      kind: Job
      name: homebridge-backup-prune-29445720
      uid: 8c14086f-168a-4f6b-9e75-b8c785fa5370
    resourceVersion: "58029945"
    uid: 233c7c66-91c8-4e15-9da5-65f853fd5053
  spec:
    containers:
    - args:
      - |
        set -eux
        cd /backups

        echo "=== BEFORE ==="
        ls -lh
        df -h .

        echo
        echo "=== Deleting files older than 60 days ==="
        # Adjust the -mtime value if you want a different window
        find . -maxdepth 1 -type f -name 'homebridge*.tgz' -mtime +60 -print -delete || true

        echo
        echo "=== AFTER ==="
        ls -lh
        df -h .
      command:
      - /bin/sh
      - -lc
      image: alpine:3.20
      imagePullPolicy: IfNotPresent
      name: prune
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /backups
        name: bkp
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-s9l9h
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    imagePullSecrets:
    - name: ghcr-allenwayne
    nodeName: w7
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: OnFailure
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: bkp
      persistentVolumeClaim:
        claimName: homebridge-backups-longhorn
    - name: kube-api-access-s9l9h
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-12-26T10:00:00Z"
      status: "False"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-12-26T10:00:00Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-12-26T10:00:00Z"
      message: 'containers with unready status: [prune]'
      reason: ContainersNotReady
      status: "False"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-12-26T10:00:00Z"
      message: 'containers with unready status: [prune]'
      reason: ContainersNotReady
      status: "False"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-12-26T10:00:00Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - image: alpine:3.20
      imageID: ""
      lastState: {}
      name: prune
      ready: false
      restartCount: 0
      started: false
      state:
        waiting:
          reason: ContainerCreating
      volumeMounts:
      - mountPath: /backups
        name: bkp
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-s9l9h
        readOnly: true
        recursiveReadOnly: Disabled
    hostIP: 192.168.50.126
    hostIPs:
    - ip: 192.168.50.126
    phase: Pending
    qosClass: BestEffort
    startTime: "2025-12-26T10:00:00Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2025-12-27T10:00:00Z"
    finalizers:
    - batch.kubernetes.io/job-tracking
    generateName: homebridge-backup-prune-29447160-
    generation: 1
    labels:
      batch.kubernetes.io/controller-uid: c59f3bb9-4959-4288-a9ea-f0a832a4091c
      batch.kubernetes.io/job-name: homebridge-backup-prune-29447160
      controller-uid: c59f3bb9-4959-4288-a9ea-f0a832a4091c
      job-name: homebridge-backup-prune-29447160
    name: homebridge-backup-prune-29447160-d2xqf
    namespace: suite
    ownerReferences:
    - apiVersion: batch/v1
      blockOwnerDeletion: true
      controller: true
      kind: Job
      name: homebridge-backup-prune-29447160
      uid: c59f3bb9-4959-4288-a9ea-f0a832a4091c
    resourceVersion: "58567901"
    uid: 4551b093-ddeb-480f-a4fe-4d734df12546
  spec:
    containers:
    - args:
      - |
        set -eux
        cd /backups

        echo "=== BEFORE ==="
        ls -lh
        df -h .

        echo
        echo "=== Deleting files older than 60 days ==="
        # Adjust the -mtime value if you want a different window
        find . -maxdepth 1 -type f -name 'homebridge*.tgz' -mtime +60 -print -delete || true

        echo
        echo "=== AFTER ==="
        ls -lh
        df -h .
      command:
      - /bin/sh
      - -lc
      image: alpine:3.20
      imagePullPolicy: IfNotPresent
      name: prune
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /backups
        name: bkp
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-vvhqp
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    imagePullSecrets:
    - name: ghcr-allenwayne
    nodeName: w7
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: OnFailure
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: bkp
      persistentVolumeClaim:
        claimName: homebridge-backups-longhorn
    - name: kube-api-access-vvhqp
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-12-27T10:00:00Z"
      status: "False"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-12-27T10:00:00Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-12-27T10:00:00Z"
      message: 'containers with unready status: [prune]'
      reason: ContainersNotReady
      status: "False"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-12-27T10:00:00Z"
      message: 'containers with unready status: [prune]'
      reason: ContainersNotReady
      status: "False"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-12-27T10:00:00Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - image: alpine:3.20
      imageID: ""
      lastState: {}
      name: prune
      ready: false
      restartCount: 0
      started: false
      state:
        waiting:
          reason: ContainerCreating
      volumeMounts:
      - mountPath: /backups
        name: bkp
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-vvhqp
        readOnly: true
        recursiveReadOnly: Disabled
    hostIP: 192.168.50.126
    hostIPs:
    - ip: 192.168.50.126
    phase: Pending
    qosClass: BestEffort
    startTime: "2025-12-27T10:00:00Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2025-12-29T10:00:00Z"
    generateName: homebridge-backup-prune-29450040-
    generation: 1
    labels:
      batch.kubernetes.io/controller-uid: 7966e16a-444b-440a-87c4-23de8e00a31f
      batch.kubernetes.io/job-name: homebridge-backup-prune-29450040
      controller-uid: 7966e16a-444b-440a-87c4-23de8e00a31f
      job-name: homebridge-backup-prune-29450040
    name: homebridge-backup-prune-29450040-22vn8
    namespace: suite
    ownerReferences:
    - apiVersion: batch/v1
      blockOwnerDeletion: true
      controller: true
      kind: Job
      name: homebridge-backup-prune-29450040
      uid: 7966e16a-444b-440a-87c4-23de8e00a31f
    resourceVersion: "59813033"
    uid: 9b47577c-fe2c-4730-b3b7-4cf96d8a3a25
  spec:
    containers:
    - args:
      - |
        set -eux
        cd /backups

        echo "=== BEFORE ==="
        ls -lh
        df -h .

        echo
        echo "=== Deleting files older than 60 days ==="
        # Adjust the -mtime value if you want a different window
        find . -maxdepth 1 -type f -name 'homebridge*.tgz' -mtime +60 -print -delete || true

        echo
        echo "=== AFTER ==="
        ls -lh
        df -h .
      command:
      - /bin/sh
      - -lc
      image: alpine:3.20
      imagePullPolicy: IfNotPresent
      name: prune
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /backups
        name: bkp
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-wjzfk
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    imagePullSecrets:
    - name: ghcr-allenwayne
    nodeName: m2
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: OnFailure
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: bkp
      persistentVolumeClaim:
        claimName: homebridge-backups-longhorn
    - name: kube-api-access-wjzfk
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-12-29T10:17:48Z"
      status: "False"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-12-29T10:00:00Z"
      reason: PodCompleted
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-12-29T10:00:00Z"
      reason: PodCompleted
      status: "False"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-12-29T10:00:00Z"
      reason: PodCompleted
      status: "False"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-12-29T10:00:00Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://fbe70d3ee898137f960361fd69347df88ee5994f944d7a5382da9e0987b4f87b
      image: docker.io/library/alpine:3.20
      imageID: docker.io/library/alpine@sha256:b3119ef930faabb6b7b976780c0c7a9c1aa24d0c75e9179ac10e6bc9ac080d0d
      lastState: {}
      name: prune
      ready: false
      resources: {}
      restartCount: 0
      started: false
      state:
        terminated:
          containerID: containerd://fbe70d3ee898137f960361fd69347df88ee5994f944d7a5382da9e0987b4f87b
          exitCode: 0
          finishedAt: "2025-12-29T10:17:47Z"
          reason: Completed
          startedAt: "2025-12-29T10:17:47Z"
      user:
        linux:
          gid: 0
          supplementalGroups:
          - 0
          - 1
          - 2
          - 3
          - 4
          - 6
          - 10
          - 11
          - 20
          - 26
          - 27
          uid: 0
      volumeMounts:
      - mountPath: /backups
        name: bkp
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-wjzfk
        readOnly: true
        recursiveReadOnly: Disabled
    hostIP: 192.168.50.6
    hostIPs:
    - ip: 192.168.50.6
    phase: Succeeded
    podIP: 10.42.0.197
    podIPs:
    - ip: 10.42.0.197
    qosClass: BestEffort
    startTime: "2025-12-29T10:00:00Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2025-12-30T10:00:00Z"
    generateName: homebridge-backup-prune-29451480-
    generation: 1
    labels:
      batch.kubernetes.io/controller-uid: 5653478b-9605-42a7-8984-2957c5016b93
      batch.kubernetes.io/job-name: homebridge-backup-prune-29451480
      controller-uid: 5653478b-9605-42a7-8984-2957c5016b93
      job-name: homebridge-backup-prune-29451480
    name: homebridge-backup-prune-29451480-mkrvj
    namespace: suite
    ownerReferences:
    - apiVersion: batch/v1
      blockOwnerDeletion: true
      controller: true
      kind: Job
      name: homebridge-backup-prune-29451480
      uid: 5653478b-9605-42a7-8984-2957c5016b93
    resourceVersion: "60449583"
    uid: c62443d4-1849-4220-a364-a597e6dc7671
  spec:
    containers:
    - args:
      - |
        set -eux
        cd /backups

        echo "=== BEFORE ==="
        ls -lh
        df -h .

        echo
        echo "=== Deleting files older than 60 days ==="
        # Adjust the -mtime value if you want a different window
        find . -maxdepth 1 -type f -name 'homebridge*.tgz' -mtime +60 -print -delete || true

        echo
        echo "=== AFTER ==="
        ls -lh
        df -h .
      command:
      - /bin/sh
      - -lc
      image: alpine:3.20
      imagePullPolicy: IfNotPresent
      name: prune
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /backups
        name: bkp
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-tb48x
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    imagePullSecrets:
    - name: ghcr-allenwayne
    nodeName: m2
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: OnFailure
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: bkp
      persistentVolumeClaim:
        claimName: homebridge-backups-longhorn
    - name: kube-api-access-tb48x
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-12-30T10:00:18Z"
      status: "False"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-12-30T10:00:00Z"
      reason: PodCompleted
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-12-30T10:00:00Z"
      reason: PodCompleted
      status: "False"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-12-30T10:00:00Z"
      reason: PodCompleted
      status: "False"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-12-30T10:00:00Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://33f3a91cd0a9b3d3b2ef3f70d3c01655504cc19ab435b5022ce5dd7fe696a87c
      image: docker.io/library/alpine:3.20
      imageID: docker.io/library/alpine@sha256:b3119ef930faabb6b7b976780c0c7a9c1aa24d0c75e9179ac10e6bc9ac080d0d
      lastState: {}
      name: prune
      ready: false
      resources: {}
      restartCount: 0
      started: false
      state:
        terminated:
          containerID: containerd://33f3a91cd0a9b3d3b2ef3f70d3c01655504cc19ab435b5022ce5dd7fe696a87c
          exitCode: 0
          finishedAt: "2025-12-30T10:00:17Z"
          reason: Completed
          startedAt: "2025-12-30T10:00:17Z"
      user:
        linux:
          gid: 0
          supplementalGroups:
          - 0
          - 1
          - 2
          - 3
          - 4
          - 6
          - 10
          - 11
          - 20
          - 26
          - 27
          uid: 0
      volumeMounts:
      - mountPath: /backups
        name: bkp
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-tb48x
        readOnly: true
        recursiveReadOnly: Disabled
    hostIP: 192.168.50.6
    hostIPs:
    - ip: 192.168.50.6
    phase: Succeeded
    podIP: 10.42.0.201
    podIPs:
    - ip: 10.42.0.201
    qosClass: BestEffort
    startTime: "2025-12-30T10:00:00Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2026-01-01T10:00:00Z"
    generateName: homebridge-backup-prune-29454360-
    generation: 1
    labels:
      batch.kubernetes.io/controller-uid: fff3c811-f843-4ce6-921b-910dc6c37555
      batch.kubernetes.io/job-name: homebridge-backup-prune-29454360
      controller-uid: fff3c811-f843-4ce6-921b-910dc6c37555
      job-name: homebridge-backup-prune-29454360
    name: homebridge-backup-prune-29454360-tdpt9
    namespace: suite
    ownerReferences:
    - apiVersion: batch/v1
      blockOwnerDeletion: true
      controller: true
      kind: Job
      name: homebridge-backup-prune-29454360
      uid: fff3c811-f843-4ce6-921b-910dc6c37555
    resourceVersion: "61728367"
    uid: 67d0ca8c-a7f2-4847-a5c1-804981d20bc0
  spec:
    containers:
    - args:
      - |
        set -eux
        cd /backups

        echo "=== BEFORE ==="
        ls -lh
        df -h .

        echo
        echo "=== Deleting files older than 60 days ==="
        # Adjust the -mtime value if you want a different window
        find . -maxdepth 1 -type f -name 'homebridge*.tgz' -mtime +60 -print -delete || true

        echo
        echo "=== AFTER ==="
        ls -lh
        df -h .
      command:
      - /bin/sh
      - -lc
      image: alpine:3.20
      imagePullPolicy: IfNotPresent
      name: prune
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /backups
        name: bkp
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-cpftj
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    imagePullSecrets:
    - name: ghcr-allenwayne
    nodeName: m2
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: OnFailure
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: bkp
      persistentVolumeClaim:
        claimName: homebridge-backups-longhorn
    - name: kube-api-access-cpftj
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2026-01-01T10:01:35Z"
      status: "False"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2026-01-01T10:00:00Z"
      reason: PodCompleted
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2026-01-01T10:00:00Z"
      reason: PodCompleted
      status: "False"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2026-01-01T10:00:00Z"
      reason: PodCompleted
      status: "False"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2026-01-01T10:00:00Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://017a6a8eadd4197922b7ebd0dd63c05b956c618bf47b31f9221c42cd64a7c11a
      image: docker.io/library/alpine:3.20
      imageID: docker.io/library/alpine@sha256:b3119ef930faabb6b7b976780c0c7a9c1aa24d0c75e9179ac10e6bc9ac080d0d
      lastState: {}
      name: prune
      ready: false
      resources: {}
      restartCount: 0
      started: false
      state:
        terminated:
          containerID: containerd://017a6a8eadd4197922b7ebd0dd63c05b956c618bf47b31f9221c42cd64a7c11a
          exitCode: 0
          finishedAt: "2026-01-01T10:01:33Z"
          reason: Completed
          startedAt: "2026-01-01T10:01:33Z"
      user:
        linux:
          gid: 0
          supplementalGroups:
          - 0
          - 1
          - 2
          - 3
          - 4
          - 6
          - 10
          - 11
          - 20
          - 26
          - 27
          uid: 0
      volumeMounts:
      - mountPath: /backups
        name: bkp
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-cpftj
        readOnly: true
        recursiveReadOnly: Disabled
    hostIP: 192.168.50.6
    hostIPs:
    - ip: 192.168.50.6
    phase: Succeeded
    podIP: 10.42.0.218
    podIPs:
    - ip: 10.42.0.218
    qosClass: BestEffort
    startTime: "2026-01-01T10:00:00Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2025-12-27T13:31:53Z"
    generateName: jenkins-77ffddbfd-
    generation: 1
    labels:
      app: jenkins
      pod-template-hash: 77ffddbfd
    name: jenkins-77ffddbfd-ltvnn
    namespace: suite
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: jenkins-77ffddbfd
      uid: a73adc26-6bc5-415e-87c2-cb9310f1aee2
    resourceVersion: "58632882"
    uid: cdd1281e-2205-468d-9790-d030b2fee346
  spec:
    containers:
    - env:
      - name: JAVA_OPTS
        value: -Djenkins.install.runSetupWizard=false
      image: jenkins/jenkins:lts-jdk17
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /login
          port: 8080
          scheme: HTTP
        initialDelaySeconds: 60
        periodSeconds: 20
        successThreshold: 1
        timeoutSeconds: 1
      name: jenkins
      ports:
      - containerPort: 8080
        name: http
        protocol: TCP
      - containerPort: 50000
        name: agent
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /login
          port: 8080
          scheme: HTTP
        initialDelaySeconds: 30
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources:
        limits:
          cpu: "1"
          memory: 2Gi
        requests:
          cpu: 500m
          memory: 1Gi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/jenkins_home
        name: jenkins-home
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-ft8kp
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: w7
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 1000
    serviceAccount: jenkins
    serviceAccountName: jenkins
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: jenkins-home
      persistentVolumeClaim:
        claimName: jenkins-home
    - name: kube-api-access-ft8kp
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-12-27T12:47:58Z"
      status: "False"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-12-27T12:47:58Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-12-27T12:47:58Z"
      message: 'containers with unready status: [jenkins]'
      reason: ContainersNotReady
      status: "False"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-12-27T12:47:58Z"
      message: 'containers with unready status: [jenkins]'
      reason: ContainersNotReady
      status: "False"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-12-27T13:31:53Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - image: jenkins/jenkins:lts-jdk17
      imageID: ""
      lastState: {}
      name: jenkins
      ready: false
      restartCount: 0
      started: false
      state:
        waiting:
          reason: ContainerCreating
      volumeMounts:
      - mountPath: /var/jenkins_home
        name: jenkins-home
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-ft8kp
        readOnly: true
        recursiveReadOnly: Disabled
    hostIP: 192.168.50.126
    hostIPs:
    - ip: 192.168.50.126
    phase: Pending
    qosClass: Burstable
    startTime: "2025-12-27T12:47:58Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2025-12-27T13:32:47Z"
    generateName: magicmirror-app-79d76f44c-
    generation: 1
    labels:
      allow-egress: internet
      app: magicmirror-app
      pod-template-hash: 79d76f44c
    name: magicmirror-app-79d76f44c-5mm74
    namespace: suite
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: magicmirror-app-79d76f44c
      uid: bdd526ab-4682-4f98-83cf-37bc1778c495
    resourceVersion: "58635439"
    uid: 0f25c415-5a62-4b87-aafc-2bc5d46f216d
  spec:
    containers:
    - env:
      - name: MM_CONFIG_FILE
        value: /opt/magic_mirror/config/config.js
      - name: NODE_ENV
        value: production
      image: docker.io/bastilimbach/docker-magicmirror:latest
      imagePullPolicy: Always
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /
          port: http
          scheme: HTTP
        initialDelaySeconds: 25
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 2
      name: magicmirror
      ports:
      - containerPort: 8080
        name: http
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /
          port: http
          scheme: HTTP
        initialDelaySeconds: 12
        periodSeconds: 5
        successThreshold: 1
        timeoutSeconds: 2
      resources:
        limits:
          cpu: 800m
          memory: 512Mi
        requests:
          cpu: 200m
          memory: 256Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /opt/magic_mirror/config/config.js
        name: mm-config
        readOnly: true
        subPath: config.js
      - mountPath: /opt/magic_mirror/modules
        name: modules-work
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-84gt6
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    imagePullSecrets:
    - name: ghcr-allenwayne
    initContainers:
    - args:
      - |
        set -e
        # Start with image defaults
        cp -a /opt/magic_mirror/modules/. /work/
        mkdir -p /work/custom
        # Merge persisted customs (if any)
        cp -a /persist/. /work/custom/ 2>/dev/null || true
      command:
      - /bin/sh
      - -lc
      image: docker.io/bastilimbach/docker-magicmirror:latest
      imagePullPolicy: IfNotPresent
      name: seed-modules
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /work
        name: modules-work
      - mountPath: /persist
        name: mm-persist
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-84gt6
        readOnly: true
    nodeName: m3
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - configMap:
        defaultMode: 420
        name: magicmirror-config
      name: mm-config
    - name: mm-persist
      persistentVolumeClaim:
        claimName: mm-modules-pvc
    - emptyDir: {}
      name: modules-work
    - name: kube-api-access-84gt6
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-12-27T13:33:23Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-12-27T13:33:23Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-12-27T13:33:36Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-12-27T13:33:36Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-12-27T13:32:47Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - allocatedResources:
        cpu: 200m
        memory: 256Mi
      containerID: containerd://2a6f6fcf977569a02bb4691e9385a7c1b95441edeb21d5eb51d9b8840ad471b2
      image: docker.io/bastilimbach/docker-magicmirror:latest
      imageID: docker.io/bastilimbach/docker-magicmirror@sha256:41b0835ab31e93a72de92804d84f483be0861bb7771c36a1df2a742693fdfb4e
      lastState: {}
      name: magicmirror
      ready: true
      resources:
        limits:
          cpu: 800m
          memory: 512Mi
        requests:
          cpu: 200m
          memory: 256Mi
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-12-27T13:33:24Z"
      user:
        linux:
          gid: 0
          supplementalGroups:
          - 0
          uid: 0
      volumeMounts:
      - mountPath: /opt/magic_mirror/config/config.js
        name: mm-config
        readOnly: true
        recursiveReadOnly: Disabled
      - mountPath: /opt/magic_mirror/modules
        name: modules-work
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-84gt6
        readOnly: true
        recursiveReadOnly: Disabled
    hostIP: 192.168.50.3
    hostIPs:
    - ip: 192.168.50.3
    initContainerStatuses:
    - containerID: containerd://6b17f86617563d0ce75a83bfcda4e96b508be107c7dd50bafc42a8a809f67a55
      image: docker.io/bastilimbach/docker-magicmirror:latest
      imageID: docker.io/bastilimbach/docker-magicmirror@sha256:41b0835ab31e93a72de92804d84f483be0861bb7771c36a1df2a742693fdfb4e
      lastState: {}
      name: seed-modules
      ready: true
      resources: {}
      restartCount: 0
      started: false
      state:
        terminated:
          containerID: containerd://6b17f86617563d0ce75a83bfcda4e96b508be107c7dd50bafc42a8a809f67a55
          exitCode: 0
          finishedAt: "2025-12-27T13:33:22Z"
          reason: Completed
          startedAt: "2025-12-27T13:33:22Z"
      user:
        linux:
          gid: 0
          supplementalGroups:
          - 0
          uid: 0
      volumeMounts:
      - mountPath: /work
        name: modules-work
      - mountPath: /persist
        name: mm-persist
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-84gt6
        readOnly: true
        recursiveReadOnly: Disabled
    phase: Running
    podIP: 10.42.1.185
    podIPs:
    - ip: 10.42.1.185
    qosClass: Burstable
    startTime: "2025-12-27T13:32:47Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2025-12-14T19:27:55Z"
    generateName: magicmirror-server-5c8f999799-
    generation: 1
    labels:
      app: magicmirror-server
      pod-template-hash: 5c8f999799
    name: magicmirror-server-5c8f999799-swlbr
    namespace: suite
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: magicmirror-server-5c8f999799
      uid: f23dea4e-f548-4f64-b518-345a2db8546f
    resourceVersion: "58629424"
    uid: aa9fee4b-0671-4edd-bc8c-9a684d6d4a85
  spec:
    containers:
    - args:
      - npm run server
      command:
      - /bin/sh
      - -lc
      env:
      - name: TZ
        value: America/Chicago
      - name: OPENWEATHER_API_KEY
        valueFrom:
          secretKeyRef:
            key: API_KEY
            name: openweather
      image: docker.io/allenwayne/magicmirror-server:2.32
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /
          port: 8080
          scheme: HTTP
        initialDelaySeconds: 30
        periodSeconds: 20
        successThreshold: 1
        timeoutSeconds: 1
      name: magicmirror
      ports:
      - containerPort: 8080
        protocol: TCP
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /opt/magic_mirror/config/config.js
        name: mm-config
        subPath: config.js
      - mountPath: /opt/magic_mirror/modules
        name: mm-modules
      - mountPath: /opt/magic_mirror/public
        name: mm-public
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-dm24h
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    imagePullSecrets:
    - name: ghcr-allenwayne
    initContainers:
    - args:
      - |
        set -eux
        rm -rf /work/modules/* /work/public/* || true
        if [ -d /opt/magic_mirror/modules ]; then
          cp -a /opt/magic_mirror/modules/. /work/modules/
        fi
        if [ -d /opt/magic_mirror/public ]; then
          cp -a /opt/magic_mirror/public/. /work/public/
        fi
      command:
      - /bin/sh
      - -lc
      image: docker.io/allenwayne/magicmirror-server:2.32
      imagePullPolicy: IfNotPresent
      name: seed-modules
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /work/modules
        name: mm-modules
      - mountPath: /work/public
        name: mm-public
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-dm24h
        readOnly: true
    - args:
      - echo skipping git-modules; exit 0
      command:
      - /bin/sh
      - -lc
      image: alpine:3.20
      imagePullPolicy: IfNotPresent
      name: git-modules
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /work/modules
        name: mm-modules
      - mountPath: /work/public
        name: mm-public
      - mountPath: /extras
        name: mm-extras
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-dm24h
        readOnly: true
    nodeName: m3
    nodeSelector:
      kubernetes.io/hostname: m3
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - configMap:
        defaultMode: 420
        name: magicmirror-config
      name: mm-config
    - emptyDir: {}
      name: mm-modules
    - emptyDir: {}
      name: mm-public
    - configMap:
        defaultMode: 420
        name: magicmirror-extras
      name: mm-extras
    - name: kube-api-access-dm24h
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-12-27T12:45:12Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-12-14T19:31:53Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-12-27T12:45:14Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-12-27T12:45:14Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-12-14T19:31:46Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://32b0ba01d06a806575250d9667da331d6e6a194dc8a3d47e4017419624b1c9e5
      image: docker.io/allenwayne/magicmirror-server:2.32
      imageID: docker.io/allenwayne/magicmirror-server@sha256:93659cdae8d69e5ef103d9915d3a375acee3ff26241f34ed7ae2f5ba37ac9b12
      lastState:
        terminated:
          containerID: containerd://52ecae571b6a67f4079f9407ef9f47d773f426f14b4f65e05e595ae19c4ad3c2
          exitCode: 255
          finishedAt: "2025-12-27T12:44:47Z"
          reason: Unknown
          startedAt: "2025-12-14T19:31:53Z"
      name: magicmirror
      ready: true
      resources: {}
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2025-12-27T12:45:13Z"
      user:
        linux:
          gid: 0
          supplementalGroups:
          - 0
          uid: 0
      volumeMounts:
      - mountPath: /opt/magic_mirror/config/config.js
        name: mm-config
      - mountPath: /opt/magic_mirror/modules
        name: mm-modules
      - mountPath: /opt/magic_mirror/public
        name: mm-public
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-dm24h
        readOnly: true
        recursiveReadOnly: Disabled
    hostIP: 192.168.50.3
    hostIPs:
    - ip: 192.168.50.3
    initContainerStatuses:
    - containerID: containerd://26ae56e7c0b804f6110b7cac099347cf2b6ab2e7cc925f646f26c62d5af290e0
      image: docker.io/allenwayne/magicmirror-server:2.32
      imageID: docker.io/allenwayne/magicmirror-server@sha256:93659cdae8d69e5ef103d9915d3a375acee3ff26241f34ed7ae2f5ba37ac9b12
      lastState: {}
      name: seed-modules
      ready: true
      resources: {}
      restartCount: 1
      started: false
      state:
        terminated:
          containerID: containerd://26ae56e7c0b804f6110b7cac099347cf2b6ab2e7cc925f646f26c62d5af290e0
          exitCode: 0
          finishedAt: "2025-12-27T12:45:11Z"
          reason: Completed
          startedAt: "2025-12-27T12:45:11Z"
      user:
        linux:
          gid: 0
          supplementalGroups:
          - 0
          uid: 0
      volumeMounts:
      - mountPath: /work/modules
        name: mm-modules
      - mountPath: /work/public
        name: mm-public
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-dm24h
        readOnly: true
        recursiveReadOnly: Disabled
    - containerID: containerd://af6895b74e918af4a52140dcff58417fe5f4154dff08e4ee0c309460e30b72f8
      image: docker.io/library/alpine:3.20
      imageID: docker.io/library/alpine@sha256:b3119ef930faabb6b7b976780c0c7a9c1aa24d0c75e9179ac10e6bc9ac080d0d
      lastState: {}
      name: git-modules
      ready: true
      resources: {}
      restartCount: 0
      started: false
      state:
        terminated:
          containerID: containerd://af6895b74e918af4a52140dcff58417fe5f4154dff08e4ee0c309460e30b72f8
          exitCode: 0
          finishedAt: "2025-12-27T12:45:12Z"
          reason: Completed
          startedAt: "2025-12-27T12:45:12Z"
      user:
        linux:
          gid: 0
          supplementalGroups:
          - 0
          - 1
          - 2
          - 3
          - 4
          - 6
          - 10
          - 11
          - 20
          - 26
          - 27
          uid: 0
      volumeMounts:
      - mountPath: /work/modules
        name: mm-modules
      - mountPath: /work/public
        name: mm-public
      - mountPath: /extras
        name: mm-extras
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-dm24h
        readOnly: true
        recursiveReadOnly: Disabled
    phase: Running
    podIP: 10.42.1.180
    podIPs:
    - ip: 10.42.1.180
    qosClass: BestEffort
    startTime: "2025-12-14T19:31:48Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubectl.kubernetes.io/restartedAt: "2025-12-10T09:43:15-06:00"
    creationTimestamp: "2025-12-27T13:32:06Z"
    generateName: pihole-7cbbb589c4-
    generation: 1
    labels:
      app: pihole
      pod-template-hash: 7cbbb589c4
    name: pihole-7cbbb589c4-9cch4
    namespace: suite
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: pihole-7cbbb589c4
      uid: afb6b86c-7341-413a-8a65-d8fb7e425e55
    resourceVersion: "58633144"
    uid: ee95404c-9805-4c7e-8a5f-a2db2f0d5f32
  spec:
    containers:
    - env:
      - name: DNSMASQ_LISTENING
        value: all
      - name: ServerIP
        value: 192.168.50.245
      - name: WEB_PORT
        value: "80"
      - name: PIHOLE_DNS_1
        value: 1.1.1.1
      - name: PIHOLE_DNS_2
        value: 9.9.9.9
      - name: DNSSEC
        value: "false"
      - name: TZ
        value: America/Chicago
      image: pihole/pihole:latest
      imagePullPolicy: Always
      name: pihole
      ports:
      - containerPort: 53
        name: dns-udp
        protocol: UDP
      - containerPort: 53
        name: dns-tcp
        protocol: TCP
      - containerPort: 80
        name: http
        protocol: TCP
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/dnsmasq.d
        name: etc-dnsmasq
      - mountPath: /etc/dnsmasq.d/01-ui-host.conf
        name: ui-override
        subPath: 01-ui-host.conf
      - mountPath: /etc/dnsmasq.d/02-suite-home-arpa.conf
        name: dnsmasq-cm
        subPath: 02-suite-home-arpa.conf
      - mountPath: /etc/dnsmasq.d/03-custom.conf
        name: dnsmasq-custom
        subPath: 03-custom.conf
      - mountPath: /etc/pihole
        name: etc-pihole
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-294fq
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    imagePullSecrets:
    - name: ghcr-allenwayne
    nodeName: m2
    nodeSelector:
      kubernetes.io/arch: arm64
      kubernetes.io/hostname: m2
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: etc-pihole
      persistentVolumeClaim:
        claimName: pihole-etc-pihole-pvc-longhorn
    - name: etc-dnsmasq
      persistentVolumeClaim:
        claimName: pihole-dnsmasq-pvc-longhorn
    - configMap:
        defaultMode: 420
        name: pihole-dnsmasq
      name: dnsmasq-cm
    - configMap:
        defaultMode: 420
        name: pihole-ui-override
      name: ui-override
    - configMap:
        defaultMode: 420
        name: pihole-dnsmasq-custom
      name: dnsmasq-custom
    - name: kube-api-access-294fq
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-12-27T13:32:08Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-12-27T13:32:06Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-12-27T13:32:08Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-12-27T13:32:08Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-12-27T13:32:06Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://6ad648f68c88ff0475387ed3e5fede184bb9e563ac7ee04cff8bcbab57e779a0
      image: docker.io/pihole/pihole:latest
      imageID: docker.io/pihole/pihole@sha256:91dc91ddd413bf461c283204558f8f21839851e9824799075a7ceff7c77eea40
      lastState: {}
      name: pihole
      ready: true
      resources: {}
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-12-27T13:32:07Z"
      user:
        linux:
          gid: 0
          supplementalGroups:
          - 0
          - 1
          - 2
          - 3
          - 4
          - 6
          - 10
          - 11
          - 20
          - 26
          - 27
          uid: 0
      volumeMounts:
      - mountPath: /etc/dnsmasq.d
        name: etc-dnsmasq
      - mountPath: /etc/dnsmasq.d/01-ui-host.conf
        name: ui-override
      - mountPath: /etc/dnsmasq.d/02-suite-home-arpa.conf
        name: dnsmasq-cm
      - mountPath: /etc/dnsmasq.d/03-custom.conf
        name: dnsmasq-custom
      - mountPath: /etc/pihole
        name: etc-pihole
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-294fq
        readOnly: true
        recursiveReadOnly: Disabled
    hostIP: 192.168.50.6
    hostIPs:
    - ip: 192.168.50.6
    phase: Running
    podIP: 10.42.0.186
    podIPs:
    - ip: 10.42.0.186
    qosClass: BestEffort
    startTime: "2025-12-27T13:32:06Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubectl.kubernetes.io/restartedAt: "2025-12-29T11:07:10-06:00"
    creationTimestamp: "2025-12-29T17:07:07Z"
    generateName: suite-command-center-api-7455994f75-
    generation: 1
    labels:
      app: suite-command-center-api
      pod-template-hash: 7455994f75
    name: suite-command-center-api-7455994f75-q2znj
    namespace: suite
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: suite-command-center-api-7455994f75
      uid: c6dd0ff0-318b-40dd-a166-ec35e6a7110a
    resourceVersion: "59996578"
    uid: 366a9462-74c9-499d-9939-ac3fd217f7d9
  spec:
    automountServiceAccountToken: true
    containers:
    - env:
      - name: NO_PROXY
        value: 127.0.0.1,localhost,192.168.50.251,192.168.50.2,192.168.50.3,192.168.50.6,10.0.0.0/8,10.42.0.0/16,10.43.0.0/16,.svc,.svc.cluster.local,.cluster.local
      - name: PORT
        value: "8000"
      image: registry.suite.home.arpa:5000/suite-command-center-api:latest
      imagePullPolicy: Always
      name: api
      ports:
      - containerPort: 8000
        protocol: TCP
      resources: {}
      startupProbe:
        failureThreshold: 60
        httpGet:
          path: /healthz
          port: 8000
          scheme: HTTP
        periodSeconds: 2
        successThreshold: 1
        timeoutSeconds: 2
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-xfr5t
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: m1
    nodeSelector:
      kubernetes.io/hostname: m1
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: suite-command-center-api
    serviceAccountName: suite-command-center-api
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-xfr5t
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-12-29T17:07:08Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-12-29T17:07:07Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-12-29T17:07:12Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-12-29T17:07:12Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-12-29T17:07:07Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://3752fc13752290c52a2ab1ac51e4905462461d5e139d3c912b802b7d10dd456d
      image: registry.suite.home.arpa:5000/suite-command-center-api:latest
      imageID: registry.suite.home.arpa:5000/suite-command-center-api@sha256:dc7a0fb55bc9d747fab07121c24ffd73f1ea2b58ce4bd6329f53d9326b8bdd74
      lastState: {}
      name: api
      ready: true
      resources: {}
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-12-29T17:07:08Z"
      user:
        linux:
          gid: 0
          supplementalGroups:
          - 0
          uid: 0
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-xfr5t
        readOnly: true
        recursiveReadOnly: Disabled
    hostIP: 192.168.50.2
    hostIPs:
    - ip: 192.168.50.2
    phase: Running
    podIP: 10.42.2.135
    podIPs:
    - ip: 10.42.2.135
    qosClass: BestEffort
    startTime: "2025-12-29T17:07:07Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubectl.kubernetes.io/restartedAt: "2025-12-31T19:35:38-06:00"
    creationTimestamp: "2026-01-01T01:35:38Z"
    generateName: suite-command-center-api-shim-68795c87d9-
    generation: 1
    labels:
      app: suite-command-center-api-shim
      pod-template-hash: 68795c87d9
    name: suite-command-center-api-shim-68795c87d9-2t69k
    namespace: suite
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: suite-command-center-api-shim-68795c87d9
      uid: 1c6fafb8-2446-484b-9d21-51d7bc23dbfa
    resourceVersion: "61876750"
    uid: 886aad67-c14e-474e-b19f-a2f91e5dddd4
  spec:
    containers:
    - command:
      - python
      - /app/server.py
      env:
      - name: PORT
        value: "8000"
      - name: APP_NAME
        value: suite-command-center-api-shim
      image: python:3.12-slim
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /healthz
          port: 8000
          scheme: HTTP
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      name: api
      ports:
      - containerPort: 8000
        name: http
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /healthz
          port: 8000
          scheme: HTTP
        initialDelaySeconds: 2
        periodSeconds: 5
        successThreshold: 1
        timeoutSeconds: 1
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /app
        name: code
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-j6h9t
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: m2
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: suite-command-center-api-shim
    serviceAccountName: suite-command-center-api-shim
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - configMap:
        defaultMode: 420
        name: suite-command-center-api-shim
      name: code
    - name: kube-api-access-j6h9t
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2026-01-01T01:35:38Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2026-01-01T01:35:38Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2026-01-01T15:36:51Z"
      message: 'containers with unready status: [api]'
      reason: ContainersNotReady
      status: "False"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2026-01-01T15:36:51Z"
      message: 'containers with unready status: [api]'
      reason: ContainersNotReady
      status: "False"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2026-01-01T01:35:38Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://9398d1c337d49013d8eb62c56edf5bce57d9a9b1528bba9e9f6cf4e9d9994a5a
      image: docker.io/library/python:3.12-slim
      imageID: docker.io/library/python@sha256:abc799c7ee22b0d66f46c367643088a35e048bbabd81212d73c2323aed38c64f
      lastState:
        terminated:
          containerID: containerd://af6bb89f9f80ffd1fed12c7d39e0f7887139f47690e2ec4a5364b5e589ab4e19
          exitCode: 137
          finishedAt: "2026-01-01T15:34:29Z"
          reason: Error
          startedAt: "2026-01-01T15:33:19Z"
      name: api
      ready: false
      resources: {}
      restartCount: 7
      started: true
      state:
        running:
          startedAt: "2026-01-01T15:34:29Z"
      user:
        linux:
          gid: 0
          supplementalGroups:
          - 0
          uid: 0
      volumeMounts:
      - mountPath: /app
        name: code
        readOnly: true
        recursiveReadOnly: Disabled
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-j6h9t
        readOnly: true
        recursiveReadOnly: Disabled
    hostIP: 192.168.50.6
    hostIPs:
    - ip: 192.168.50.6
    phase: Running
    podIP: 10.42.0.216
    podIPs:
    - ip: 10.42.0.216
    qosClass: BestEffort
    startTime: "2026-01-01T01:35:38Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubectl.kubernetes.io/restartedAt: "2025-12-31T19:35:38-06:00"
    creationTimestamp: "2026-01-01T02:07:35Z"
    generateName: suite-command-center-api-shim-68795c87d9-
    generation: 1
    labels:
      app: suite-command-center-api-shim
      pod-template-hash: 68795c87d9
    name: suite-command-center-api-shim-68795c87d9-m7829
    namespace: suite
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: suite-command-center-api-shim-68795c87d9
      uid: 1c6fafb8-2446-484b-9d21-51d7bc23dbfa
    resourceVersion: "61876643"
    uid: 200ea101-d630-4d70-990e-608c0523db38
  spec:
    containers:
    - command:
      - python
      - /app/server.py
      env:
      - name: PORT
        value: "8000"
      - name: APP_NAME
        value: suite-command-center-api-shim
      image: python:3.12-slim
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /healthz
          port: 8000
          scheme: HTTP
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      name: api
      ports:
      - containerPort: 8000
        name: http
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /healthz
          port: 8000
          scheme: HTTP
        initialDelaySeconds: 2
        periodSeconds: 5
        successThreshold: 1
        timeoutSeconds: 1
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /app
        name: code
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-224hd
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: w7
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: suite-command-center-api-shim
    serviceAccountName: suite-command-center-api-shim
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - configMap:
        defaultMode: 420
        name: suite-command-center-api-shim
      name: code
    - name: kube-api-access-224hd
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2026-01-01T02:07:36Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2026-01-01T02:07:35Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2026-01-01T15:35:44Z"
      message: 'containers with unready status: [api]'
      reason: ContainersNotReady
      status: "False"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2026-01-01T15:35:44Z"
      message: 'containers with unready status: [api]'
      reason: ContainersNotReady
      status: "False"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2026-01-01T02:07:35Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://67860f4dd74d37b6e222577a464f02966b65f7e59262816271b5ec34f636c788
      image: docker.io/library/python:3.12-slim
      imageID: docker.io/library/python@sha256:8fbd0afc32e6cb14696c2fc47fadcda4c04ca0e766782343464bd716a6dc3f96
      lastState:
        terminated:
          containerID: containerd://67860f4dd74d37b6e222577a464f02966b65f7e59262816271b5ec34f636c788
          exitCode: 137
          finishedAt: "2026-01-01T15:36:36Z"
          reason: Error
          startedAt: "2026-01-01T15:35:26Z"
      name: api
      ready: false
      resources: {}
      restartCount: 7
      started: false
      state:
        waiting:
          message: back-off 5m0s restarting failed container=api pod=suite-command-center-api-shim-68795c87d9-m7829_suite(200ea101-d630-4d70-990e-608c0523db38)
          reason: CrashLoopBackOff
      user:
        linux:
          gid: 0
          supplementalGroups:
          - 0
          uid: 0
      volumeMounts:
      - mountPath: /app
        name: code
        readOnly: true
        recursiveReadOnly: Disabled
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-224hd
        readOnly: true
        recursiveReadOnly: Disabled
    hostIP: 192.168.50.126
    hostIPs:
    - ip: 192.168.50.126
    phase: Running
    podIP: 10.42.5.164
    podIPs:
    - ip: 10.42.5.164
    qosClass: BestEffort
    startTime: "2026-01-01T02:07:35Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubectl.kubernetes.io/restartedAt: "2025-12-27T10:05:49-06:00"
    creationTimestamp: "2025-12-27T22:42:11Z"
    generateName: suite-command-center-ui-6c856bb4f8-
    generation: 1
    labels:
      app: suite-command-center-ui
      pod-template-hash: 6c856bb4f8
    name: suite-command-center-ui-6c856bb4f8-wc8vj
    namespace: suite
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: suite-command-center-ui-6c856bb4f8
      uid: 61a25626-fbc6-4328-b762-3d05fc89d7f9
    resourceVersion: "58857657"
    uid: 6d59426f-6bee-4ddb-a04f-2d8a75bb3f2f
  spec:
    containers:
    - image: registry.suite.home.arpa:5000/suite-command-center-ui:latest
      imagePullPolicy: Always
      name: ui
      ports:
      - containerPort: 80
        protocol: TCP
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-9p2rw
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    imagePullSecrets:
    - name: ghcr-allenwayne
    nodeName: m3
    nodeSelector:
      suite.home.arpa/display: "true"
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-9p2rw
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-12-27T22:42:13Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-12-27T22:42:11Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-12-27T22:42:13Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-12-27T22:42:13Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-12-27T22:42:11Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://33750ee2f0a74513ad1bfb986d7d286ca90f373a3cba5015d1374e09eea20ebc
      image: 192.168.50.248:5000/suite-command-center-ui:latest
      imageID: 192.168.50.248:5000/suite-command-center-ui@sha256:0ed8d6f49ed77820b5100fe64470e2474d6e787ebea3cdeddbc99011d9dbf7e2
      lastState: {}
      name: ui
      ready: true
      resources: {}
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-12-27T22:42:12Z"
      user:
        linux:
          gid: 0
          supplementalGroups:
          - 0
          - 1
          - 2
          - 3
          - 4
          - 6
          - 10
          - 11
          - 20
          - 26
          - 27
          uid: 0
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-9p2rw
        readOnly: true
        recursiveReadOnly: Disabled
    hostIP: 192.168.50.3
    hostIPs:
    - ip: 192.168.50.3
    phase: Running
    podIP: 10.42.1.189
    podIPs:
    - ip: 10.42.1.189
    qosClass: BestEffort
    startTime: "2025-12-27T22:42:11Z"
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"Service","metadata":{"annotations":{},"labels":{"app":"camera-esp32-relay"},"name":"camera-esp32-relay-public","namespace":"suite"},"spec":{"ports":[{"name":"rtsp","port":8554,"targetPort":"rtsp"},{"name":"hls","port":8888,"targetPort":"hls"},{"name":"webrtc","port":8889,"targetPort":"webrtc"}],"selector":{"app":"camera-esp32-relay"},"type":"LoadBalancer"}}
    creationTimestamp: "2025-09-19T14:23:21Z"
    deletionGracePeriodSeconds: 0
    deletionTimestamp: "2025-10-17T02:14:16Z"
    finalizers:
    - service.kubernetes.io/load-balancer-cleanup
    labels:
      app: camera-esp32-relay
    name: camera-esp32-relay-public
    namespace: suite
    resourceVersion: "21791206"
    uid: 49ba0ebd-3eab-46ed-a335-6af5ace0c0a1
  spec:
    allocateLoadBalancerNodePorts: true
    clusterIP: 10.43.249.89
    clusterIPs:
    - 10.43.249.89
    externalTrafficPolicy: Cluster
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: rtsp
      nodePort: 32575
      port: 8554
      protocol: TCP
      targetPort: rtsp
    - name: hls
      nodePort: 30425
      port: 8888
      protocol: TCP
      targetPort: hls
    - name: webrtc
      nodePort: 31640
      port: 8889
      protocol: TCP
      targetPort: webrtc
    selector:
      app: camera-esp32-relay
    sessionAffinity: None
    type: LoadBalancer
  status:
    loadBalancer:
      ingress:
      - ip: 192.168.50.3
        ipMode: VIP
      - ip: 192.168.50.9
        ipMode: VIP
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"Service","metadata":{"annotations":{},"name":"camera-uploader","namespace":"suite"},"spec":{"ports":[{"name":"http","port":80,"targetPort":80}],"selector":{"app":"camera-uploader"}}}
    creationTimestamp: "2025-09-19T15:30:36Z"
    name: camera-uploader
    namespace: suite
    resourceVersion: "9875384"
    uid: 3eed0334-f955-4260-b00c-bc33f132f0d0
  spec:
    clusterIP: 10.43.147.59
    clusterIPs:
    - 10.43.147.59
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: http
      port: 80
      protocol: TCP
      targetPort: 80
    selector:
      app: camera-uploader
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    creationTimestamp: "2025-11-28T18:13:08Z"
    labels:
      app: clm
    name: clm
    namespace: suite
    resourceVersion: "43102643"
    uid: abe2598b-7bf6-401c-9318-5663d7f73acd
  spec:
    allocateLoadBalancerNodePorts: true
    clusterIP: 10.43.93.181
    clusterIPs:
    - 10.43.93.181
    externalTrafficPolicy: Cluster
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - nodePort: 30968
      port: 3000
      protocol: TCP
      targetPort: 3000
    selector:
      app: clm
    sessionAffinity: None
    type: LoadBalancer
  status:
    loadBalancer:
      ingress:
      - ip: 192.168.50.241
        ipMode: VIP
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"Service","metadata":{"annotations":{},"name":"echo-8081","namespace":"suite"},"spec":{"ports":[{"name":"http","port":8081,"targetPort":8081}],"selector":{"app":"echo-8081"}}}
    creationTimestamp: "2025-10-02T22:33:10Z"
    name: echo-8081
    namespace: suite
    resourceVersion: "15092146"
    uid: 7641ebe2-e6a6-496b-a8ba-eceaf2f6e838
  spec:
    clusterIP: 10.43.111.84
    clusterIPs:
    - 10.43.111.84
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: http
      port: 8081
      protocol: TCP
      targetPort: 8081
    selector:
      app: echo-8081
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"Service","metadata":{"annotations":{},"name":"homebridge","namespace":"suite"},"spec":{"ports":[{"name":"ui","port":8581,"targetPort":8581},{"name":"https","port":51443,"targetPort":51443}],"selector":{"app":"homebridge"}}}
    creationTimestamp: "2025-09-12T12:53:26Z"
    name: homebridge
    namespace: suite
    resourceVersion: "40082613"
    uid: cfa18a04-7c93-4e97-a234-c62400493acf
  spec:
    clusterIP: 10.43.54.215
    clusterIPs:
    - 10.43.54.215
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: ui
      port: 8581
      protocol: TCP
      targetPort: 8581
    - name: https
      port: 51443
      protocol: TCP
      targetPort: 51443
    selector:
      app: homebridge
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"Service","metadata":{"annotations":{},"name":"jenkins","namespace":"suite"},"spec":{"ports":[{"name":"http","port":8080,"targetPort":8080},{"name":"agent","port":50000,"targetPort":50000}],"selector":{"app":"jenkins"},"type":"ClusterIP"}}
    creationTimestamp: "2025-11-02T14:51:36Z"
    name: jenkins
    namespace: suite
    resourceVersion: "32567626"
    uid: 0e5b0d42-a4f3-4f19-9e4d-29f0a85558bd
  spec:
    clusterIP: 10.43.166.247
    clusterIPs:
    - 10.43.166.247
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: http
      port: 8080
      protocol: TCP
      targetPort: 8080
    - name: agent
      port: 50000
      protocol: TCP
      targetPort: 50000
    selector:
      app: jenkins
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"Service","metadata":{"annotations":{},"name":"magicmirror-hostport","namespace":"suite"},"spec":{"externalTrafficPolicy":"Local","ports":[{"name":"http","nodePort":32181,"port":8080,"targetPort":8081}],"selector":{"app.kubernetes.io/name":"magicmirror"},"type":"NodePort"}}
      meta.helm.sh/release-name: magicmirror
      meta.helm.sh/release-namespace: suite
    creationTimestamp: "2025-10-03T02:43:42Z"
    labels:
      app.kubernetes.io/instance: magicmirror
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: magicmirror-server
    name: magicmirror-hostport
    namespace: suite
    resourceVersion: "26528178"
    uid: 7a6a6bdb-1342-4377-bbd5-4fd5db6dee4c
  spec:
    clusterIP: 10.43.30.137
    clusterIPs:
    - 10.43.30.137
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: web
      port: 80
      protocol: TCP
      targetPort: 8080
    selector:
      app: magicmirror-app
    sessionAffinity: ClientIP
    sessionAffinityConfig:
      clientIP:
        timeoutSeconds: 10800
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"Service","metadata":{"annotations":{},"name":"magicmirror-server","namespace":"suite"},"spec":{"ports":[{"port":8080,"targetPort":8080}],"selector":{"app":"magicmirror-server"}}}
    creationTimestamp: "2025-10-02T16:43:26Z"
    name: magicmirror-server
    namespace: suite
    resourceVersion: "32567641"
    uid: 0ae8ff75-13a8-4d4e-abdb-553ec3eaf2db
  spec:
    clusterIP: 10.43.191.110
    clusterIPs:
    - 10.43.191.110
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - port: 8080
      protocol: TCP
      targetPort: 8080
    selector:
      app: magicmirror-server
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"Service","metadata":{"annotations":{},"name":"mediamtx","namespace":"suite"},"spec":{"ports":[{"name":"rtsp","port":8554,"targetPort":8554},{"name":"hls","port":8888,"targetPort":8888},{"name":"webrtc","port":8889,"targetPort":8889}],"selector":{"app":"mediamtx"}}}
    creationTimestamp: "2025-09-27T11:47:45Z"
    name: mediamtx
    namespace: suite
    resourceVersion: "32567665"
    uid: e0fe1459-a8f1-431d-ab93-867802c5d801
  spec:
    clusterIP: 10.43.190.144
    clusterIPs:
    - 10.43.190.144
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: rtsp
      port: 8554
      protocol: TCP
      targetPort: 8554
    - name: hls
      port: 8888
      protocol: TCP
      targetPort: 8888
    - name: webrtc
      port: 8889
      protocol: TCP
      targetPort: 8889
    selector:
      app: mediamtx
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"Service","metadata":{"annotations":{},"name":"mosquitto","namespace":"suite"},"spec":{"ports":[{"name":"mqtt","port":1883,"targetPort":1883}],"selector":{"app":"mosquitto"}}}
    creationTimestamp: "2025-09-12T12:53:25Z"
    name: mosquitto
    namespace: suite
    resourceVersion: "32567686"
    uid: 151a17e3-37f9-491a-bde4-684aa72aa4d9
  spec:
    clusterIP: 10.43.34.37
    clusterIPs:
    - 10.43.34.37
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: mqtt
      port: 1883
      protocol: TCP
      targetPort: 1883
    selector:
      app: mosquitto
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"Service","metadata":{"annotations":{},"name":"mosquitto-headless","namespace":"suite"},"spec":{"clusterIP":"None","ports":[{"name":"mqtt","port":1883,"protocol":"TCP","targetPort":1883}],"selector":{"app":"mosquitto"}}}
    creationTimestamp: "2025-09-27T12:58:04Z"
    name: mosquitto-headless
    namespace: suite
    resourceVersion: "12961422"
    uid: 70c27268-04d8-497e-bdc5-636d74f64eaf
  spec:
    clusterIP: None
    clusterIPs:
    - None
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: mqtt
      port: 1883
      protocol: TCP
      targetPort: 1883
    selector:
      app: mosquitto
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"Service","metadata":{"annotations":{},"creationTimestamp":"2025-09-12T12:53:26Z","finalizers":["service.kubernetes.io/load-balancer-cleanup"],"name":"pihole","namespace":"suite","resourceVersion":"38141993","uid":"dc1b1f61-c173-4187-a5c5-60ade3c33c4f"},"spec":{"allocateLoadBalancerNodePorts":true,"clusterIP":"10.43.157.234","clusterIPs":["10.43.157.234"],"externalTrafficPolicy":"Local","healthCheckNodePort":32749,"internalTrafficPolicy":"Cluster","ipFamilies":["IPv4"],"ipFamilyPolicy":"SingleStack","loadBalancerIP":"192.168.50.245","ports":[{"name":"dns-udp","nodePort":31173,"port":53,"protocol":"UDP","targetPort":53},{"name":"dns-tcp","nodePort":32643,"port":53,"protocol":"TCP","targetPort":53},{"name":"http","nodePort":31961,"port":80,"protocol":"TCP","targetPort":80}],"selector":{"app":"pihole"},"sessionAffinity":"None","type":"LoadBalancer"},"status":{"loadBalancer":{"ingress":[{"ip":"192.168.50.245","ipMode":"VIP"}]}}}
    creationTimestamp: "2025-09-12T12:53:26Z"
    finalizers:
    - service.kubernetes.io/load-balancer-cleanup
    name: pihole
    namespace: suite
    resourceVersion: "38155529"
    uid: dc1b1f61-c173-4187-a5c5-60ade3c33c4f
  spec:
    allocateLoadBalancerNodePorts: true
    clusterIP: 10.43.157.234
    clusterIPs:
    - 10.43.157.234
    externalTrafficPolicy: Local
    healthCheckNodePort: 32749
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    loadBalancerIP: 192.168.50.245
    ports:
    - name: dns-udp
      nodePort: 31173
      port: 53
      protocol: UDP
      targetPort: 53
    - name: dns-tcp
      nodePort: 32643
      port: 53
      protocol: TCP
      targetPort: 53
    - name: http
      nodePort: 31961
      port: 80
      protocol: TCP
      targetPort: 80
    selector:
      app: pihole
    sessionAffinity: None
    type: LoadBalancer
  status:
    loadBalancer:
      ingress:
      - ip: 192.168.50.245
        ipMode: VIP
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"Service","metadata":{"annotations":{},"name":"scrypted","namespace":"suite"},"spec":{"ports":[{"name":"ui","port":11080,"targetPort":11080}],"selector":{"app":"scrypted"}}}
    creationTimestamp: "2025-09-12T12:53:26Z"
    name: scrypted
    namespace: suite
    resourceVersion: "32567738"
    uid: f4a4920c-98e6-4d25-ab7c-53bdbc5eb501
  spec:
    clusterIP: 10.43.111.153
    clusterIPs:
    - 10.43.111.153
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: ui
      port: 11080
      protocol: TCP
      targetPort: 11080
    selector:
      app: scrypted
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      meta.helm.sh/release-name: magicmirror
      meta.helm.sh/release-namespace: suite
    creationTimestamp: "2025-10-20T00:58:05Z"
    labels:
      app.kubernetes.io/managed-by: Helm
    name: spotify-callback
    namespace: suite
    resourceVersion: "23244887"
    uid: 8cce2f3a-5404-4db4-b810-a01b45f9d82d
  spec:
    clusterIP: 10.43.50.117
    clusterIPs:
    - 10.43.50.117
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: http
      port: 8080
      protocol: TCP
      targetPort: 8080
    selector:
      app: spotify-callback
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"Service","metadata":{"annotations":{},"name":"suite-command-center-api","namespace":"suite"},"spec":{"ports":[{"name":"http","port":80,"targetPort":8000}],"selector":{"app":"suite-command-center-api"}}}
      meta.helm.sh/release-name: suite-command-center
      meta.helm.sh/release-namespace: suite
    creationTimestamp: "2025-12-22T16:35:34Z"
    labels:
      app.kubernetes.io/managed-by: Helm
      helm.toolkit.fluxcd.io/name: suite-command-center
      helm.toolkit.fluxcd.io/namespace: suite
    name: suite-command-center-api
    namespace: suite
    resourceVersion: "58857591"
    uid: 17e4d216-e575-4943-8e21-0955456eb55e
  spec:
    clusterIP: 10.43.6.39
    clusterIPs:
    - 10.43.6.39
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: http
      port: 80
      protocol: TCP
      targetPort: 8000
    selector:
      app: suite-command-center-api
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    creationTimestamp: "2025-12-30T01:11:59Z"
    labels:
      kustomize.toolkit.fluxcd.io/name: flux-system
      kustomize.toolkit.fluxcd.io/namespace: flux-system
    name: suite-command-center-api-shim
    namespace: suite
    resourceVersion: "60219668"
    uid: 2573ba1e-83c6-4a9b-afbe-6f4fa04b90be
  spec:
    clusterIP: 10.43.5.218
    clusterIPs:
    - 10.43.5.218
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: http
      port: 80
      protocol: TCP
      targetPort: http
    selector:
      app: suite-command-center-api-shim
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"Service","metadata":{"annotations":{},"name":"suite-command-center-ui","namespace":"suite"},"spec":{"ports":[{"name":"http","port":80,"targetPort":3000}],"selector":{"app":"suite-command-center-ui"}}}
      meta.helm.sh/release-name: suite-command-center
      meta.helm.sh/release-namespace: suite
    creationTimestamp: "2025-12-22T16:35:34Z"
    labels:
      app.kubernetes.io/managed-by: Helm
      helm.toolkit.fluxcd.io/name: suite-command-center
      helm.toolkit.fluxcd.io/namespace: suite
    name: suite-command-center-ui
    namespace: suite
    resourceVersion: "60150797"
    uid: 9cd8325f-67a5-4e13-a32e-69dc1a08050a
  spec:
    clusterIP: 10.43.138.141
    clusterIPs:
    - 10.43.138.141
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: http
      port: 80
      protocol: TCP
      targetPort: 3000
    selector:
      app: suite-command-center-ui
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"Service","metadata":{"annotations":{},"name":"wyze","namespace":"suite"},"spec":{"loadBalancerIP":"192.168.50.243","ports":[{"name":"rtsp","port":8554,"targetPort":8554}],"selector":{"app":"wyze"},"type":"LoadBalancer"}}
    creationTimestamp: "2025-11-08T02:10:26Z"
    name: wyze
    namespace: suite
    resourceVersion: "32567854"
    uid: 9ef9e101-afd3-4440-9162-007c7117ad4b
  spec:
    allocateLoadBalancerNodePorts: true
    clusterIP: 10.43.254.119
    clusterIPs:
    - 10.43.254.119
    externalTrafficPolicy: Cluster
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    loadBalancerIP: 192.168.50.243
    ports:
    - name: rtsp
      nodePort: 31485
      port: 8554
      protocol: TCP
      targetPort: 8554
    selector:
      app: wyze
    sessionAffinity: None
    type: LoadBalancer
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"Service","metadata":{"annotations":{},"name":"zigbee2mqtt","namespace":"suite"},"spec":{"ports":[{"name":"ui","port":8081,"targetPort":8081}],"selector":{"app":"zigbee2mqtt"}}}
    creationTimestamp: "2025-09-12T12:53:26Z"
    name: zigbee2mqtt
    namespace: suite
    resourceVersion: "32567869"
    uid: bf95faf0-ff1f-4ead-b090-1338cfa7db04
  spec:
    clusterIP: 10.43.62.97
    clusterIPs:
    - 10.43.62.97
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: ui
      port: 8081
      protocol: TCP
      targetPort: 8081
    selector:
      app: zigbee2mqtt
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "2"
    creationTimestamp: "2025-10-04T03:41:42Z"
    generation: 2
    labels:
      app: clm
    name: clm
    namespace: suite
    resourceVersion: "61861524"
    uid: bffb52eb-32ce-4c63-a3c7-f9b3fb018f4d
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app: clm
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        creationTimestamp: null
        labels:
          app: clm
      spec:
        containers:
        - image: allenwayne/clm
          imagePullPolicy: Always
          name: clm-clean
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
  status:
    conditions:
    - lastTransitionTime: "2025-10-04T03:41:42Z"
      lastUpdateTime: "2025-10-04T03:42:54Z"
      message: ReplicaSet "clm-58888847cd" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2026-01-01T15:02:59Z"
      lastUpdateTime: "2026-01-01T15:02:59Z"
      message: Deployment does not have minimum availability.
      reason: MinimumReplicasUnavailable
      status: "False"
      type: Available
    observedGeneration: 2
    replicas: 1
    unavailableReplicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "44"
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"Deployment","metadata":{"annotations":{},"name":"homebridge","namespace":"suite"},"spec":{"replicas":1,"selector":{"matchLabels":{"app":"homebridge"}},"template":{"metadata":{"labels":{"app":"homebridge"}},"spec":{"containers":[{"env":[{"name":"TZ","value":"America/Chicago"},{"name":"HOMEBRIDGE_CONFIG_UI","value":"1"},{"name":"HOMEBRIDGE_CONFIG_UI_PORT","value":"8581"},{"name":"HOMEBRIDGE_CONFIG_UI_HOST","value":"0.0.0.0"},{"name":"HOMEBRIDGE_DISABLE_IPV6","value":"1"},{"name":"NODE_OPTIONS","value":"--dns-result-order=ipv4first"}],"image":"homebridge/homebridge:latest","name":"homebridge","ports":[{"containerPort":8581,"name":"ui"},{"containerPort":51443,"name":"hap"}],"volumeMounts":[{"mountPath":"/homebridge","name":"data"}]}],"nodeSelector":{"homekit":"bridge"},"volumes":[{"name":"data","persistentVolumeClaim":{"claimName":"homebridge-data-longhorn"}}]}}}}
    creationTimestamp: "2025-09-12T12:53:26Z"
    generation: 47
    name: homebridge
    namespace: suite
    resourceVersion: "58635269"
    uid: 8e4a2527-6b40-42c8-b340-b884931ae03c
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app: homebridge
    strategy:
      type: Recreate
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-11-22T14:22:52-06:00"
        creationTimestamp: null
        labels:
          app: homebridge
      spec:
        containers:
        - env:
          - name: TZ
            value: America/Chicago
          - name: HOMEBRIDGE_CONFIG_UI
            value: "1"
          - name: HOMEBRIDGE_CONFIG_UI_PORT
            value: "8581"
          - name: HOMEBRIDGE_CONFIG_UI_HOST
            value: 0.0.0.0
          - name: HOMEBRIDGE_DISABLE_IPV6
            value: "1"
          - name: NODE_OPTIONS
            value: --dns-result-order=ipv4first
          - name: HOMEBRIDGE_ADVERTISER
            value: ciao
          - name: HOMEBRIDGE_MDNS_INTERFACE
            value: eth0
          - name: HOMEBRIDGE_ENABLE_IPV6
            value: "0"
          image: homebridge/homebridge:latest
          imagePullPolicy: Always
          name: homebridge
          ports:
          - containerPort: 8581
            name: ui
            protocol: TCP
          - containerPort: 51443
            name: hap
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /homebridge
            name: data
          - mountPath: /etc/avahi/avahi-daemon.conf
            name: avahi-config
            subPath: avahi-daemon.conf
        dnsConfig:
          nameservers:
          - 1.1.1.1
          - 8.8.8.8
        dnsPolicy: ClusterFirstWithHostNet
        hostNetwork: true
        nodeSelector:
          homekit: bridge
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
        volumes:
        - configMap:
            defaultMode: 420
            name: homebridge-avahi
          name: avahi-config
        - name: data
          persistentVolumeClaim:
            claimName: homebridge-data-longhorn
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2025-11-13T00:02:55Z"
      lastUpdateTime: "2025-11-22T20:22:56Z"
      message: ReplicaSet "homebridge-7b5b8cdf94" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2025-12-27T13:33:27Z"
      lastUpdateTime: "2025-12-27T13:33:27Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 47
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"Deployment","metadata":{"annotations":{},"name":"jenkins","namespace":"suite"},"spec":{"replicas":1,"selector":{"matchLabels":{"app":"jenkins"}},"template":{"metadata":{"labels":{"app":"jenkins"}},"spec":{"containers":[{"env":[{"name":"JAVA_OPTS","value":"-Djenkins.install.runSetupWizard=false"}],"image":"jenkins/jenkins:lts-jdk17","imagePullPolicy":"IfNotPresent","livenessProbe":{"httpGet":{"path":"/login","port":8080},"initialDelaySeconds":60,"periodSeconds":20},"name":"jenkins","ports":[{"containerPort":8080,"name":"http"},{"containerPort":50000,"name":"agent"}],"readinessProbe":{"httpGet":{"path":"/login","port":8080},"initialDelaySeconds":30,"periodSeconds":10},"resources":{"limits":{"cpu":"1","memory":"2Gi"},"requests":{"cpu":"500m","memory":"1Gi"}},"volumeMounts":[{"mountPath":"/var/jenkins_home","name":"jenkins-home"}]}],"securityContext":{"fsGroup":1000},"serviceAccountName":"jenkins","volumes":[{"name":"jenkins-home","persistentVolumeClaim":{"claimName":"jenkins-home"}}]}}}}
    creationTimestamp: "2025-11-02T14:51:36Z"
    generation: 1
    name: jenkins
    namespace: suite
    resourceVersion: "58632892"
    uid: 1e309af3-2042-40f5-b9e4-9e0c9aa8a8a9
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app: jenkins
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        creationTimestamp: null
        labels:
          app: jenkins
      spec:
        containers:
        - env:
          - name: JAVA_OPTS
            value: -Djenkins.install.runSetupWizard=false
          image: jenkins/jenkins:lts-jdk17
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /login
              port: 8080
              scheme: HTTP
            initialDelaySeconds: 60
            periodSeconds: 20
            successThreshold: 1
            timeoutSeconds: 1
          name: jenkins
          ports:
          - containerPort: 8080
            name: http
            protocol: TCP
          - containerPort: 50000
            name: agent
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /login
              port: 8080
              scheme: HTTP
            initialDelaySeconds: 30
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources:
            limits:
              cpu: "1"
              memory: 2Gi
            requests:
              cpu: 500m
              memory: 1Gi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /var/jenkins_home
            name: jenkins-home
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          fsGroup: 1000
        serviceAccount: jenkins
        serviceAccountName: jenkins
        terminationGracePeriodSeconds: 30
        volumes:
        - name: jenkins-home
          persistentVolumeClaim:
            claimName: jenkins-home
  status:
    conditions:
    - lastTransitionTime: "2025-11-02T14:51:36Z"
      lastUpdateTime: "2025-11-02T14:52:41Z"
      message: ReplicaSet "jenkins-77ffddbfd" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2025-12-27T12:45:38Z"
      lastUpdateTime: "2025-12-27T12:45:38Z"
      message: Deployment does not have minimum availability.
      reason: MinimumReplicasUnavailable
      status: "False"
      type: Available
    observedGeneration: 1
    replicas: 1
    unavailableReplicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
    creationTimestamp: "2025-10-28T18:05:03Z"
    generation: 1
    name: magicmirror-app
    namespace: suite
    resourceVersion: "58635443"
    uid: bcc9f2e9-bafc-4800-9aef-5fb8601ea11e
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app: magicmirror-app
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        creationTimestamp: null
        labels:
          allow-egress: internet
          app: magicmirror-app
      spec:
        containers:
        - env:
          - name: MM_CONFIG_FILE
            value: /opt/magic_mirror/config/config.js
          - name: NODE_ENV
            value: production
          image: docker.io/bastilimbach/docker-magicmirror:latest
          imagePullPolicy: Always
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /
              port: http
              scheme: HTTP
            initialDelaySeconds: 25
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 2
          name: magicmirror
          ports:
          - containerPort: 8080
            name: http
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /
              port: http
              scheme: HTTP
            initialDelaySeconds: 12
            periodSeconds: 5
            successThreshold: 1
            timeoutSeconds: 2
          resources:
            limits:
              cpu: 800m
              memory: 512Mi
            requests:
              cpu: 200m
              memory: 256Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /opt/magic_mirror/config/config.js
            name: mm-config
            readOnly: true
            subPath: config.js
          - mountPath: /opt/magic_mirror/modules
            name: modules-work
        dnsPolicy: ClusterFirst
        initContainers:
        - args:
          - |
            set -e
            # Start with image defaults
            cp -a /opt/magic_mirror/modules/. /work/
            mkdir -p /work/custom
            # Merge persisted customs (if any)
            cp -a /persist/. /work/custom/ 2>/dev/null || true
          command:
          - /bin/sh
          - -lc
          image: docker.io/bastilimbach/docker-magicmirror:latest
          imagePullPolicy: IfNotPresent
          name: seed-modules
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /work
            name: modules-work
          - mountPath: /persist
            name: mm-persist
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
        volumes:
        - configMap:
            defaultMode: 420
            name: magicmirror-config
          name: mm-config
        - name: mm-persist
          persistentVolumeClaim:
            claimName: mm-modules-pvc
        - emptyDir: {}
          name: modules-work
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2025-10-28T18:05:03Z"
      lastUpdateTime: "2025-10-28T18:05:22Z"
      message: ReplicaSet "magicmirror-app-79d76f44c" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2025-12-27T13:33:36Z"
      lastUpdateTime: "2025-12-27T13:33:36Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"Deployment","metadata":{"annotations":{},"name":"magicmirror-server","namespace":"suite"},"spec":{"replicas":1,"selector":{"matchLabels":{"app":"magicmirror-server"}},"strategy":{"type":"Recreate"},"template":{"metadata":{"labels":{"app":"magicmirror-server"}},"spec":{"containers":[{"args":["npm run server"],"command":["/bin/sh","-lc"],"env":[{"name":"TZ","value":"America/Chicago"},{"name":"OPENWEATHER_API_KEY","valueFrom":{"secretKeyRef":{"key":"API_KEY","name":"openweather"}}}],"image":"docker.io/allenwayne/magicmirror-server:2.32","livenessProbe":{"httpGet":{"path":"/","port":8080},"initialDelaySeconds":30,"periodSeconds":20},"name":"magicmirror","ports":[{"containerPort":8080}],"volumeMounts":[{"mountPath":"/opt/magic_mirror/config/config.js","name":"mm-config","subPath":"config.js"},{"mountPath":"/opt/magic_mirror/modules","name":"mm-modules"},{"mountPath":"/opt/magic_mirror/public","name":"mm-public"}]}],"initContainers":[{"args":["set -eux\nrm -rf /work/modules/* /work/public/* || true\nif [ -d /opt/magic_mirror/modules ]; then\n  cp -a /opt/magic_mirror/modules/. /work/modules/\nfi\nif [ -d /opt/magic_mirror/public ]; then\n  cp -a /opt/magic_mirror/public/. /work/public/\nfi\n"],"command":["/bin/sh","-lc"],"image":"docker.io/allenwayne/magicmirror-server:2.32","name":"seed-modules","volumeMounts":[{"mountPath":"/work/modules","name":"mm-modules"},{"mountPath":"/work/public","name":"mm-public"}]},{"args":["echo skipping git-modules; exit 0"],"command":["/bin/sh","-lc"],"image":"alpine:3.20","name":"git-modules","volumeMounts":[{"mountPath":"/work/modules","name":"mm-modules"},{"mountPath":"/work/public","name":"mm-public"},{"mountPath":"/extras","name":"mm-extras"}]}],"nodeSelector":{"kubernetes.io/hostname":"m3"},"volumes":[{"configMap":{"name":"magicmirror-config"},"name":"mm-config"},{"emptyDir":{},"name":"mm-modules"},{"emptyDir":{},"name":"mm-public"},{"configMap":{"name":"magicmirror-extras"},"name":"mm-extras"}]}}}}
    creationTimestamp: "2025-11-08T02:10:23Z"
    generation: 1
    name: magicmirror-server
    namespace: suite
    resourceVersion: "51921868"
    uid: e432d4fc-6664-4f1a-8eda-709c4ffcde63
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app: magicmirror-server
    strategy:
      type: Recreate
    template:
      metadata:
        creationTimestamp: null
        labels:
          app: magicmirror-server
      spec:
        containers:
        - args:
          - npm run server
          command:
          - /bin/sh
          - -lc
          env:
          - name: TZ
            value: America/Chicago
          - name: OPENWEATHER_API_KEY
            valueFrom:
              secretKeyRef:
                key: API_KEY
                name: openweather
          image: docker.io/allenwayne/magicmirror-server:2.32
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /
              port: 8080
              scheme: HTTP
            initialDelaySeconds: 30
            periodSeconds: 20
            successThreshold: 1
            timeoutSeconds: 1
          name: magicmirror
          ports:
          - containerPort: 8080
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /opt/magic_mirror/config/config.js
            name: mm-config
            subPath: config.js
          - mountPath: /opt/magic_mirror/modules
            name: mm-modules
          - mountPath: /opt/magic_mirror/public
            name: mm-public
        dnsPolicy: ClusterFirst
        initContainers:
        - args:
          - |
            set -eux
            rm -rf /work/modules/* /work/public/* || true
            if [ -d /opt/magic_mirror/modules ]; then
              cp -a /opt/magic_mirror/modules/. /work/modules/
            fi
            if [ -d /opt/magic_mirror/public ]; then
              cp -a /opt/magic_mirror/public/. /work/public/
            fi
          command:
          - /bin/sh
          - -lc
          image: docker.io/allenwayne/magicmirror-server:2.32
          imagePullPolicy: IfNotPresent
          name: seed-modules
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /work/modules
            name: mm-modules
          - mountPath: /work/public
            name: mm-public
        - args:
          - echo skipping git-modules; exit 0
          command:
          - /bin/sh
          - -lc
          image: alpine:3.20
          imagePullPolicy: IfNotPresent
          name: git-modules
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /work/modules
            name: mm-modules
          - mountPath: /work/public
            name: mm-public
          - mountPath: /extras
            name: mm-extras
        nodeSelector:
          kubernetes.io/hostname: m3
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
        volumes:
        - configMap:
            defaultMode: 420
            name: magicmirror-config
          name: mm-config
        - emptyDir: {}
          name: mm-modules
        - emptyDir: {}
          name: mm-public
        - configMap:
            defaultMode: 420
            name: magicmirror-extras
          name: mm-extras
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2025-11-08T02:10:24Z"
      lastUpdateTime: "2025-11-08T02:10:27Z"
      message: ReplicaSet "magicmirror-server-5c8f999799" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2025-12-14T19:31:54Z"
      lastUpdateTime: "2025-12-14T19:31:54Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "31"
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"Deployment","metadata":{"annotations":{"deployment.kubernetes.io/revision":"30"},"creationTimestamp":"2025-09-12T12:53:26Z","generation":40,"name":"pihole","namespace":"suite","resourceVersion":"37681377","uid":"c641337e-588b-4870-97a6-eefb0f7cc2d3"},"spec":{"progressDeadlineSeconds":600,"replicas":1,"revisionHistoryLimit":10,"selector":{"matchLabels":{"app":"pihole"}},"strategy":{"type":"Recreate"},"template":{"metadata":{"annotations":{"kubectl.kubernetes.io/restartedAt":"2025-11-15T09:02:01-06:00"},"creationTimestamp":null,"labels":{"app":"pihole"}},"spec":{"containers":[{"env":[{"name":"DNSMASQ_LISTENING","value":"all"},{"name":"ServerIP","value":"192.168.50.245"},{"name":"WEB_PORT","value":"80"},{"name":"PIHOLE_DNS_1","value":"1.1.1.1"},{"name":"PIHOLE_DNS_2","value":"9.9.9.9"},{"name":"DNSSEC","value":"false"},{"name":"TZ","value":"America/Chicago"}],"image":"pihole/pihole:latest","imagePullPolicy":"Always","name":"pihole","ports":[{"containerPort":53,"name":"dns-udp","protocol":"UDP"},{"containerPort":53,"name":"dns-tcp","protocol":"TCP"},{"containerPort":80,"name":"http","protocol":"TCP"}],"resources":{},"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","volumeMounts":[{"mountPath":"/etc/dnsmasq.d","name":"etc-dnsmasq"},{"mountPath":"/etc/dnsmasq.d/01-ui-host.conf","name":"ui-override","subPath":"01-ui-host.conf"},{"mountPath":"/etc/dnsmasq.d/02-suite-home-arpa.conf","name":"dnsmasq-cm","subPath":"02-suite-home-arpa.conf"},{"mountPath":"/etc/dnsmasq.d/03-custom.conf","name":"dnsmasq-custom","subPath":"03-custom.conf"},{"mountPath":"/etc/pihole","name":"etc-pihole"}]}],"dnsPolicy":"ClusterFirst","nodeSelector":{"kubernetes.io/arch":"arm64","kubernetes.io/hostname":"m2"},"restartPolicy":"Always","schedulerName":"default-scheduler","securityContext":{},"terminationGracePeriodSeconds":30,"volumes":[{"name":"etc-pihole","persistentVolumeClaim":{"claimName":"pihole-etc-pihole-pvc-longhorn"}},{"name":"etc-dnsmasq","persistentVolumeClaim":{"claimName":"pihole-dnsmasq-pvc-longhorn"}},{"configMap":{"defaultMode":420,"name":"pihole-dnsmasq"},"name":"dnsmasq-cm"},{"configMap":{"defaultMode":420,"name":"pihole-ui-override"},"name":"ui-override"},{"configMap":{"defaultMode":420,"name":"pihole-dnsmasq-custom"},"name":"dnsmasq-custom"}]}}},"status":{"availableReplicas":1,"conditions":[{"lastTransitionTime":"2025-11-11T15:55:35Z","lastUpdateTime":"2025-11-15T15:02:19Z","message":"ReplicaSet \"pihole-dd4df85d\" has successfully progressed.","reason":"NewReplicaSetAvailable","status":"True","type":"Progressing"},{"lastTransitionTime":"2025-11-18T03:26:33Z","lastUpdateTime":"2025-11-18T03:26:33Z","message":"Deployment has minimum availability.","reason":"MinimumReplicasAvailable","status":"True","type":"Available"}],"observedGeneration":40,"readyReplicas":1,"replicas":1,"updatedReplicas":1}}
    creationTimestamp: "2025-09-12T12:53:26Z"
    generation: 42
    name: pihole
    namespace: suite
    resourceVersion: "58633151"
    uid: c641337e-588b-4870-97a6-eefb0f7cc2d3
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app: pihole
    strategy:
      type: Recreate
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-12-10T09:43:15-06:00"
        creationTimestamp: null
        labels:
          app: pihole
      spec:
        containers:
        - env:
          - name: DNSMASQ_LISTENING
            value: all
          - name: ServerIP
            value: 192.168.50.245
          - name: WEB_PORT
            value: "80"
          - name: PIHOLE_DNS_1
            value: 1.1.1.1
          - name: PIHOLE_DNS_2
            value: 9.9.9.9
          - name: DNSSEC
            value: "false"
          - name: TZ
            value: America/Chicago
          image: pihole/pihole:latest
          imagePullPolicy: Always
          name: pihole
          ports:
          - containerPort: 53
            name: dns-udp
            protocol: UDP
          - containerPort: 53
            name: dns-tcp
            protocol: TCP
          - containerPort: 80
            name: http
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/dnsmasq.d
            name: etc-dnsmasq
          - mountPath: /etc/dnsmasq.d/01-ui-host.conf
            name: ui-override
            subPath: 01-ui-host.conf
          - mountPath: /etc/dnsmasq.d/02-suite-home-arpa.conf
            name: dnsmasq-cm
            subPath: 02-suite-home-arpa.conf
          - mountPath: /etc/dnsmasq.d/03-custom.conf
            name: dnsmasq-custom
            subPath: 03-custom.conf
          - mountPath: /etc/pihole
            name: etc-pihole
        dnsPolicy: ClusterFirst
        nodeSelector:
          kubernetes.io/arch: arm64
          kubernetes.io/hostname: m2
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
        volumes:
        - name: etc-pihole
          persistentVolumeClaim:
            claimName: pihole-etc-pihole-pvc-longhorn
        - name: etc-dnsmasq
          persistentVolumeClaim:
            claimName: pihole-dnsmasq-pvc-longhorn
        - configMap:
            defaultMode: 420
            name: pihole-dnsmasq
          name: dnsmasq-cm
        - configMap:
            defaultMode: 420
            name: pihole-ui-override
          name: ui-override
        - configMap:
            defaultMode: 420
            name: pihole-dnsmasq-custom
          name: dnsmasq-custom
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2025-11-11T15:55:35Z"
      lastUpdateTime: "2025-12-10T15:43:27Z"
      message: ReplicaSet "pihole-7cbbb589c4" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2025-12-27T13:32:08Z"
      lastUpdateTime: "2025-12-27T13:32:08Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 42
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "22"
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"Deployment","metadata":{"annotations":{},"labels":{"app":"suite-command-center-api"},"name":"suite-command-center-api","namespace":"suite"},"spec":{"replicas":1,"selector":{"matchLabels":{"app":"suite-command-center-api"}},"template":{"metadata":{"labels":{"app":"suite-command-center-api"}},"spec":{"containers":[{"env":[{"name":"NO_PROXY","value":"127.0.0.1,localhost,10.0.0.0/8,10.42.0.0/16,10.43.0.0/16,.svc,.svc.cluster.local,.cluster.local"}],"image":"registry.suite.home.arpa:5000/suite-command-center-api:latest","name":"api","ports":[{"containerPort":8000}]}],"serviceAccountName":"suite-command-center-api"}}}}
      meta.helm.sh/release-name: suite-command-center
      meta.helm.sh/release-namespace: suite
    creationTimestamp: "2025-12-24T15:00:54Z"
    generation: 23
    labels:
      app: suite-command-center-api
      app.kubernetes.io/managed-by: Helm
      helm.toolkit.fluxcd.io/name: suite-command-center
      helm.toolkit.fluxcd.io/namespace: suite
    name: suite-command-center-api
    namespace: suite
    resourceVersion: "59996592"
    uid: 3ce9cd02-afeb-4c08-b60d-62d132e28a0b
  spec:
    progressDeadlineSeconds: 300
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app: suite-command-center-api
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-12-29T11:07:10-06:00"
        creationTimestamp: null
        labels:
          app: suite-command-center-api
      spec:
        automountServiceAccountToken: true
        containers:
        - env:
          - name: NO_PROXY
            value: 127.0.0.1,localhost,192.168.50.251,192.168.50.2,192.168.50.3,192.168.50.6,10.0.0.0/8,10.42.0.0/16,10.43.0.0/16,.svc,.svc.cluster.local,.cluster.local
          - name: PORT
            value: "8000"
          image: registry.suite.home.arpa:5000/suite-command-center-api:latest
          imagePullPolicy: Always
          name: api
          ports:
          - containerPort: 8000
            protocol: TCP
          resources: {}
          startupProbe:
            failureThreshold: 60
            httpGet:
              path: /healthz
              port: 8000
              scheme: HTTP
            periodSeconds: 2
            successThreshold: 1
            timeoutSeconds: 2
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        nodeSelector:
          kubernetes.io/hostname: m1
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: suite-command-center-api
        serviceAccountName: suite-command-center-api
        terminationGracePeriodSeconds: 30
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2025-12-29T17:07:07Z"
      lastUpdateTime: "2025-12-29T17:07:07Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    - lastTransitionTime: "2025-12-29T17:07:07Z"
      lastUpdateTime: "2025-12-29T17:07:12Z"
      message: ReplicaSet "suite-command-center-api-7455994f75" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    observedGeneration: 23
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "12"
    creationTimestamp: "2025-12-31T19:03:00Z"
    generation: 14
    labels:
      kustomize.toolkit.fluxcd.io/name: flux-system
      kustomize.toolkit.fluxcd.io/namespace: flux-system
    name: suite-command-center-api-shim
    namespace: suite
    resourceVersion: "61876754"
    uid: 8fae3472-1d7d-4499-b9a1-32fe9be2a32c
  spec:
    progressDeadlineSeconds: 600
    replicas: 2
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app: suite-command-center-api-shim
    strategy:
      rollingUpdate:
        maxSurge: 1
        maxUnavailable: 0
      type: RollingUpdate
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-12-31T19:35:38-06:00"
        creationTimestamp: null
        labels:
          app: suite-command-center-api-shim
      spec:
        containers:
        - command:
          - python
          - /app/server.py
          env:
          - name: PORT
            value: "8000"
          - name: APP_NAME
            value: suite-command-center-api-shim
          image: python:3.12-slim
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: 8000
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          name: api
          ports:
          - containerPort: 8000
            name: http
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: 8000
              scheme: HTTP
            initialDelaySeconds: 2
            periodSeconds: 5
            successThreshold: 1
            timeoutSeconds: 1
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /app
            name: code
            readOnly: true
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: suite-command-center-api-shim
        serviceAccountName: suite-command-center-api-shim
        terminationGracePeriodSeconds: 30
        volumes:
        - configMap:
            defaultMode: 420
            name: suite-command-center-api-shim
          name: code
  status:
    conditions:
    - lastTransitionTime: "2025-12-31T19:03:00Z"
      lastUpdateTime: "2026-01-01T01:35:44Z"
      message: ReplicaSet "suite-command-center-api-shim-68795c87d9" has successfully
        progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2026-01-01T15:35:45Z"
      lastUpdateTime: "2026-01-01T15:35:45Z"
      message: Deployment does not have minimum availability.
      reason: MinimumReplicasUnavailable
      status: "False"
      type: Available
    observedGeneration: 14
    replicas: 2
    unavailableReplicas: 2
    updatedReplicas: 2
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "27"
      meta.helm.sh/release-name: suite-command-center
      meta.helm.sh/release-namespace: suite
    creationTimestamp: "2025-12-22T16:35:34Z"
    generation: 28
    labels:
      app.kubernetes.io/managed-by: Helm
      helm.toolkit.fluxcd.io/name: suite-command-center
      helm.toolkit.fluxcd.io/namespace: suite
    name: suite-command-center-ui
    namespace: suite
    resourceVersion: "58857661"
    uid: 31548020-dd89-4c5f-9f6f-755fa5109650
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app: suite-command-center-ui
    strategy:
      rollingUpdate:
        maxSurge: 1
        maxUnavailable: 1
      type: RollingUpdate
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-12-27T10:05:49-06:00"
        creationTimestamp: null
        labels:
          app: suite-command-center-ui
      spec:
        containers:
        - image: registry.suite.home.arpa:5000/suite-command-center-ui:latest
          imagePullPolicy: Always
          name: ui
          ports:
          - containerPort: 80
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        nodeSelector:
          suite.home.arpa/display: "true"
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2025-12-23T00:28:10Z"
      lastUpdateTime: "2025-12-23T00:28:10Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    - lastTransitionTime: "2025-12-25T01:19:09Z"
      lastUpdateTime: "2025-12-27T22:42:13Z"
      message: ReplicaSet "suite-command-center-ui-6c856bb4f8" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    observedGeneration: 28
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "2"
    creationTimestamp: "2025-10-04T03:42:53Z"
    generation: 1
    labels:
      app: clm
      pod-template-hash: 58888847cd
    name: clm-58888847cd
    namespace: suite
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: clm
      uid: bffb52eb-32ce-4c63-a3c7-f9b3fb018f4d
    resourceVersion: "61861523"
    uid: 3ced13b9-8b4a-43ae-98e3-b04d420f2190
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: clm
        pod-template-hash: 58888847cd
    template:
      metadata:
        creationTimestamp: null
        labels:
          app: clm
          pod-template-hash: 58888847cd
      spec:
        containers:
        - image: allenwayne/clm
          imagePullPolicy: Always
          name: clm-clean
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
  status:
    fullyLabeledReplicas: 1
    observedGeneration: 1
    replicas: 1
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "1"
    creationTimestamp: "2025-10-04T03:41:42Z"
    generation: 2
    labels:
      app: clm
      pod-template-hash: 5d7ffc7778
    name: clm-5d7ffc7778
    namespace: suite
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: clm
      uid: bffb52eb-32ce-4c63-a3c7-f9b3fb018f4d
    resourceVersion: "15568483"
    uid: ca63d2f0-d847-41e1-bd74-7988cd6dbd27
  spec:
    replicas: 0
    selector:
      matchLabels:
        app: clm
        pod-template-hash: 5d7ffc7778
    template:
      metadata:
        creationTimestamp: null
        labels:
          app: clm
          pod-template-hash: 5d7ffc7778
      spec:
        containers:
        - image: allenwayne/clm-clean
          imagePullPolicy: Always
          name: clm-clean
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "1"
      deployment.kubernetes.io/revision: "41"
    creationTimestamp: "2025-11-16T14:10:28Z"
    generation: 2
    labels:
      app: homebridge
      pod-template-hash: 6bdd44bdf7
    name: homebridge-6bdd44bdf7
    namespace: suite
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: homebridge
      uid: 8e4a2527-6b40-42c8-b340-b884931ae03c
    resourceVersion: "38627893"
    uid: 98013fed-1d6f-43aa-a32e-7120650e9347
  spec:
    replicas: 0
    selector:
      matchLabels:
        app: homebridge
        pod-template-hash: 6bdd44bdf7
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-11-13T08:54:48-06:00"
        creationTimestamp: null
        labels:
          app: homebridge
          pod-template-hash: 6bdd44bdf7
      spec:
        containers:
        - env:
          - name: TZ
            value: America/Chicago
          - name: HOMEBRIDGE_CONFIG_UI
            value: "1"
          - name: HOMEBRIDGE_CONFIG_UI_PORT
            value: "8581"
          - name: HOMEBRIDGE_CONFIG_UI_HOST
            value: 0.0.0.0
          - name: HOMEBRIDGE_DISABLE_IPV6
            value: "1"
          - name: NODE_OPTIONS
            value: --dns-result-order=ipv4first
          - name: HOMEBRIDGE_ADVERTISER
            value: ciao
          - name: HOMEBRIDGE_MDNS_INTERFACE
            value: eth0
          - name: HOMEBRIDGE_ENABLE_IPV6
            value: "0"
          image: homebridge/homebridge:latest
          imagePullPolicy: Always
          name: homebridge
          ports:
          - containerPort: 8581
            name: ui
            protocol: TCP
          - containerPort: 51443
            name: hap
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /homebridge
            name: data
          - mountPath: /etc/avahi/avahi-daemon.conf
            name: avahi-config
            subPath: avahi-daemon.conf
        dnsConfig:
          nameservers:
          - 1.1.1.1
          - 8.8.8.8
        dnsPolicy: ClusterFirstWithHostNet
        hostNetwork: true
        nodeSelector:
          homekit: bridge
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
        volumes:
        - configMap:
            defaultMode: 420
            name: homebridge-avahi
          name: avahi-config
        - name: data
          persistentVolumeClaim:
            claimName: homebridge-data-longhorn
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "1"
      deployment.kubernetes.io/revision: "37"
    creationTimestamp: "2025-11-13T00:12:44Z"
    generation: 2
    labels:
      app: homebridge
      pod-template-hash: 6c747bdcd7
    name: homebridge-6c747bdcd7
    namespace: suite
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: homebridge
      uid: 8e4a2527-6b40-42c8-b340-b884931ae03c
    resourceVersion: "35317120"
    uid: 3bba1c1d-6f71-45bf-8920-23ba582b3e50
  spec:
    replicas: 0
    selector:
      matchLabels:
        app: homebridge
        pod-template-hash: 6c747bdcd7
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-11-12T18:08:52-06:00"
        creationTimestamp: null
        labels:
          app: homebridge
          pod-template-hash: 6c747bdcd7
      spec:
        containers:
        - env:
          - name: TZ
            value: America/Chicago
          - name: HOMEBRIDGE_CONFIG_UI
            value: "1"
          - name: HOMEBRIDGE_CONFIG_UI_PORT
            value: "8581"
          - name: HOMEBRIDGE_CONFIG_UI_HOST
            value: 0.0.0.0
          - name: HOMEBRIDGE_DISABLE_IPV6
            value: "1"
          - name: NODE_OPTIONS
            value: --dns-result-order=ipv4first
          - name: HOMEBRIDGE_ADVERTISER
            value: ciao
          - name: HOMEBRIDGE_MDNS_INTERFACE
            value: eth0
          - name: HOMEBRIDGE_ENABLE_IPV6
            value: "0"
          image: homebridge/homebridge:latest
          imagePullPolicy: Always
          name: homebridge
          ports:
          - containerPort: 8581
            name: ui
            protocol: TCP
          - containerPort: 51443
            name: hap
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /homebridge
            name: data
          - mountPath: /etc/avahi/avahi-daemon.conf
            name: avahi-config
            subPath: avahi-daemon.conf
        dnsConfig:
          nameservers:
          - 1.1.1.1
          - 8.8.8.8
        dnsPolicy: ClusterFirst
        nodeSelector:
          homekit: bridge
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
        volumes:
        - configMap:
            defaultMode: 420
            name: homebridge-avahi
          name: avahi-config
        - name: data
          persistentVolumeClaim:
            claimName: homebridge-data-longhorn
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "1"
      deployment.kubernetes.io/revision: "38"
    creationTimestamp: "2025-11-13T14:10:42Z"
    generation: 2
    labels:
      app: homebridge
      pod-template-hash: 6d94bfb658
    name: homebridge-6d94bfb658
    namespace: suite
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: homebridge
      uid: 8e4a2527-6b40-42c8-b340-b884931ae03c
    resourceVersion: "35322450"
    uid: 97e78a45-9545-4f90-b5a6-e1d071a38824
  spec:
    replicas: 0
    selector:
      matchLabels:
        app: homebridge
        pod-template-hash: 6d94bfb658
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-11-13T08:10:38-06:00"
        creationTimestamp: null
        labels:
          app: homebridge
          pod-template-hash: 6d94bfb658
      spec:
        containers:
        - env:
          - name: TZ
            value: America/Chicago
          - name: HOMEBRIDGE_CONFIG_UI
            value: "1"
          - name: HOMEBRIDGE_CONFIG_UI_PORT
            value: "8581"
          - name: HOMEBRIDGE_CONFIG_UI_HOST
            value: 0.0.0.0
          - name: HOMEBRIDGE_DISABLE_IPV6
            value: "1"
          - name: NODE_OPTIONS
            value: --dns-result-order=ipv4first
          - name: HOMEBRIDGE_ADVERTISER
            value: ciao
          - name: HOMEBRIDGE_MDNS_INTERFACE
            value: eth0
          - name: HOMEBRIDGE_ENABLE_IPV6
            value: "0"
          image: homebridge/homebridge:latest
          imagePullPolicy: Always
          name: homebridge
          ports:
          - containerPort: 8581
            name: ui
            protocol: TCP
          - containerPort: 51443
            name: hap
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /homebridge
            name: data
          - mountPath: /etc/avahi/avahi-daemon.conf
            name: avahi-config
            subPath: avahi-daemon.conf
        dnsConfig:
          nameservers:
          - 1.1.1.1
          - 8.8.8.8
        dnsPolicy: ClusterFirst
        nodeSelector:
          homekit: bridge
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
        volumes:
        - configMap:
            defaultMode: 420
            name: homebridge-avahi
          name: avahi-config
        - name: data
          persistentVolumeClaim:
            claimName: homebridge-data-longhorn
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "1"
      deployment.kubernetes.io/revision: "40"
    creationTimestamp: "2025-11-13T14:54:52Z"
    generation: 2
    labels:
      app: homebridge
      pod-template-hash: 6fd5cd59f
    name: homebridge-6fd5cd59f
    namespace: suite
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: homebridge
      uid: 8e4a2527-6b40-42c8-b340-b884931ae03c
    resourceVersion: "36863435"
    uid: fb1c0570-7250-4330-b090-2a0e206bfdea
  spec:
    replicas: 0
    selector:
      matchLabels:
        app: homebridge
        pod-template-hash: 6fd5cd59f
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-11-13T08:54:48-06:00"
        creationTimestamp: null
        labels:
          app: homebridge
          pod-template-hash: 6fd5cd59f
      spec:
        containers:
        - env:
          - name: TZ
            value: America/Chicago
          - name: HOMEBRIDGE_CONFIG_UI
            value: "1"
          - name: HOMEBRIDGE_CONFIG_UI_PORT
            value: "8581"
          - name: HOMEBRIDGE_CONFIG_UI_HOST
            value: 0.0.0.0
          - name: HOMEBRIDGE_DISABLE_IPV6
            value: "1"
          - name: NODE_OPTIONS
            value: --dns-result-order=ipv4first
          - name: HOMEBRIDGE_ADVERTISER
            value: ciao
          - name: HOMEBRIDGE_MDNS_INTERFACE
            value: eth0
          - name: HOMEBRIDGE_ENABLE_IPV6
            value: "0"
          image: homebridge/homebridge:latest
          imagePullPolicy: Always
          name: homebridge
          ports:
          - containerPort: 8581
            name: ui
            protocol: TCP
          - containerPort: 51443
            name: hap
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /homebridge
            name: data
          - mountPath: /etc/avahi/avahi-daemon.conf
            name: avahi-config
            subPath: avahi-daemon.conf
        dnsConfig:
          nameservers:
          - 1.1.1.1
          - 8.8.8.8
        dnsPolicy: ClusterFirst
        nodeSelector:
          homekit: bridge
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
        volumes:
        - configMap:
            defaultMode: 420
            name: homebridge-avahi
          name: avahi-config
        - name: data
          persistentVolumeClaim:
            claimName: homebridge-data-longhorn
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "1"
      deployment.kubernetes.io/revision: "42"
    creationTimestamp: "2025-11-19T23:35:32Z"
    generation: 2
    labels:
      app: homebridge
      pod-template-hash: 746945f75
    name: homebridge-746945f75
    namespace: suite
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: homebridge
      uid: 8e4a2527-6b40-42c8-b340-b884931ae03c
    resourceVersion: "38654400"
    uid: 938b6769-8aa8-4d84-a021-af75aa2bf01c
  spec:
    replicas: 0
    selector:
      matchLabels:
        app: homebridge
        pod-template-hash: 746945f75
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-11-19T17:35:30-06:00"
        creationTimestamp: null
        labels:
          app: homebridge
          pod-template-hash: 746945f75
      spec:
        containers:
        - env:
          - name: TZ
            value: America/Chicago
          - name: HOMEBRIDGE_CONFIG_UI
            value: "1"
          - name: HOMEBRIDGE_CONFIG_UI_PORT
            value: "8581"
          - name: HOMEBRIDGE_CONFIG_UI_HOST
            value: 0.0.0.0
          - name: HOMEBRIDGE_DISABLE_IPV6
            value: "1"
          - name: NODE_OPTIONS
            value: --dns-result-order=ipv4first
          - name: HOMEBRIDGE_ADVERTISER
            value: ciao
          - name: HOMEBRIDGE_MDNS_INTERFACE
            value: eth0
          - name: HOMEBRIDGE_ENABLE_IPV6
            value: "0"
          image: homebridge/homebridge:latest
          imagePullPolicy: Always
          name: homebridge
          ports:
          - containerPort: 8581
            name: ui
            protocol: TCP
          - containerPort: 51443
            name: hap
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /homebridge
            name: data
          - mountPath: /etc/avahi/avahi-daemon.conf
            name: avahi-config
            subPath: avahi-daemon.conf
        dnsConfig:
          nameservers:
          - 1.1.1.1
          - 8.8.8.8
        dnsPolicy: ClusterFirstWithHostNet
        hostNetwork: true
        nodeSelector:
          homekit: bridge
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
        volumes:
        - configMap:
            defaultMode: 420
            name: homebridge-avahi
          name: avahi-config
        - name: data
          persistentVolumeClaim:
            claimName: homebridge-data-longhorn
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "1"
      deployment.kubernetes.io/revision: "44"
    creationTimestamp: "2025-11-22T20:22:54Z"
    generation: 1
    labels:
      app: homebridge
      pod-template-hash: 7b5b8cdf94
    name: homebridge-7b5b8cdf94
    namespace: suite
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: homebridge
      uid: 8e4a2527-6b40-42c8-b340-b884931ae03c
    resourceVersion: "58635266"
    uid: edd9bb2c-2cd8-49c4-a40b-5a9d5558d4fe
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: homebridge
        pod-template-hash: 7b5b8cdf94
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-11-22T14:22:52-06:00"
        creationTimestamp: null
        labels:
          app: homebridge
          pod-template-hash: 7b5b8cdf94
      spec:
        containers:
        - env:
          - name: TZ
            value: America/Chicago
          - name: HOMEBRIDGE_CONFIG_UI
            value: "1"
          - name: HOMEBRIDGE_CONFIG_UI_PORT
            value: "8581"
          - name: HOMEBRIDGE_CONFIG_UI_HOST
            value: 0.0.0.0
          - name: HOMEBRIDGE_DISABLE_IPV6
            value: "1"
          - name: NODE_OPTIONS
            value: --dns-result-order=ipv4first
          - name: HOMEBRIDGE_ADVERTISER
            value: ciao
          - name: HOMEBRIDGE_MDNS_INTERFACE
            value: eth0
          - name: HOMEBRIDGE_ENABLE_IPV6
            value: "0"
          image: homebridge/homebridge:latest
          imagePullPolicy: Always
          name: homebridge
          ports:
          - containerPort: 8581
            name: ui
            protocol: TCP
          - containerPort: 51443
            name: hap
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /homebridge
            name: data
          - mountPath: /etc/avahi/avahi-daemon.conf
            name: avahi-config
            subPath: avahi-daemon.conf
        dnsConfig:
          nameservers:
          - 1.1.1.1
          - 8.8.8.8
        dnsPolicy: ClusterFirstWithHostNet
        hostNetwork: true
        nodeSelector:
          homekit: bridge
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
        volumes:
        - configMap:
            defaultMode: 420
            name: homebridge-avahi
          name: avahi-config
        - name: data
          persistentVolumeClaim:
            claimName: homebridge-data-longhorn
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "34"
    creationTimestamp: "2025-11-08T02:10:23Z"
    generation: 2
    labels:
      app: homebridge
      pod-template-hash: 7d4cb85bd6
    name: homebridge-7d4cb85bd6
    namespace: suite
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: homebridge
      uid: 8e4a2527-6b40-42c8-b340-b884931ae03c
    resourceVersion: "35016657"
    uid: bcb70f24-8e21-4f0e-93d4-285d0936407d
  spec:
    replicas: 0
    selector:
      matchLabels:
        app: homebridge
        pod-template-hash: 7d4cb85bd6
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-10-11T19:57:40-05:00"
        creationTimestamp: null
        labels:
          app: homebridge
          pod-template-hash: 7d4cb85bd6
      spec:
        containers:
        - env:
          - name: TZ
            value: America/Chicago
          - name: HOMEBRIDGE_CONFIG_UI
            value: "1"
          - name: HOMEBRIDGE_CONFIG_UI_PORT
            value: "8581"
          - name: HOMEBRIDGE_CONFIG_UI_HOST
            value: 0.0.0.0
          - name: HOMEBRIDGE_DISABLE_IPV6
            value: "1"
          - name: NODE_OPTIONS
            value: --dns-result-order=ipv4first
          - name: HOMEBRIDGE_ADVERTISER
            value: ciao
          - name: HOMEBRIDGE_MDNS_INTERFACE
            value: eth0
          - name: HOMEBRIDGE_ENABLE_IPV6
            value: "0"
          image: homebridge/homebridge:latest
          imagePullPolicy: Always
          name: homebridge
          ports:
          - containerPort: 8581
            name: ui
            protocol: TCP
          - containerPort: 51443
            name: hap
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /homebridge
            name: data
          - mountPath: /etc/avahi/avahi-daemon.conf
            name: avahi-config
            subPath: avahi-daemon.conf
        dnsConfig:
          nameservers:
          - 1.1.1.1
          - 8.8.8.8
        dnsPolicy: ClusterFirstWithHostNet
        hostNetwork: true
        hostname: homebridge
        nodeSelector:
          homekit: bridge
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
        volumes:
        - configMap:
            defaultMode: 420
            name: homebridge-avahi
          name: avahi-config
        - name: data
          persistentVolumeClaim:
            claimName: homebridge-data-longhorn
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "1"
      deployment.kubernetes.io/revision: "35"
    creationTimestamp: "2025-11-13T00:02:55Z"
    generation: 3
    labels:
      app: homebridge
      pod-template-hash: 7ff7cf8649
    name: homebridge-7ff7cf8649
    namespace: suite
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: homebridge
      uid: 8e4a2527-6b40-42c8-b340-b884931ae03c
    resourceVersion: "35018825"
    uid: 5e2db649-2b9d-4b03-a9a9-352bc8cf9dd5
  spec:
    replicas: 0
    selector:
      matchLabels:
        app: homebridge
        pod-template-hash: 7ff7cf8649
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-11-12T18:02:56-06:00"
        creationTimestamp: null
        labels:
          app: homebridge
          pod-template-hash: 7ff7cf8649
      spec:
        containers:
        - env:
          - name: TZ
            value: America/Chicago
          - name: HOMEBRIDGE_CONFIG_UI
            value: "1"
          - name: HOMEBRIDGE_CONFIG_UI_PORT
            value: "8581"
          - name: HOMEBRIDGE_CONFIG_UI_HOST
            value: 0.0.0.0
          - name: HOMEBRIDGE_DISABLE_IPV6
            value: "1"
          - name: NODE_OPTIONS
            value: --dns-result-order=ipv4first
          - name: HOMEBRIDGE_ADVERTISER
            value: ciao
          - name: HOMEBRIDGE_MDNS_INTERFACE
            value: eth0
          - name: HOMEBRIDGE_ENABLE_IPV6
            value: "0"
          image: homebridge/homebridge:latest
          imagePullPolicy: Always
          name: homebridge
          ports:
          - containerPort: 8581
            name: ui
            protocol: TCP
          - containerPort: 51443
            name: hap
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /homebridge
            name: data
          - mountPath: /etc/avahi/avahi-daemon.conf
            name: avahi-config
            subPath: avahi-daemon.conf
        dnsConfig:
          nameservers:
          - 1.1.1.1
          - 8.8.8.8
        dnsPolicy: ClusterFirstWithHostNet
        hostNetwork: true
        hostname: homebridge
        nodeSelector:
          homekit: bridge
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
        volumes:
        - configMap:
            defaultMode: 420
            name: homebridge-avahi
          name: avahi-config
        - name: data
          persistentVolumeClaim:
            claimName: homebridge-data-longhorn
  status:
    observedGeneration: 3
    replicas: 0
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "1"
      deployment.kubernetes.io/revision: "43"
    creationTimestamp: "2025-11-20T00:46:51Z"
    generation: 2
    labels:
      app: homebridge
      pod-template-hash: 849cc6cb84
    name: homebridge-849cc6cb84
    namespace: suite
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: homebridge
      uid: 8e4a2527-6b40-42c8-b340-b884931ae03c
    resourceVersion: "40082629"
    uid: fd373167-4b1b-4974-afe1-e5d5cc104724
  spec:
    replicas: 0
    selector:
      matchLabels:
        app: homebridge
        pod-template-hash: 849cc6cb84
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-11-19T18:46:50-06:00"
        creationTimestamp: null
        labels:
          app: homebridge
          pod-template-hash: 849cc6cb84
      spec:
        containers:
        - env:
          - name: TZ
            value: America/Chicago
          - name: HOMEBRIDGE_CONFIG_UI
            value: "1"
          - name: HOMEBRIDGE_CONFIG_UI_PORT
            value: "8581"
          - name: HOMEBRIDGE_CONFIG_UI_HOST
            value: 0.0.0.0
          - name: HOMEBRIDGE_DISABLE_IPV6
            value: "1"
          - name: NODE_OPTIONS
            value: --dns-result-order=ipv4first
          - name: HOMEBRIDGE_ADVERTISER
            value: ciao
          - name: HOMEBRIDGE_MDNS_INTERFACE
            value: eth0
          - name: HOMEBRIDGE_ENABLE_IPV6
            value: "0"
          image: homebridge/homebridge:latest
          imagePullPolicy: Always
          name: homebridge
          ports:
          - containerPort: 8581
            name: ui
            protocol: TCP
          - containerPort: 51443
            name: hap
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /homebridge
            name: data
          - mountPath: /etc/avahi/avahi-daemon.conf
            name: avahi-config
            subPath: avahi-daemon.conf
        dnsConfig:
          nameservers:
          - 1.1.1.1
          - 8.8.8.8
        dnsPolicy: ClusterFirstWithHostNet
        hostNetwork: true
        nodeSelector:
          homekit: bridge
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
        volumes:
        - configMap:
            defaultMode: 420
            name: homebridge-avahi
          name: avahi-config
        - name: data
          persistentVolumeClaim:
            claimName: homebridge-data-longhorn
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "1"
      deployment.kubernetes.io/revision: "36"
    creationTimestamp: "2025-11-13T00:08:56Z"
    generation: 2
    labels:
      app: homebridge
      pod-template-hash: 858bd7d7f9
    name: homebridge-858bd7d7f9
    namespace: suite
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: homebridge
      uid: 8e4a2527-6b40-42c8-b340-b884931ae03c
    resourceVersion: "35020249"
    uid: a9b2752e-d830-4266-a1f4-7d6ab4ba4569
  spec:
    replicas: 0
    selector:
      matchLabels:
        app: homebridge
        pod-template-hash: 858bd7d7f9
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-11-12T18:08:52-06:00"
        creationTimestamp: null
        labels:
          app: homebridge
          pod-template-hash: 858bd7d7f9
      spec:
        containers:
        - env:
          - name: TZ
            value: America/Chicago
          - name: HOMEBRIDGE_CONFIG_UI
            value: "1"
          - name: HOMEBRIDGE_CONFIG_UI_PORT
            value: "8581"
          - name: HOMEBRIDGE_CONFIG_UI_HOST
            value: 0.0.0.0
          - name: HOMEBRIDGE_DISABLE_IPV6
            value: "1"
          - name: NODE_OPTIONS
            value: --dns-result-order=ipv4first
          - name: HOMEBRIDGE_ADVERTISER
            value: ciao
          - name: HOMEBRIDGE_MDNS_INTERFACE
            value: eth0
          - name: HOMEBRIDGE_ENABLE_IPV6
            value: "0"
          image: homebridge/homebridge:latest
          imagePullPolicy: Always
          name: homebridge
          ports:
          - containerPort: 8581
            name: ui
            protocol: TCP
          - containerPort: 51443
            name: hap
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /homebridge
            name: data
          - mountPath: /etc/avahi/avahi-daemon.conf
            name: avahi-config
            subPath: avahi-daemon.conf
        dnsConfig:
          nameservers:
          - 1.1.1.1
          - 8.8.8.8
        dnsPolicy: ClusterFirstWithHostNet
        hostNetwork: true
        hostname: homebridge
        nodeSelector:
          homekit: bridge
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
        volumes:
        - configMap:
            defaultMode: 420
            name: homebridge-avahi
          name: avahi-config
        - name: data
          persistentVolumeClaim:
            claimName: homebridge-data-longhorn
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "1"
      deployment.kubernetes.io/revision: "39"
    creationTimestamp: "2025-11-13T14:25:37Z"
    generation: 2
    labels:
      app: homebridge
      pod-template-hash: f8587877
    name: homebridge-f8587877
    namespace: suite
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: homebridge
      uid: 8e4a2527-6b40-42c8-b340-b884931ae03c
    resourceVersion: "35333359"
    uid: eb6fc29a-e815-4a92-942a-73202a034518
  spec:
    replicas: 0
    selector:
      matchLabels:
        app: homebridge
        pod-template-hash: f8587877
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-11-13T08:25:33-06:00"
        creationTimestamp: null
        labels:
          app: homebridge
          pod-template-hash: f8587877
      spec:
        containers:
        - env:
          - name: TZ
            value: America/Chicago
          - name: HOMEBRIDGE_CONFIG_UI
            value: "1"
          - name: HOMEBRIDGE_CONFIG_UI_PORT
            value: "8581"
          - name: HOMEBRIDGE_CONFIG_UI_HOST
            value: 0.0.0.0
          - name: HOMEBRIDGE_DISABLE_IPV6
            value: "1"
          - name: NODE_OPTIONS
            value: --dns-result-order=ipv4first
          - name: HOMEBRIDGE_ADVERTISER
            value: ciao
          - name: HOMEBRIDGE_MDNS_INTERFACE
            value: eth0
          - name: HOMEBRIDGE_ENABLE_IPV6
            value: "0"
          image: homebridge/homebridge:latest
          imagePullPolicy: Always
          name: homebridge
          ports:
          - containerPort: 8581
            name: ui
            protocol: TCP
          - containerPort: 51443
            name: hap
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /homebridge
            name: data
          - mountPath: /etc/avahi/avahi-daemon.conf
            name: avahi-config
            subPath: avahi-daemon.conf
        dnsConfig:
          nameservers:
          - 1.1.1.1
          - 8.8.8.8
        dnsPolicy: ClusterFirst
        nodeSelector:
          homekit: bridge
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
        volumes:
        - configMap:
            defaultMode: 420
            name: homebridge-avahi
          name: avahi-config
        - name: data
          persistentVolumeClaim:
            claimName: homebridge-data-longhorn
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "1"
    creationTimestamp: "2025-11-02T14:51:36Z"
    generation: 1
    labels:
      app: jenkins
      pod-template-hash: 77ffddbfd
    name: jenkins-77ffddbfd
    namespace: suite
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: jenkins
      uid: 1e309af3-2042-40f5-b9e4-9e0c9aa8a8a9
    resourceVersion: "58632888"
    uid: a73adc26-6bc5-415e-87c2-cb9310f1aee2
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: jenkins
        pod-template-hash: 77ffddbfd
    template:
      metadata:
        creationTimestamp: null
        labels:
          app: jenkins
          pod-template-hash: 77ffddbfd
      spec:
        containers:
        - env:
          - name: JAVA_OPTS
            value: -Djenkins.install.runSetupWizard=false
          image: jenkins/jenkins:lts-jdk17
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /login
              port: 8080
              scheme: HTTP
            initialDelaySeconds: 60
            periodSeconds: 20
            successThreshold: 1
            timeoutSeconds: 1
          name: jenkins
          ports:
          - containerPort: 8080
            name: http
            protocol: TCP
          - containerPort: 50000
            name: agent
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /login
              port: 8080
              scheme: HTTP
            initialDelaySeconds: 30
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources:
            limits:
              cpu: "1"
              memory: 2Gi
            requests:
              cpu: 500m
              memory: 1Gi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /var/jenkins_home
            name: jenkins-home
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          fsGroup: 1000
        serviceAccount: jenkins
        serviceAccountName: jenkins
        terminationGracePeriodSeconds: 30
        volumes:
        - name: jenkins-home
          persistentVolumeClaim:
            claimName: jenkins-home
  status:
    fullyLabeledReplicas: 1
    observedGeneration: 1
    replicas: 1
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "1"
    creationTimestamp: "2025-10-28T18:05:03Z"
    generation: 1
    labels:
      allow-egress: internet
      app: magicmirror-app
      pod-template-hash: 79d76f44c
    name: magicmirror-app-79d76f44c
    namespace: suite
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: magicmirror-app
      uid: bcc9f2e9-bafc-4800-9aef-5fb8601ea11e
    resourceVersion: "58635442"
    uid: bdd526ab-4682-4f98-83cf-37bc1778c495
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: magicmirror-app
        pod-template-hash: 79d76f44c
    template:
      metadata:
        creationTimestamp: null
        labels:
          allow-egress: internet
          app: magicmirror-app
          pod-template-hash: 79d76f44c
      spec:
        containers:
        - env:
          - name: MM_CONFIG_FILE
            value: /opt/magic_mirror/config/config.js
          - name: NODE_ENV
            value: production
          image: docker.io/bastilimbach/docker-magicmirror:latest
          imagePullPolicy: Always
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /
              port: http
              scheme: HTTP
            initialDelaySeconds: 25
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 2
          name: magicmirror
          ports:
          - containerPort: 8080
            name: http
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /
              port: http
              scheme: HTTP
            initialDelaySeconds: 12
            periodSeconds: 5
            successThreshold: 1
            timeoutSeconds: 2
          resources:
            limits:
              cpu: 800m
              memory: 512Mi
            requests:
              cpu: 200m
              memory: 256Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /opt/magic_mirror/config/config.js
            name: mm-config
            readOnly: true
            subPath: config.js
          - mountPath: /opt/magic_mirror/modules
            name: modules-work
        dnsPolicy: ClusterFirst
        initContainers:
        - args:
          - |
            set -e
            # Start with image defaults
            cp -a /opt/magic_mirror/modules/. /work/
            mkdir -p /work/custom
            # Merge persisted customs (if any)
            cp -a /persist/. /work/custom/ 2>/dev/null || true
          command:
          - /bin/sh
          - -lc
          image: docker.io/bastilimbach/docker-magicmirror:latest
          imagePullPolicy: IfNotPresent
          name: seed-modules
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /work
            name: modules-work
          - mountPath: /persist
            name: mm-persist
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
        volumes:
        - configMap:
            defaultMode: 420
            name: magicmirror-config
          name: mm-config
        - name: mm-persist
          persistentVolumeClaim:
            claimName: mm-modules-pvc
        - emptyDir: {}
          name: modules-work
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "1"
      deployment.kubernetes.io/revision: "1"
    creationTimestamp: "2025-11-08T02:10:24Z"
    generation: 1
    labels:
      app: magicmirror-server
      pod-template-hash: 5c8f999799
    name: magicmirror-server-5c8f999799
    namespace: suite
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: magicmirror-server
      uid: e432d4fc-6664-4f1a-8eda-709c4ffcde63
    resourceVersion: "51921867"
    uid: f23dea4e-f548-4f64-b518-345a2db8546f
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: magicmirror-server
        pod-template-hash: 5c8f999799
    template:
      metadata:
        creationTimestamp: null
        labels:
          app: magicmirror-server
          pod-template-hash: 5c8f999799
      spec:
        containers:
        - args:
          - npm run server
          command:
          - /bin/sh
          - -lc
          env:
          - name: TZ
            value: America/Chicago
          - name: OPENWEATHER_API_KEY
            valueFrom:
              secretKeyRef:
                key: API_KEY
                name: openweather
          image: docker.io/allenwayne/magicmirror-server:2.32
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /
              port: 8080
              scheme: HTTP
            initialDelaySeconds: 30
            periodSeconds: 20
            successThreshold: 1
            timeoutSeconds: 1
          name: magicmirror
          ports:
          - containerPort: 8080
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /opt/magic_mirror/config/config.js
            name: mm-config
            subPath: config.js
          - mountPath: /opt/magic_mirror/modules
            name: mm-modules
          - mountPath: /opt/magic_mirror/public
            name: mm-public
        dnsPolicy: ClusterFirst
        initContainers:
        - args:
          - |
            set -eux
            rm -rf /work/modules/* /work/public/* || true
            if [ -d /opt/magic_mirror/modules ]; then
              cp -a /opt/magic_mirror/modules/. /work/modules/
            fi
            if [ -d /opt/magic_mirror/public ]; then
              cp -a /opt/magic_mirror/public/. /work/public/
            fi
          command:
          - /bin/sh
          - -lc
          image: docker.io/allenwayne/magicmirror-server:2.32
          imagePullPolicy: IfNotPresent
          name: seed-modules
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /work/modules
            name: mm-modules
          - mountPath: /work/public
            name: mm-public
        - args:
          - echo skipping git-modules; exit 0
          command:
          - /bin/sh
          - -lc
          image: alpine:3.20
          imagePullPolicy: IfNotPresent
          name: git-modules
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /work/modules
            name: mm-modules
          - mountPath: /work/public
            name: mm-public
          - mountPath: /extras
            name: mm-extras
        nodeSelector:
          kubernetes.io/hostname: m3
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
        volumes:
        - configMap:
            defaultMode: 420
            name: magicmirror-config
          name: mm-config
        - emptyDir: {}
          name: mm-modules
        - emptyDir: {}
          name: mm-public
        - configMap:
            defaultMode: 420
            name: magicmirror-extras
          name: mm-extras
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "0"
      deployment.kubernetes.io/max-replicas: "0"
      deployment.kubernetes.io/revision: "22"
    creationTimestamp: "2025-09-19T00:03:37Z"
    generation: 2
    labels:
      app: pihole
      pod-template-hash: 55bfd46cb
    name: pihole-55bfd46cb
    namespace: suite
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: pihole
      uid: c641337e-588b-4870-97a6-eefb0f7cc2d3
    resourceVersion: "22016725"
    uid: 1afbb75d-cf08-41cd-b11a-9ff4a6add362
  spec:
    replicas: 0
    selector:
      matchLabels:
        app: pihole
        pod-template-hash: 55bfd46cb
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-09-14T08:59:17-05:00"
        creationTimestamp: null
        labels:
          app: pihole
          pod-template-hash: 55bfd46cb
      spec:
        containers:
        - env:
          - name: DNSMASQ_LISTENING
            value: all
          - name: ServerIP
            value: 192.168.50.245
          - name: WEB_PORT
            value: "80"
          - name: DNSSEC
            value: "false"
          - name: TZ
            value: America/Chicago
          - name: PIHOLE_DNS_1
            value: 1.1.1.1
          - name: PIHOLE_DNS_2
            value: 9.9.9.9
          - name: FTLCONF_dnsmasq__conf_dir
            value: /etc/dnsmasq.d
          - name: FTLCONF_dnsmasq__addn_hosts
            value: /etc/pihole/custom.list
          - name: FTLCONF_pihole__etc_dnsmasq_d
            value: "true"
          - name: FTLCONF_pihole__dnsmasq_lines
            value: '["address=/suite.home.arpa/192.168.50.242","addn-hosts=/etc/pihole/custom.list"]'
          - name: FTLCONF_webserver_api_password
            value: '@1lSaved'
          image: pihole/pihole:latest
          imagePullPolicy: IfNotPresent
          livenessProbe:
            exec:
              command:
              - sh
              - -lc
              - dig +time=1 +tries=1 @127.0.0.1 pi.hole || exit 1
            failureThreshold: 3
            initialDelaySeconds: 30
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 2
          name: pihole
          ports:
          - containerPort: 53
            name: dns-udp
            protocol: UDP
          - containerPort: 53
            name: dns-tcp
            protocol: TCP
          - containerPort: 80
            name: http
            protocol: TCP
          readinessProbe:
            exec:
              command:
              - sh
              - -lc
              - dig +time=1 +tries=1 @127.0.0.1 pi.hole || exit 1
            failureThreshold: 3
            initialDelaySeconds: 10
            periodSeconds: 5
            successThreshold: 1
            timeoutSeconds: 2
          resources: {}
          startupProbe:
            failureThreshold: 30
            initialDelaySeconds: 10
            periodSeconds: 5
            successThreshold: 1
            tcpSocket:
              port: 53
            timeoutSeconds: 1
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/pihole
            name: etc-pihole
          - mountPath: /etc/dnsmasq.d
            name: etc-dnsmasq
          - mountPath: /etc/dnsmasq.d/01-ui-host.conf
            name: ui-override
            subPath: 01-ui-host.conf
          - mountPath: /etc/dnsmasq.d/02-suite-home-arpa.conf
            name: dnsmasq-cm
            subPath: 02-suite-home-arpa.conf
          - mountPath: /etc/pihole/custom.list
            name: pihole-custom-list
            subPath: custom.list
        dnsPolicy: ClusterFirstWithHostNet
        hostNetwork: true
        nodeSelector:
          kubernetes.io/hostname: m2
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
        volumes:
        - name: etc-pihole
          persistentVolumeClaim:
            claimName: pihole-etc-pihole-pvc
        - name: etc-dnsmasq
          persistentVolumeClaim:
            claimName: pihole-dnsmasq-pvc
        - configMap:
            defaultMode: 420
            name: pihole-dnsmasq
          name: dnsmasq-cm
        - configMap:
            defaultMode: 420
            name: pihole-ui-override
          name: ui-override
        - configMap:
            defaultMode: 420
            name: pihole-custom-list
          name: pihole-custom-list
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "1"
      deployment.kubernetes.io/revision: "29"
    creationTimestamp: "2025-11-15T14:28:31Z"
    generation: 2
    labels:
      app: pihole
      pod-template-hash: 55d9486494
    name: pihole-55d9486494
    namespace: suite
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: pihole
      uid: c641337e-588b-4870-97a6-eefb0f7cc2d3
    resourceVersion: "36366279"
    uid: 99c85560-c999-4397-8560-e0e07f9d31f7
  spec:
    replicas: 0
    selector:
      matchLabels:
        app: pihole
        pod-template-hash: 55d9486494
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-11-15T08:28:00-06:00"
        creationTimestamp: null
        labels:
          app: pihole
          pod-template-hash: 55d9486494
      spec:
        containers:
        - env:
          - name: DNSMASQ_LISTENING
            value: all
          - name: ServerIP
            value: 192.168.50.245
          - name: WEB_PORT
            value: "80"
          - name: PIHOLE_DNS_1
            value: 1.1.1.1
          - name: PIHOLE_DNS_2
            value: 9.9.9.9
          - name: DNSSEC
            value: "false"
          - name: TZ
            value: America/Chicago
          image: pihole/pihole:latest
          imagePullPolicy: Always
          name: pihole
          ports:
          - containerPort: 53
            name: dns-udp
            protocol: UDP
          - containerPort: 53
            name: dns-tcp
            protocol: TCP
          - containerPort: 80
            name: http
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/dnsmasq.d
            name: etc-dnsmasq
          - mountPath: /etc/dnsmasq.d/01-ui-host.conf
            name: ui-override
            subPath: 01-ui-host.conf
          - mountPath: /etc/dnsmasq.d/02-suite-home-arpa.conf
            name: dnsmasq-cm
            subPath: 02-suite-home-arpa.conf
          - mountPath: /etc/dnsmasq.d/03-custom.conf
            name: dnsmasq-custom
            subPath: 03-custom.conf
          - mountPath: /etc/pihole
            name: etc-pihole
        dnsPolicy: ClusterFirst
        nodeSelector:
          kubernetes.io/arch: arm64
          kubernetes.io/hostname: m2
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
        volumes:
        - name: etc-pihole
          persistentVolumeClaim:
            claimName: pihole-etc-pihole-pvc-longhorn
        - name: etc-dnsmasq
          persistentVolumeClaim:
            claimName: pihole-dnsmasq-pvc-longhorn
        - configMap:
            defaultMode: 420
            name: pihole-dnsmasq
          name: dnsmasq-cm
        - configMap:
            defaultMode: 420
            name: pihole-ui-override
          name: ui-override
        - configMap:
            defaultMode: 420
            name: pihole-dnsmasq-custom
          name: dnsmasq-custom
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "1"
      deployment.kubernetes.io/revision: "26"
    creationTimestamp: "2025-11-08T02:10:29Z"
    generation: 2
    labels:
      app: pihole
      pod-template-hash: 656d98765c
    name: pihole-656d98765c
    namespace: suite
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: pihole
      uid: c641337e-588b-4870-97a6-eefb0f7cc2d3
    resourceVersion: "35341264"
    uid: a4cb88a0-cede-46d8-af20-41fe4a4975ef
  spec:
    replicas: 0
    selector:
      matchLabels:
        app: pihole
        pod-template-hash: 656d98765c
    template:
      metadata:
        creationTimestamp: null
        labels:
          app: pihole
          pod-template-hash: 656d98765c
      spec:
        containers:
        - env:
          - name: DNSMASQ_LISTENING
            value: all
          - name: ServerIP
            value: 192.168.50.245
          - name: WEB_PORT
            value: "80"
          - name: PIHOLE_DNS_1
            value: 1.1.1.1
          - name: PIHOLE_DNS_2
            value: 9.9.9.9
          - name: DNSSEC
            value: "false"
          - name: TZ
            value: America/Chicago
          image: pihole/pihole:latest
          imagePullPolicy: Always
          name: pihole
          ports:
          - containerPort: 53
            name: dns-udp
            protocol: UDP
          - containerPort: 53
            name: dns-tcp
            protocol: TCP
          - containerPort: 80
            name: http
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/dnsmasq.d
            name: etc-dnsmasq
          - mountPath: /etc/dnsmasq.d/01-ui-host.conf
            name: ui-override
            subPath: 01-ui-host.conf
          - mountPath: /etc/dnsmasq.d/02-suite-home-arpa.conf
            name: dnsmasq-cm
            subPath: 02-suite-home-arpa.conf
          - mountPath: /etc/dnsmasq.d/03-custom.conf
            name: dnsmasq-custom
            subPath: 03-custom.conf
          - mountPath: /etc/pihole
            name: etc-pihole
        dnsPolicy: ClusterFirst
        nodeSelector:
          kubernetes.io/arch: arm64
          kubernetes.io/hostname: m2
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
        volumes:
        - name: etc-pihole
          persistentVolumeClaim:
            claimName: pihole-etc-pihole-pvc
        - name: etc-dnsmasq
          persistentVolumeClaim:
            claimName: pihole-dnsmasq-pvc
        - configMap:
            defaultMode: 420
            name: pihole-dnsmasq
          name: dnsmasq-cm
        - configMap:
            defaultMode: 420
            name: pihole-ui-override
          name: ui-override
        - configMap:
            defaultMode: 420
            name: pihole-dnsmasq-custom
          name: dnsmasq-custom
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "1"
      deployment.kubernetes.io/revision: "24"
    creationTimestamp: "2025-10-17T13:32:37Z"
    generation: 2
    labels:
      app: pihole
      pod-template-hash: 6b7c88f648
    name: pihole-6b7c88f648
    namespace: suite
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: pihole
      uid: c641337e-588b-4870-97a6-eefb0f7cc2d3
    resourceVersion: "22094674"
    uid: ce80b24d-3389-4b17-ad95-7506d55d9229
  spec:
    replicas: 0
    selector:
      matchLabels:
        app: pihole
        pod-template-hash: 6b7c88f648
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-10-17T08:32:38-05:00"
        creationTimestamp: null
        labels:
          app: pihole
          pod-template-hash: 6b7c88f648
      spec:
        containers:
        - env:
          - name: DNSMASQ_LISTENING
            value: all
          - name: ServerIP
            value: 192.168.50.245
          - name: WEB_PORT
            value: "80"
          - name: DNSSEC
            value: "false"
          - name: TZ
            value: America/Chicago
          - name: PIHOLE_DNS_1
            value: 1.1.1.1
          - name: PIHOLE_DNS_2
            value: 9.9.9.9
          - name: FTLCONF_dnsmasq__conf_dir
            value: /etc/dnsmasq.d
          - name: FTLCONF_dnsmasq__addn_hosts
            value: /etc/pihole/custom.list
          - name: FTLCONF_pihole__etc_dnsmasq_d
            value: "true"
          - name: FTLCONF_pihole__dnsmasq_lines
            value: '["address=/suite.home.arpa/192.168.50.250","addn-hosts=/etc/pihole/custom.list"]'
          - name: FTLCONF_webserver_api_password
            value: '@1lSaved'
          image: pihole/pihole:latest
          imagePullPolicy: IfNotPresent
          livenessProbe:
            exec:
              command:
              - sh
              - -lc
              - dig +time=1 +tries=1 @127.0.0.1 pi.hole || exit 1
            failureThreshold: 3
            initialDelaySeconds: 30
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 2
          name: pihole
          ports:
          - containerPort: 53
            name: dns-udp
            protocol: UDP
          - containerPort: 53
            name: dns-tcp
            protocol: TCP
          - containerPort: 80
            name: http
            protocol: TCP
          readinessProbe:
            exec:
              command:
              - sh
              - -lc
              - dig +time=1 +tries=1 @127.0.0.1 pi.hole || exit 1
            failureThreshold: 3
            initialDelaySeconds: 10
            periodSeconds: 5
            successThreshold: 1
            timeoutSeconds: 2
          resources: {}
          startupProbe:
            failureThreshold: 30
            initialDelaySeconds: 10
            periodSeconds: 5
            successThreshold: 1
            tcpSocket:
              port: 53
            timeoutSeconds: 1
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/pihole
            name: etc-pihole
          - mountPath: /etc/dnsmasq.d
            name: etc-dnsmasq
          - mountPath: /etc/dnsmasq.d/01-ui-host.conf
            name: ui-override
            subPath: 01-ui-host.conf
          - mountPath: /etc/dnsmasq.d/02-suite-home-arpa.conf
            name: dnsmasq-cm
            subPath: 02-suite-home-arpa.conf
          - mountPath: /etc/pihole/custom.list
            name: pihole-custom-list
            subPath: custom.list
        dnsPolicy: ClusterFirstWithHostNet
        hostNetwork: true
        nodeSelector:
          kubernetes.io/hostname: m2
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
        volumes:
        - name: etc-pihole
          persistentVolumeClaim:
            claimName: pihole-etc-pihole-pvc-longhorn
        - name: etc-dnsmasq
          persistentVolumeClaim:
            claimName: pihole-dnsmasq-pvc-longhorn
        - configMap:
            defaultMode: 420
            name: pihole-dnsmasq
          name: dnsmasq-cm
        - configMap:
            defaultMode: 420
            name: pihole-ui-override
          name: ui-override
        - configMap:
            defaultMode: 420
            name: pihole-custom-list
          name: pihole-custom-list
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "1"
      deployment.kubernetes.io/revision: "28"
    creationTimestamp: "2025-11-15T14:27:44Z"
    generation: 2
    labels:
      app: pihole
      pod-template-hash: 6bf65f8f5b
    name: pihole-6bf65f8f5b
    namespace: suite
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: pihole
      uid: c641337e-588b-4870-97a6-eefb0f7cc2d3
    resourceVersion: "36353960"
    uid: 7a8fa882-9892-4c02-8317-e69cc24047b8
  spec:
    replicas: 0
    selector:
      matchLabels:
        app: pihole
        pod-template-hash: 6bf65f8f5b
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-11-13T09:16:35-06:00"
        creationTimestamp: null
        labels:
          app: pihole
          pod-template-hash: 6bf65f8f5b
      spec:
        containers:
        - env:
          - name: DNSMASQ_LISTENING
            value: all
          - name: ServerIP
            value: 192.168.50.245
          - name: WEB_PORT
            value: "80"
          - name: PIHOLE_DNS_1
            value: 1.1.1.1
          - name: PIHOLE_DNS_2
            value: 9.9.9.9
          - name: DNSSEC
            value: "false"
          - name: TZ
            value: America/Chicago
          image: pihole/pihole:latest
          imagePullPolicy: Always
          name: pihole
          ports:
          - containerPort: 53
            name: dns-udp
            protocol: UDP
          - containerPort: 53
            name: dns-tcp
            protocol: TCP
          - containerPort: 80
            name: http
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/dnsmasq.d
            name: etc-dnsmasq
          - mountPath: /etc/dnsmasq.d/01-ui-host.conf
            name: ui-override
            subPath: 01-ui-host.conf
          - mountPath: /etc/dnsmasq.d/02-suite-home-arpa.conf
            name: dnsmasq-cm
            subPath: 02-suite-home-arpa.conf
          - mountPath: /etc/dnsmasq.d/03-custom.conf
            name: dnsmasq-custom
            subPath: 03-custom.conf
          - mountPath: /etc/pihole
            name: etc-pihole
        dnsPolicy: ClusterFirst
        nodeSelector:
          kubernetes.io/arch: arm64
          kubernetes.io/hostname: m2
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
        volumes:
        - name: etc-pihole
          persistentVolumeClaim:
            claimName: pihole-etc-pihole-pvc-longhorn
        - name: etc-dnsmasq
          persistentVolumeClaim:
            claimName: pihole-dnsmasq-pvc-longhorn
        - configMap:
            defaultMode: 420
            name: pihole-dnsmasq
          name: dnsmasq-cm
        - configMap:
            defaultMode: 420
            name: pihole-ui-override
          name: ui-override
        - configMap:
            defaultMode: 420
            name: pihole-dnsmasq-custom
          name: dnsmasq-custom
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "1"
      deployment.kubernetes.io/revision: "21"
    creationTimestamp: "2025-09-14T13:59:21Z"
    generation: 2
    labels:
      app: pihole
      pod-template-hash: 78dc9589f8
    name: pihole-78dc9589f8
    namespace: suite
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: pihole
      uid: c641337e-588b-4870-97a6-eefb0f7cc2d3
    resourceVersion: "9662520"
    uid: 7e5714af-afea-410a-a918-531dad176e53
  spec:
    replicas: 0
    selector:
      matchLabels:
        app: pihole
        pod-template-hash: 78dc9589f8
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-09-14T08:59:17-05:00"
        creationTimestamp: null
        labels:
          app: pihole
          pod-template-hash: 78dc9589f8
      spec:
        containers:
        - env:
          - name: DNSMASQ_LISTENING
            value: all
          - name: ServerIP
            value: 192.168.50.245
          - name: WEB_PORT
            value: "80"
          - name: DNSSEC
            value: "false"
          - name: TZ
            value: America/Chicago
          - name: PIHOLE_DNS_1
            value: 1.1.1.1
          - name: PIHOLE_DNS_2
            value: 9.9.9.9
          - name: FTLCONF_dnsmasq__conf_dir
            value: /etc/dnsmasq.d
          - name: FTLCONF_dnsmasq__addn_hosts
            value: /etc/pihole/custom.list
          - name: FTLCONF_pihole__etc_dnsmasq_d
            value: "true"
          - name: FTLCONF_pihole__dnsmasq_lines
            value: '["address=/suite.home.arpa/192.168.50.242","addn-hosts=/etc/pihole/custom.list"]'
          image: pihole/pihole:latest
          imagePullPolicy: IfNotPresent
          livenessProbe:
            exec:
              command:
              - sh
              - -lc
              - dig +time=1 +tries=1 @127.0.0.1 pi.hole || exit 1
            failureThreshold: 3
            initialDelaySeconds: 30
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 2
          name: pihole
          ports:
          - containerPort: 53
            name: dns-udp
            protocol: UDP
          - containerPort: 53
            name: dns-tcp
            protocol: TCP
          - containerPort: 80
            name: http
            protocol: TCP
          readinessProbe:
            exec:
              command:
              - sh
              - -lc
              - dig +time=1 +tries=1 @127.0.0.1 pi.hole || exit 1
            failureThreshold: 3
            initialDelaySeconds: 10
            periodSeconds: 5
            successThreshold: 1
            timeoutSeconds: 2
          resources: {}
          startupProbe:
            failureThreshold: 30
            initialDelaySeconds: 10
            periodSeconds: 5
            successThreshold: 1
            tcpSocket:
              port: 53
            timeoutSeconds: 1
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/pihole
            name: etc-pihole
          - mountPath: /etc/dnsmasq.d
            name: etc-dnsmasq
          - mountPath: /etc/dnsmasq.d/01-ui-host.conf
            name: ui-override
            subPath: 01-ui-host.conf
          - mountPath: /etc/dnsmasq.d/02-suite-home-arpa.conf
            name: dnsmasq-cm
            subPath: 02-suite-home-arpa.conf
          - mountPath: /etc/pihole/custom.list
            name: pihole-custom-list
            subPath: custom.list
        dnsPolicy: ClusterFirstWithHostNet
        hostNetwork: true
        nodeSelector:
          kubernetes.io/hostname: m2
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
        volumes:
        - name: etc-pihole
          persistentVolumeClaim:
            claimName: pihole-etc-pihole-pvc
        - name: etc-dnsmasq
          persistentVolumeClaim:
            claimName: pihole-dnsmasq-pvc
        - configMap:
            defaultMode: 420
            name: pihole-dnsmasq
          name: dnsmasq-cm
        - configMap:
            defaultMode: 420
            name: pihole-ui-override
          name: ui-override
        - configMap:
            defaultMode: 420
            name: pihole-custom-list
          name: pihole-custom-list
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "1"
      deployment.kubernetes.io/revision: "25"
    creationTimestamp: "2025-10-17T16:56:04Z"
    generation: 2
    labels:
      app: pihole
      pod-template-hash: 7c84589945
    name: pihole-7c84589945
    namespace: suite
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: pihole
      uid: c641337e-588b-4870-97a6-eefb0f7cc2d3
    resourceVersion: "32567703"
    uid: 1336bb0b-ca79-4613-bce7-3d0fc395b068
  spec:
    replicas: 0
    selector:
      matchLabels:
        app: pihole
        pod-template-hash: 7c84589945
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-10-17T11:56:06-05:00"
        creationTimestamp: null
        labels:
          app: pihole
          pod-template-hash: 7c84589945
      spec:
        containers:
        - env:
          - name: DNSMASQ_LISTENING
            value: all
          - name: ServerIP
            value: 192.168.50.245
          - name: WEB_PORT
            value: "80"
          - name: DNSSEC
            value: "false"
          - name: TZ
            value: America/Chicago
          - name: PIHOLE_DNS_1
            value: 1.1.1.1
          - name: PIHOLE_DNS_2
            value: 9.9.9.9
          - name: FTLCONF_dnsmasq__conf_dir
            value: /etc/dnsmasq.d
          - name: FTLCONF_dnsmasq__addn_hosts
            value: /etc/pihole/custom.list
          - name: FTLCONF_pihole__etc_dnsmasq_d
            value: "true"
          - name: FTLCONF_pihole__dnsmasq_lines
            value: '["address=/suite.home.arpa/192.168.50.250","addn-hosts=/etc/pihole/custom.list"]'
          - name: FTLCONF_webserver_api_password
            value: '@1lSaved'
          image: pihole/pihole:latest
          imagePullPolicy: IfNotPresent
          livenessProbe:
            exec:
              command:
              - sh
              - -lc
              - dig +time=1 +tries=1 @127.0.0.1 pi.hole || exit 1
            failureThreshold: 3
            initialDelaySeconds: 30
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 2
          name: pihole
          ports:
          - containerPort: 53
            name: dns-udp
            protocol: UDP
          - containerPort: 53
            name: dns-tcp
            protocol: TCP
          - containerPort: 80
            name: http
            protocol: TCP
          readinessProbe:
            exec:
              command:
              - sh
              - -lc
              - dig +time=1 +tries=1 @127.0.0.1 pi.hole || exit 1
            failureThreshold: 3
            initialDelaySeconds: 10
            periodSeconds: 5
            successThreshold: 1
            timeoutSeconds: 2
          resources: {}
          startupProbe:
            failureThreshold: 30
            initialDelaySeconds: 10
            periodSeconds: 5
            successThreshold: 1
            tcpSocket:
              port: 53
            timeoutSeconds: 1
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/pihole
            name: etc-pihole
          - mountPath: /etc/dnsmasq.d
            name: etc-dnsmasq
          - mountPath: /etc/dnsmasq.d/01-ui-host.conf
            name: ui-override
            subPath: 01-ui-host.conf
          - mountPath: /etc/dnsmasq.d/02-suite-home-arpa.conf
            name: dnsmasq-cm
            subPath: 02-suite-home-arpa.conf
          - mountPath: /etc/pihole/custom.list
            name: pihole-custom-list
            subPath: custom.list
        dnsPolicy: ClusterFirstWithHostNet
        hostNetwork: true
        nodeSelector:
          kubernetes.io/hostname: m2
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
        volumes:
        - name: etc-pihole
          persistentVolumeClaim:
            claimName: pihole-etc-pihole-pvc-longhorn
        - name: etc-dnsmasq
          persistentVolumeClaim:
            claimName: pihole-dnsmasq-pvc-longhorn
        - configMap:
            defaultMode: 420
            name: pihole-dnsmasq
          name: dnsmasq-cm
        - configMap:
            defaultMode: 420
            name: pihole-ui-override
          name: ui-override
        - configMap:
            defaultMode: 420
            name: pihole-custom-list
          name: pihole-custom-list
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "1"
      deployment.kubernetes.io/revision: "31"
    creationTimestamp: "2025-12-10T15:43:18Z"
    generation: 1
    labels:
      app: pihole
      pod-template-hash: 7cbbb589c4
    name: pihole-7cbbb589c4
    namespace: suite
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: pihole
      uid: c641337e-588b-4870-97a6-eefb0f7cc2d3
    resourceVersion: "58633149"
    uid: afb6b86c-7341-413a-8a65-d8fb7e425e55
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: pihole
        pod-template-hash: 7cbbb589c4
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-12-10T09:43:15-06:00"
        creationTimestamp: null
        labels:
          app: pihole
          pod-template-hash: 7cbbb589c4
      spec:
        containers:
        - env:
          - name: DNSMASQ_LISTENING
            value: all
          - name: ServerIP
            value: 192.168.50.245
          - name: WEB_PORT
            value: "80"
          - name: PIHOLE_DNS_1
            value: 1.1.1.1
          - name: PIHOLE_DNS_2
            value: 9.9.9.9
          - name: DNSSEC
            value: "false"
          - name: TZ
            value: America/Chicago
          image: pihole/pihole:latest
          imagePullPolicy: Always
          name: pihole
          ports:
          - containerPort: 53
            name: dns-udp
            protocol: UDP
          - containerPort: 53
            name: dns-tcp
            protocol: TCP
          - containerPort: 80
            name: http
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/dnsmasq.d
            name: etc-dnsmasq
          - mountPath: /etc/dnsmasq.d/01-ui-host.conf
            name: ui-override
            subPath: 01-ui-host.conf
          - mountPath: /etc/dnsmasq.d/02-suite-home-arpa.conf
            name: dnsmasq-cm
            subPath: 02-suite-home-arpa.conf
          - mountPath: /etc/dnsmasq.d/03-custom.conf
            name: dnsmasq-custom
            subPath: 03-custom.conf
          - mountPath: /etc/pihole
            name: etc-pihole
        dnsPolicy: ClusterFirst
        nodeSelector:
          kubernetes.io/arch: arm64
          kubernetes.io/hostname: m2
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
        volumes:
        - name: etc-pihole
          persistentVolumeClaim:
            claimName: pihole-etc-pihole-pvc-longhorn
        - name: etc-dnsmasq
          persistentVolumeClaim:
            claimName: pihole-dnsmasq-pvc-longhorn
        - configMap:
            defaultMode: 420
            name: pihole-dnsmasq
          name: dnsmasq-cm
        - configMap:
            defaultMode: 420
            name: pihole-ui-override
          name: ui-override
        - configMap:
            defaultMode: 420
            name: pihole-dnsmasq-custom
          name: dnsmasq-custom
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "1"
      deployment.kubernetes.io/revision: "23"
    creationTimestamp: "2025-10-17T13:12:00Z"
    generation: 3
    labels:
      app: pihole
      pod-template-hash: 854c665bc6
    name: pihole-854c665bc6
    namespace: suite
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: pihole
      uid: c641337e-588b-4870-97a6-eefb0f7cc2d3
    resourceVersion: "22024044"
    uid: d7e0dff3-a6be-4700-a6f3-37b8d2a0e082
  spec:
    replicas: 0
    selector:
      matchLabels:
        app: pihole
        pod-template-hash: 854c665bc6
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-09-14T08:59:17-05:00"
        creationTimestamp: null
        labels:
          app: pihole
          pod-template-hash: 854c665bc6
      spec:
        containers:
        - env:
          - name: DNSMASQ_LISTENING
            value: all
          - name: ServerIP
            value: 192.168.50.245
          - name: WEB_PORT
            value: "80"
          - name: DNSSEC
            value: "false"
          - name: TZ
            value: America/Chicago
          - name: PIHOLE_DNS_1
            value: 1.1.1.1
          - name: PIHOLE_DNS_2
            value: 9.9.9.9
          - name: FTLCONF_dnsmasq__conf_dir
            value: /etc/dnsmasq.d
          - name: FTLCONF_dnsmasq__addn_hosts
            value: /etc/pihole/custom.list
          - name: FTLCONF_pihole__etc_dnsmasq_d
            value: "true"
          - name: FTLCONF_pihole__dnsmasq_lines
            value: '["address=/suite.home.arpa/192.168.50.242","addn-hosts=/etc/pihole/custom.list"]'
          - name: FTLCONF_webserver_api_password
            value: '@1lSaved'
          image: pihole/pihole:latest
          imagePullPolicy: IfNotPresent
          livenessProbe:
            exec:
              command:
              - sh
              - -lc
              - dig +time=1 +tries=1 @127.0.0.1 pi.hole || exit 1
            failureThreshold: 3
            initialDelaySeconds: 30
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 2
          name: pihole
          ports:
          - containerPort: 53
            name: dns-udp
            protocol: UDP
          - containerPort: 53
            name: dns-tcp
            protocol: TCP
          - containerPort: 80
            name: http
            protocol: TCP
          readinessProbe:
            exec:
              command:
              - sh
              - -lc
              - dig +time=1 +tries=1 @127.0.0.1 pi.hole || exit 1
            failureThreshold: 3
            initialDelaySeconds: 10
            periodSeconds: 5
            successThreshold: 1
            timeoutSeconds: 2
          resources: {}
          startupProbe:
            failureThreshold: 30
            initialDelaySeconds: 10
            periodSeconds: 5
            successThreshold: 1
            tcpSocket:
              port: 53
            timeoutSeconds: 1
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/pihole
            name: etc-pihole
          - mountPath: /etc/dnsmasq.d
            name: etc-dnsmasq
          - mountPath: /etc/dnsmasq.d/01-ui-host.conf
            name: ui-override
            subPath: 01-ui-host.conf
          - mountPath: /etc/dnsmasq.d/02-suite-home-arpa.conf
            name: dnsmasq-cm
            subPath: 02-suite-home-arpa.conf
          - mountPath: /etc/pihole/custom.list
            name: pihole-custom-list
            subPath: custom.list
        dnsPolicy: ClusterFirstWithHostNet
        hostNetwork: true
        nodeSelector:
          kubernetes.io/hostname: m2
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
        volumes:
        - name: etc-pihole
          persistentVolumeClaim:
            claimName: pihole-etc-pihole-pvc-longhorn
        - name: etc-dnsmasq
          persistentVolumeClaim:
            claimName: pihole-dnsmasq-pvc-longhorn
        - configMap:
            defaultMode: 420
            name: pihole-dnsmasq
          name: dnsmasq-cm
        - configMap:
            defaultMode: 420
            name: pihole-ui-override
          name: ui-override
        - configMap:
            defaultMode: 420
            name: pihole-custom-list
          name: pihole-custom-list
  status:
    observedGeneration: 3
    replicas: 0
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "1"
      deployment.kubernetes.io/revision: "27"
    creationTimestamp: "2025-11-13T15:16:38Z"
    generation: 2
    labels:
      app: pihole
      pod-template-hash: 864d7444c6
    name: pihole-864d7444c6
    namespace: suite
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: pihole
      uid: c641337e-588b-4870-97a6-eefb0f7cc2d3
    resourceVersion: "36353722"
    uid: 8b80247e-fb2b-443b-ae1f-4044d5079bde
  spec:
    replicas: 0
    selector:
      matchLabels:
        app: pihole
        pod-template-hash: 864d7444c6
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-11-13T09:16:35-06:00"
        creationTimestamp: null
        labels:
          app: pihole
          pod-template-hash: 864d7444c6
      spec:
        containers:
        - env:
          - name: DNSMASQ_LISTENING
            value: all
          - name: ServerIP
            value: 192.168.50.245
          - name: WEB_PORT
            value: "80"
          - name: PIHOLE_DNS_1
            value: 1.1.1.1
          - name: PIHOLE_DNS_2
            value: 9.9.9.9
          - name: DNSSEC
            value: "false"
          - name: TZ
            value: America/Chicago
          image: pihole/pihole:latest
          imagePullPolicy: Always
          name: pihole
          ports:
          - containerPort: 53
            name: dns-udp
            protocol: UDP
          - containerPort: 53
            name: dns-tcp
            protocol: TCP
          - containerPort: 80
            name: http
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/dnsmasq.d
            name: etc-dnsmasq
          - mountPath: /etc/dnsmasq.d/01-ui-host.conf
            name: ui-override
            subPath: 01-ui-host.conf
          - mountPath: /etc/dnsmasq.d/02-suite-home-arpa.conf
            name: dnsmasq-cm
            subPath: 02-suite-home-arpa.conf
          - mountPath: /etc/dnsmasq.d/03-custom.conf
            name: dnsmasq-custom
            subPath: 03-custom.conf
          - mountPath: /etc/pihole
            name: etc-pihole
        dnsPolicy: ClusterFirst
        nodeSelector:
          kubernetes.io/arch: arm64
          kubernetes.io/hostname: m2
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
        volumes:
        - name: etc-pihole
          persistentVolumeClaim:
            claimName: pihole-etc-pihole-pvc
        - name: etc-dnsmasq
          persistentVolumeClaim:
            claimName: pihole-dnsmasq-pvc
        - configMap:
            defaultMode: 420
            name: pihole-dnsmasq
          name: dnsmasq-cm
        - configMap:
            defaultMode: 420
            name: pihole-ui-override
          name: ui-override
        - configMap:
            defaultMode: 420
            name: pihole-dnsmasq-custom
          name: dnsmasq-custom
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "1"
      deployment.kubernetes.io/revision: "30"
    creationTimestamp: "2025-11-15T15:02:17Z"
    generation: 2
    labels:
      app: pihole
      pod-template-hash: dd4df85d
    name: pihole-dd4df85d
    namespace: suite
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: pihole
      uid: c641337e-588b-4870-97a6-eefb0f7cc2d3
    resourceVersion: "49655170"
    uid: 770bc42b-6c61-4b59-8970-ea9b8a738b7f
  spec:
    replicas: 0
    selector:
      matchLabels:
        app: pihole
        pod-template-hash: dd4df85d
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-11-15T09:02:01-06:00"
        creationTimestamp: null
        labels:
          app: pihole
          pod-template-hash: dd4df85d
      spec:
        containers:
        - env:
          - name: DNSMASQ_LISTENING
            value: all
          - name: ServerIP
            value: 192.168.50.245
          - name: WEB_PORT
            value: "80"
          - name: PIHOLE_DNS_1
            value: 1.1.1.1
          - name: PIHOLE_DNS_2
            value: 9.9.9.9
          - name: DNSSEC
            value: "false"
          - name: TZ
            value: America/Chicago
          image: pihole/pihole:latest
          imagePullPolicy: Always
          name: pihole
          ports:
          - containerPort: 53
            name: dns-udp
            protocol: UDP
          - containerPort: 53
            name: dns-tcp
            protocol: TCP
          - containerPort: 80
            name: http
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/dnsmasq.d
            name: etc-dnsmasq
          - mountPath: /etc/dnsmasq.d/01-ui-host.conf
            name: ui-override
            subPath: 01-ui-host.conf
          - mountPath: /etc/dnsmasq.d/02-suite-home-arpa.conf
            name: dnsmasq-cm
            subPath: 02-suite-home-arpa.conf
          - mountPath: /etc/dnsmasq.d/03-custom.conf
            name: dnsmasq-custom
            subPath: 03-custom.conf
          - mountPath: /etc/pihole
            name: etc-pihole
        dnsPolicy: ClusterFirst
        nodeSelector:
          kubernetes.io/arch: arm64
          kubernetes.io/hostname: m2
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
        volumes:
        - name: etc-pihole
          persistentVolumeClaim:
            claimName: pihole-etc-pihole-pvc-longhorn
        - name: etc-dnsmasq
          persistentVolumeClaim:
            claimName: pihole-dnsmasq-pvc-longhorn
        - configMap:
            defaultMode: 420
            name: pihole-dnsmasq
          name: dnsmasq-cm
        - configMap:
            defaultMode: 420
            name: pihole-ui-override
          name: ui-override
        - configMap:
            defaultMode: 420
            name: pihole-dnsmasq-custom
          name: dnsmasq-custom
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "15"
      meta.helm.sh/release-name: suite-command-center
      meta.helm.sh/release-namespace: suite
    creationTimestamp: "2025-12-25T15:56:03Z"
    generation: 2
    labels:
      app: suite-command-center-api
      app.kubernetes.io/instance: suite-command-center
      app.kubernetes.io/name: suite-command-center
      pod-template-hash: 599bbf489c
    name: suite-command-center-api-599bbf489c
    namespace: suite
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: suite-command-center-api
      uid: 3ce9cd02-afeb-4c08-b60d-62d132e28a0b
    resourceVersion: "57632922"
    uid: 81e9238e-e911-4588-a89b-b9a37617da54
  spec:
    replicas: 0
    selector:
      matchLabels:
        app: suite-command-center-api
        pod-template-hash: 599bbf489c
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-12-25T09:56:03-06:00"
        creationTimestamp: null
        labels:
          app: suite-command-center-api
          app.kubernetes.io/instance: suite-command-center
          app.kubernetes.io/name: suite-command-center
          pod-template-hash: 599bbf489c
      spec:
        automountServiceAccountToken: true
        containers:
        - env:
          - name: MQTT_ENABLED
            value: "false"
          - name: MQTT_BROKER_URL
            value: mqtt://mosquitto.suite.svc.cluster.local:1883
          - name: MQTT_TOPIC_PREFIX
            value: suite/sensors/#
          - name: NO_PROXY
            value: 127.0.0.1,localhost,192.168.50.251,192.168.50.2,192.168.50.3,192.168.50.6,10.0.0.0/8,10.42.0.0/16,10.43.0.0/16,.svc,.svc.cluster.local,.cluster.local
          image: registry.suite.home.arpa:5000/suite-command-center-api:latest
          imagePullPolicy: Always
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: 8000
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 20
            successThreshold: 1
            timeoutSeconds: 1
          name: api
          ports:
          - containerPort: 8000
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: 8000
              scheme: HTTP
            initialDelaySeconds: 3
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        nodeSelector:
          kubernetes.io/hostname: m1
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: suite-command-center-api
        serviceAccountName: suite-command-center-api
        terminationGracePeriodSeconds: 30
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "14"
      meta.helm.sh/release-name: suite-command-center
      meta.helm.sh/release-namespace: suite
    creationTimestamp: "2025-12-25T15:47:11Z"
    generation: 2
    labels:
      app: suite-command-center-api
      app.kubernetes.io/instance: suite-command-center
      app.kubernetes.io/name: suite-command-center
      pod-template-hash: 686b4547c8
    name: suite-command-center-api-686b4547c8
    namespace: suite
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: suite-command-center-api
      uid: 3ce9cd02-afeb-4c08-b60d-62d132e28a0b
    resourceVersion: "57630240"
    uid: d00abede-90a9-4804-9a05-cd1821fc2fa8
  spec:
    replicas: 0
    selector:
      matchLabels:
        app: suite-command-center-api
        pod-template-hash: 686b4547c8
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-12-25T09:47:11-06:00"
        creationTimestamp: null
        labels:
          app: suite-command-center-api
          app.kubernetes.io/instance: suite-command-center
          app.kubernetes.io/name: suite-command-center
          pod-template-hash: 686b4547c8
      spec:
        automountServiceAccountToken: true
        containers:
        - env:
          - name: MQTT_ENABLED
            value: "false"
          - name: MQTT_BROKER_URL
            value: mqtt://mosquitto.suite.svc.cluster.local:1883
          - name: MQTT_TOPIC_PREFIX
            value: suite/sensors/#
          - name: NO_PROXY
            value: 127.0.0.1,localhost,192.168.50.251,192.168.50.2,192.168.50.3,192.168.50.6,10.0.0.0/8,10.42.0.0/16,10.43.0.0/16,.svc,.svc.cluster.local,.cluster.local
          image: registry.suite.home.arpa:5000/suite-command-center-api:latest
          imagePullPolicy: Always
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: 8000
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 20
            successThreshold: 1
            timeoutSeconds: 1
          name: api
          ports:
          - containerPort: 8000
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: 8000
              scheme: HTTP
            initialDelaySeconds: 3
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        nodeSelector:
          kubernetes.io/hostname: m1
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: suite-command-center-api
        serviceAccountName: suite-command-center-api
        terminationGracePeriodSeconds: 30
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "17"
      meta.helm.sh/release-name: suite-command-center
      meta.helm.sh/release-namespace: suite
    creationTimestamp: "2025-12-25T16:15:18Z"
    generation: 2
    labels:
      app: suite-command-center-api
      app.kubernetes.io/instance: suite-command-center
      app.kubernetes.io/name: suite-command-center
      pod-template-hash: 68d48bd44c
    name: suite-command-center-api-68d48bd44c
    namespace: suite
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: suite-command-center-api
      uid: 3ce9cd02-afeb-4c08-b60d-62d132e28a0b
    resourceVersion: "57637351"
    uid: 1a3ac6b6-a356-4a2a-ad4a-a321e0ce6650
  spec:
    replicas: 0
    selector:
      matchLabels:
        app: suite-command-center-api
        pod-template-hash: 68d48bd44c
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-12-25T10:03:15-06:00"
        creationTimestamp: null
        labels:
          app: suite-command-center-api
          app.kubernetes.io/instance: suite-command-center
          app.kubernetes.io/name: suite-command-center
          pod-template-hash: 68d48bd44c
      spec:
        automountServiceAccountToken: true
        containers:
        - env:
          - name: MQTT_ENABLED
            value: "false"
          - name: MQTT_BROKER_URL
            value: mqtt://mosquitto.suite.svc.cluster.local:1883
          - name: MQTT_TOPIC_PREFIX
            value: suite/sensors/#
          - name: NO_PROXY
            value: 127.0.0.1,localhost,192.168.50.251,192.168.50.2,192.168.50.3,192.168.50.6,10.0.0.0/8,10.42.0.0/16,10.43.0.0/16,.svc,.svc.cluster.local,.cluster.local
          image: registry.suite.home.arpa:5000/suite-command-center-api:latest
          imagePullPolicy: Always
          livenessProbe:
            failureThreshold: 6
            httpGet:
              path: /healthz
              port: 8000
              scheme: HTTP
            initialDelaySeconds: 20
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 2
          name: api
          ports:
          - containerPort: 8000
            protocol: TCP
          readinessProbe:
            failureThreshold: 12
            httpGet:
              path: /healthz
              port: 8000
              scheme: HTTP
            initialDelaySeconds: 2
            periodSeconds: 5
            successThreshold: 1
            timeoutSeconds: 2
          resources: {}
          startupProbe:
            failureThreshold: 60
            httpGet:
              path: /healthz
              port: 8000
              scheme: HTTP
            periodSeconds: 2
            successThreshold: 1
            timeoutSeconds: 2
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        nodeSelector:
          kubernetes.io/hostname: m1
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: suite-command-center-api
        serviceAccountName: suite-command-center-api
        terminationGracePeriodSeconds: 30
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "13"
      meta.helm.sh/release-name: suite-command-center
      meta.helm.sh/release-namespace: suite
    creationTimestamp: "2025-12-25T00:48:49Z"
    generation: 2
    labels:
      app: suite-command-center-api
      app.kubernetes.io/instance: suite-command-center
      app.kubernetes.io/name: suite-command-center
      pod-template-hash: 6c4965b57
    name: suite-command-center-api-6c4965b57
    namespace: suite
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: suite-command-center-api
      uid: 3ce9cd02-afeb-4c08-b60d-62d132e28a0b
    resourceVersion: "57626841"
    uid: 4a82f1a4-21e3-4b96-b2f0-cf61bd101fa7
  spec:
    replicas: 0
    selector:
      matchLabels:
        app: suite-command-center-api
        pod-template-hash: 6c4965b57
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-12-24T18:13:12-06:00"
        creationTimestamp: null
        labels:
          app: suite-command-center-api
          app.kubernetes.io/instance: suite-command-center
          app.kubernetes.io/name: suite-command-center
          pod-template-hash: 6c4965b57
      spec:
        automountServiceAccountToken: true
        containers:
        - env:
          - name: MQTT_ENABLED
            value: "false"
          - name: MQTT_BROKER_URL
            value: mqtt://mosquitto.suite.svc.cluster.local:1883
          - name: MQTT_TOPIC_PREFIX
            value: suite/sensors/#
          - name: NO_PROXY
            value: 127.0.0.1,localhost,192.168.50.251,192.168.50.2,192.168.50.3,192.168.50.6,10.0.0.0/8,10.42.0.0/16,10.43.0.0/16,.svc,.svc.cluster.local,.cluster.local
          image: registry.suite.home.arpa:5000/suite-command-center-api:latest
          imagePullPolicy: Always
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: 8000
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 20
            successThreshold: 1
            timeoutSeconds: 1
          name: api
          ports:
          - containerPort: 8000
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: 8000
              scheme: HTTP
            initialDelaySeconds: 3
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        nodeSelector:
          kubernetes.io/hostname: m1
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: suite-command-center-api
        serviceAccountName: suite-command-center-api
        terminationGracePeriodSeconds: 30
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "20"
      meta.helm.sh/release-name: suite-command-center
      meta.helm.sh/release-namespace: suite
    creationTimestamp: "2025-12-26T23:14:04Z"
    generation: 2
    labels:
      app: suite-command-center-api
      app.kubernetes.io/instance: suite-command-center
      app.kubernetes.io/name: suite-command-center
      pod-template-hash: 6f754b7967
    name: suite-command-center-api-6f754b7967
    namespace: suite
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: suite-command-center-api
      uid: 3ce9cd02-afeb-4c08-b60d-62d132e28a0b
    resourceVersion: "59996507"
    uid: 5bfcfc24-d3e4-4162-afaa-07f9f8f11933
  spec:
    replicas: 0
    selector:
      matchLabels:
        app: suite-command-center-api
        pod-template-hash: 6f754b7967
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-12-25T10:15:18-06:00"
        creationTimestamp: null
        labels:
          app: suite-command-center-api
          app.kubernetes.io/instance: suite-command-center
          app.kubernetes.io/name: suite-command-center
          pod-template-hash: 6f754b7967
      spec:
        automountServiceAccountToken: true
        containers:
        - env:
          - name: MQTT_ENABLED
            value: "false"
          - name: MQTT_BROKER_URL
            value: mqtt://mosquitto.suite.svc.cluster.local:1883
          - name: MQTT_TOPIC_PREFIX
            value: suite/sensors/#
          - name: NO_PROXY
            value: 127.0.0.1,localhost,192.168.50.251,192.168.50.2,192.168.50.3,192.168.50.6,10.0.0.0/8,10.42.0.0/16,10.43.0.0/16,.svc,.svc.cluster.local,.cluster.local
          image: registry.suite.home.arpa:5000/suite-command-center-api@sha256:dc7a0fb55bc9d747fab07121c24ffd73f1ea2b58ce4bd6329f53d9326b8bdd74
          imagePullPolicy: Always
          livenessProbe:
            failureThreshold: 6
            httpGet:
              path: /healthz
              port: 8000
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 20
            successThreshold: 1
            timeoutSeconds: 2
          name: api
          ports:
          - containerPort: 8000
            protocol: TCP
          readinessProbe:
            failureThreshold: 12
            httpGet:
              path: /healthz
              port: 8000
              scheme: HTTP
            initialDelaySeconds: 3
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 2
          resources: {}
          startupProbe:
            failureThreshold: 60
            httpGet:
              path: /healthz
              port: 8000
              scheme: HTTP
            periodSeconds: 2
            successThreshold: 1
            timeoutSeconds: 2
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        nodeSelector:
          kubernetes.io/hostname: m1
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: suite-command-center-api
        serviceAccountName: suite-command-center-api
        terminationGracePeriodSeconds: 30
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "22"
      meta.helm.sh/release-name: suite-command-center
      meta.helm.sh/release-namespace: suite
    creationTimestamp: "2025-12-29T17:07:07Z"
    generation: 1
    labels:
      app: suite-command-center-api
      pod-template-hash: 7455994f75
    name: suite-command-center-api-7455994f75
    namespace: suite
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: suite-command-center-api
      uid: 3ce9cd02-afeb-4c08-b60d-62d132e28a0b
    resourceVersion: "59996581"
    uid: c6dd0ff0-318b-40dd-a166-ec35e6a7110a
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: suite-command-center-api
        pod-template-hash: 7455994f75
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-12-29T11:07:10-06:00"
        creationTimestamp: null
        labels:
          app: suite-command-center-api
          pod-template-hash: 7455994f75
      spec:
        automountServiceAccountToken: true
        containers:
        - env:
          - name: NO_PROXY
            value: 127.0.0.1,localhost,192.168.50.251,192.168.50.2,192.168.50.3,192.168.50.6,10.0.0.0/8,10.42.0.0/16,10.43.0.0/16,.svc,.svc.cluster.local,.cluster.local
          - name: PORT
            value: "8000"
          image: registry.suite.home.arpa:5000/suite-command-center-api:latest
          imagePullPolicy: Always
          name: api
          ports:
          - containerPort: 8000
            protocol: TCP
          resources: {}
          startupProbe:
            failureThreshold: 60
            httpGet:
              path: /healthz
              port: 8000
              scheme: HTTP
            periodSeconds: 2
            successThreshold: 1
            timeoutSeconds: 2
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        nodeSelector:
          kubernetes.io/hostname: m1
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: suite-command-center-api
        serviceAccountName: suite-command-center-api
        terminationGracePeriodSeconds: 30
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "12"
    creationTimestamp: "2025-12-25T00:13:12Z"
    generation: 2
    labels:
      app: suite-command-center-api
      pod-template-hash: 747d4fc5b9
    name: suite-command-center-api-747d4fc5b9
    namespace: suite
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: suite-command-center-api
      uid: 3ce9cd02-afeb-4c08-b60d-62d132e28a0b
    resourceVersion: "57290613"
    uid: f766021b-e2dd-4d0d-883a-c7a9a93f36c6
  spec:
    replicas: 0
    selector:
      matchLabels:
        app: suite-command-center-api
        pod-template-hash: 747d4fc5b9
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-12-24T18:13:12-06:00"
        creationTimestamp: null
        labels:
          app: suite-command-center-api
          pod-template-hash: 747d4fc5b9
      spec:
        automountServiceAccountToken: true
        containers:
        - env:
          - name: NO_PROXY
            value: 127.0.0.1,localhost,192.168.50.251,192.168.50.2,192.168.50.3,192.168.50.6,10.0.0.0/8,10.42.0.0/16,10.43.0.0/16,.svc,.svc.cluster.local,.cluster.local
          image: registry.suite.home.arpa:5000/suite-command-center-api:latest
          imagePullPolicy: Always
          name: api
          ports:
          - containerPort: 8000
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        nodeSelector:
          kubernetes.io/hostname: m1
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: suite-command-center
        serviceAccountName: suite-command-center
        terminationGracePeriodSeconds: 30
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "16"
      meta.helm.sh/release-name: suite-command-center
      meta.helm.sh/release-namespace: suite
    creationTimestamp: "2025-12-25T16:03:15Z"
    generation: 2
    labels:
      app: suite-command-center-api
      app.kubernetes.io/instance: suite-command-center
      app.kubernetes.io/name: suite-command-center
      pod-template-hash: 7874995c8d
    name: suite-command-center-api-7874995c8d
    namespace: suite
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: suite-command-center-api
      uid: 3ce9cd02-afeb-4c08-b60d-62d132e28a0b
    resourceVersion: "57637412"
    uid: 8ddea8cc-b5c5-49bd-96d9-854d29ec1fe5
  spec:
    replicas: 0
    selector:
      matchLabels:
        app: suite-command-center-api
        pod-template-hash: 7874995c8d
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-12-25T10:03:15-06:00"
        creationTimestamp: null
        labels:
          app: suite-command-center-api
          app.kubernetes.io/instance: suite-command-center
          app.kubernetes.io/name: suite-command-center
          pod-template-hash: 7874995c8d
      spec:
        automountServiceAccountToken: true
        containers:
        - env:
          - name: MQTT_ENABLED
            value: "false"
          - name: MQTT_BROKER_URL
            value: mqtt://mosquitto.suite.svc.cluster.local:1883
          - name: MQTT_TOPIC_PREFIX
            value: suite/sensors/#
          - name: NO_PROXY
            value: 127.0.0.1,localhost,192.168.50.251,192.168.50.2,192.168.50.3,192.168.50.6,10.0.0.0/8,10.42.0.0/16,10.43.0.0/16,.svc,.svc.cluster.local,.cluster.local
          image: registry.suite.home.arpa:5000/suite-command-center-api:latest
          imagePullPolicy: Always
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: 8000
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 20
            successThreshold: 1
            timeoutSeconds: 1
          name: api
          ports:
          - containerPort: 8000
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: 8000
              scheme: HTTP
            initialDelaySeconds: 3
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        nodeSelector:
          kubernetes.io/hostname: m1
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: suite-command-center-api
        serviceAccountName: suite-command-center-api
        terminationGracePeriodSeconds: 30
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "21"
      meta.helm.sh/release-name: suite-command-center
      meta.helm.sh/release-namespace: suite
    creationTimestamp: "2025-12-27T22:42:11Z"
    generation: 2
    labels:
      app: suite-command-center-api
      pod-template-hash: 79c8d8f6d9
    name: suite-command-center-api-79c8d8f6d9
    namespace: suite
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: suite-command-center-api
      uid: 3ce9cd02-afeb-4c08-b60d-62d132e28a0b
    resourceVersion: "59996591"
    uid: 6a8ed57a-5187-4f4d-a8b0-4806915f56d5
  spec:
    replicas: 0
    selector:
      matchLabels:
        app: suite-command-center-api
        pod-template-hash: 79c8d8f6d9
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-12-25T10:15:18-06:00"
        creationTimestamp: null
        labels:
          app: suite-command-center-api
          pod-template-hash: 79c8d8f6d9
      spec:
        automountServiceAccountToken: true
        containers:
        - env:
          - name: NO_PROXY
            value: 127.0.0.1,localhost,192.168.50.251,192.168.50.2,192.168.50.3,192.168.50.6,10.0.0.0/8,10.42.0.0/16,10.43.0.0/16,.svc,.svc.cluster.local,.cluster.local
          - name: PORT
            value: "8000"
          image: registry.suite.home.arpa:5000/suite-command-center-api:latest
          imagePullPolicy: Always
          name: api
          ports:
          - containerPort: 8000
            protocol: TCP
          resources: {}
          startupProbe:
            failureThreshold: 60
            httpGet:
              path: /healthz
              port: 8000
              scheme: HTTP
            periodSeconds: 2
            successThreshold: 1
            timeoutSeconds: 2
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        nodeSelector:
          kubernetes.io/hostname: m1
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: suite-command-center-api
        serviceAccountName: suite-command-center-api
        terminationGracePeriodSeconds: 30
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "18"
      meta.helm.sh/release-name: suite-command-center
      meta.helm.sh/release-namespace: suite
    creationTimestamp: "2025-12-25T16:15:18Z"
    generation: 3
    labels:
      app: suite-command-center-api
      app.kubernetes.io/instance: suite-command-center
      app.kubernetes.io/name: suite-command-center
      pod-template-hash: 844846f545
    name: suite-command-center-api-844846f545
    namespace: suite
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: suite-command-center-api
      uid: 3ce9cd02-afeb-4c08-b60d-62d132e28a0b
    resourceVersion: "57638476"
    uid: eb33e8c4-7846-4019-ae77-147760d99b1c
  spec:
    replicas: 0
    selector:
      matchLabels:
        app: suite-command-center-api
        pod-template-hash: 844846f545
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-12-25T10:15:18-06:00"
        creationTimestamp: null
        labels:
          app: suite-command-center-api
          app.kubernetes.io/instance: suite-command-center
          app.kubernetes.io/name: suite-command-center
          pod-template-hash: 844846f545
      spec:
        automountServiceAccountToken: true
        containers:
        - env:
          - name: MQTT_ENABLED
            value: "false"
          - name: MQTT_BROKER_URL
            value: mqtt://mosquitto.suite.svc.cluster.local:1883
          - name: MQTT_TOPIC_PREFIX
            value: suite/sensors/#
          - name: NO_PROXY
            value: 127.0.0.1,localhost,192.168.50.251,192.168.50.2,192.168.50.3,192.168.50.6,10.0.0.0/8,10.42.0.0/16,10.43.0.0/16,.svc,.svc.cluster.local,.cluster.local
          image: registry.suite.home.arpa:5000/suite-command-center-api:latest
          imagePullPolicy: Always
          livenessProbe:
            failureThreshold: 6
            httpGet:
              path: /healthz
              port: 8000
              scheme: HTTP
            initialDelaySeconds: 20
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 2
          name: api
          ports:
          - containerPort: 8000
            protocol: TCP
          readinessProbe:
            failureThreshold: 12
            httpGet:
              path: /healthz
              port: 8000
              scheme: HTTP
            initialDelaySeconds: 2
            periodSeconds: 5
            successThreshold: 1
            timeoutSeconds: 2
          resources: {}
          startupProbe:
            failureThreshold: 60
            httpGet:
              path: /healthz
              port: 8000
              scheme: HTTP
            periodSeconds: 2
            successThreshold: 1
            timeoutSeconds: 2
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        nodeSelector:
          kubernetes.io/hostname: m1
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: suite-command-center-api
        serviceAccountName: suite-command-center-api
        terminationGracePeriodSeconds: 30
  status:
    observedGeneration: 3
    replicas: 0
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "19"
      meta.helm.sh/release-name: suite-command-center
      meta.helm.sh/release-namespace: suite
    creationTimestamp: "2025-12-25T16:18:09Z"
    generation: 2
    labels:
      app: suite-command-center-api
      app.kubernetes.io/instance: suite-command-center
      app.kubernetes.io/name: suite-command-center
      pod-template-hash: 884c67474
    name: suite-command-center-api-884c67474
    namespace: suite
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: suite-command-center-api
      uid: 3ce9cd02-afeb-4c08-b60d-62d132e28a0b
    resourceVersion: "58324447"
    uid: 896c50a2-a2af-4136-8e6b-268083bead55
  spec:
    replicas: 0
    selector:
      matchLabels:
        app: suite-command-center-api
        pod-template-hash: 884c67474
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-12-25T10:15:18-06:00"
        creationTimestamp: null
        labels:
          app: suite-command-center-api
          app.kubernetes.io/instance: suite-command-center
          app.kubernetes.io/name: suite-command-center
          pod-template-hash: 884c67474
      spec:
        automountServiceAccountToken: true
        containers:
        - env:
          - name: MQTT_ENABLED
            value: "false"
          - name: MQTT_BROKER_URL
            value: mqtt://mosquitto.suite.svc.cluster.local:1883
          - name: MQTT_TOPIC_PREFIX
            value: suite/sensors/#
          - name: NO_PROXY
            value: 127.0.0.1,localhost,192.168.50.251,192.168.50.2,192.168.50.3,192.168.50.6,10.0.0.0/8,10.42.0.0/16,10.43.0.0/16,.svc,.svc.cluster.local,.cluster.local
          image: registry.suite.home.arpa:5000/suite-command-center-api:latest
          imagePullPolicy: Always
          livenessProbe:
            failureThreshold: 6
            httpGet:
              path: /healthz
              port: 8000
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 20
            successThreshold: 1
            timeoutSeconds: 2
          name: api
          ports:
          - containerPort: 8000
            protocol: TCP
          readinessProbe:
            failureThreshold: 12
            httpGet:
              path: /healthz
              port: 8000
              scheme: HTTP
            initialDelaySeconds: 3
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 2
          resources: {}
          startupProbe:
            failureThreshold: 60
            httpGet:
              path: /healthz
              port: 8000
              scheme: HTTP
            periodSeconds: 2
            successThreshold: 1
            timeoutSeconds: 2
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        nodeSelector:
          kubernetes.io/hostname: m1
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: suite-command-center-api
        serviceAccountName: suite-command-center-api
        terminationGracePeriodSeconds: 30
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "9"
    creationTimestamp: "2025-12-31T19:48:43Z"
    generation: 2
    labels:
      app: suite-command-center-api-shim
      pod-template-hash: 57886d7566
    name: suite-command-center-api-shim-57886d7566
    namespace: suite
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: suite-command-center-api-shim
      uid: 8fae3472-1d7d-4499-b9a1-32fe9be2a32c
    resourceVersion: "61355337"
    uid: edc3e414-cafa-4b6a-90a3-7d7b6f85edb9
  spec:
    replicas: 0
    selector:
      matchLabels:
        app: suite-command-center-api-shim
        pod-template-hash: 57886d7566
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-12-31T13:48:44-06:00"
        creationTimestamp: null
        labels:
          app: suite-command-center-api-shim
          pod-template-hash: 57886d7566
      spec:
        containers:
        - command:
          - python
          - /app/server.py
          env:
          - name: PORT
            value: "8000"
          - name: APP_NAME
            value: suite-command-center-api-shim
          image: python:3.12-slim
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: 8000
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          name: api
          ports:
          - containerPort: 8000
            name: http
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: 8000
              scheme: HTTP
            initialDelaySeconds: 2
            periodSeconds: 5
            successThreshold: 1
            timeoutSeconds: 1
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /app
            name: code
            readOnly: true
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: suite-command-center-api-shim
        serviceAccountName: suite-command-center-api-shim
        terminationGracePeriodSeconds: 30
        volumes:
        - configMap:
            defaultMode: 420
            name: suite-command-center-api-shim
          name: code
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "7"
    creationTimestamp: "2025-12-31T19:39:36Z"
    generation: 2
    labels:
      app: suite-command-center-api-shim
      pod-template-hash: 66b989d4fb
    name: suite-command-center-api-shim-66b989d4fb
    namespace: suite
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: suite-command-center-api-shim
      uid: 8fae3472-1d7d-4499-b9a1-32fe9be2a32c
    resourceVersion: "61350768"
    uid: a1bb062d-ff7d-42e6-aa43-3609ff20633d
  spec:
    replicas: 0
    selector:
      matchLabels:
        app: suite-command-center-api-shim
        pod-template-hash: 66b989d4fb
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-12-31T13:39:37-06:00"
        creationTimestamp: null
        labels:
          app: suite-command-center-api-shim
          pod-template-hash: 66b989d4fb
      spec:
        containers:
        - command:
          - python
          - /app/server.py
          env:
          - name: PORT
            value: "8000"
          - name: APP_NAME
            value: suite-command-center-api-shim
          image: python:3.12-slim
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: 8000
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          name: api
          ports:
          - containerPort: 8000
            name: http
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: 8000
              scheme: HTTP
            initialDelaySeconds: 2
            periodSeconds: 5
            successThreshold: 1
            timeoutSeconds: 1
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /app
            name: code
            readOnly: true
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: suite-command-center-api-shim
        serviceAccountName: suite-command-center-api-shim
        terminationGracePeriodSeconds: 30
        volumes:
        - configMap:
            defaultMode: 420
            name: suite-command-center-api-shim
          name: code
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "2"
      deployment.kubernetes.io/max-replicas: "3"
      deployment.kubernetes.io/revision: "12"
    creationTimestamp: "2026-01-01T01:35:38Z"
    generation: 2
    labels:
      app: suite-command-center-api-shim
      pod-template-hash: 68795c87d9
    name: suite-command-center-api-shim-68795c87d9
    namespace: suite
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: suite-command-center-api-shim
      uid: 8fae3472-1d7d-4499-b9a1-32fe9be2a32c
    resourceVersion: "61876753"
    uid: 1c6fafb8-2446-484b-9d21-51d7bc23dbfa
  spec:
    replicas: 2
    selector:
      matchLabels:
        app: suite-command-center-api-shim
        pod-template-hash: 68795c87d9
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-12-31T19:35:38-06:00"
        creationTimestamp: null
        labels:
          app: suite-command-center-api-shim
          pod-template-hash: 68795c87d9
      spec:
        containers:
        - command:
          - python
          - /app/server.py
          env:
          - name: PORT
            value: "8000"
          - name: APP_NAME
            value: suite-command-center-api-shim
          image: python:3.12-slim
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: 8000
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          name: api
          ports:
          - containerPort: 8000
            name: http
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: 8000
              scheme: HTTP
            initialDelaySeconds: 2
            periodSeconds: 5
            successThreshold: 1
            timeoutSeconds: 1
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /app
            name: code
            readOnly: true
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: suite-command-center-api-shim
        serviceAccountName: suite-command-center-api-shim
        terminationGracePeriodSeconds: 30
        volumes:
        - configMap:
            defaultMode: 420
            name: suite-command-center-api-shim
          name: code
  status:
    fullyLabeledReplicas: 2
    observedGeneration: 2
    replicas: 2
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "4"
    creationTimestamp: "2025-12-31T19:04:28Z"
    generation: 3
    labels:
      app: suite-command-center-api-shim
      pod-template-hash: 6976b8db79
    name: suite-command-center-api-shim-6976b8db79
    namespace: suite
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: suite-command-center-api-shim
      uid: 8fae3472-1d7d-4499-b9a1-32fe9be2a32c
    resourceVersion: "61331282"
    uid: 0854cfb1-46e1-4da5-9b31-94090471e67a
  spec:
    replicas: 0
    selector:
      matchLabels:
        app: suite-command-center-api-shim
        pod-template-hash: 6976b8db79
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-12-31T13:03:17-06:00"
          shim-server-py-rev: "1767207868"
        creationTimestamp: null
        labels:
          app: suite-command-center-api-shim
          pod-template-hash: 6976b8db79
      spec:
        containers:
        - command:
          - python
          - /app/server.py
          env:
          - name: PORT
            value: "8000"
          - name: APP_NAME
            value: suite-command-center-api-shim
          image: python:3.12-slim
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: 8000
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          name: api
          ports:
          - containerPort: 8000
            name: http
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: 8000
              scheme: HTTP
            initialDelaySeconds: 2
            periodSeconds: 5
            successThreshold: 1
            timeoutSeconds: 1
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /app/server.py
            name: server-py
            readOnly: true
            subPath: server.py
          - mountPath: /app
            name: code
            readOnly: true
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: suite-command-center-api-shim
        serviceAccountName: suite-command-center-api-shim
        terminationGracePeriodSeconds: 30
        volumes:
        - configMap:
            defaultMode: 420
            items:
            - key: server.py
              path: server.py
            name: suite-command-center-api-shim-code
          name: server-py
        - configMap:
            defaultMode: 420
            name: suite-command-center-api-shim
          name: code
  status:
    observedGeneration: 3
    replicas: 0
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "3"
    creationTimestamp: "2025-12-31T19:03:16Z"
    generation: 3
    labels:
      app: suite-command-center-api-shim
      pod-template-hash: 6c9d9fcb67
    name: suite-command-center-api-shim-6c9d9fcb67
    namespace: suite
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: suite-command-center-api-shim
      uid: 8fae3472-1d7d-4499-b9a1-32fe9be2a32c
    resourceVersion: "61331253"
    uid: 2a2b94fb-0d75-49ab-a364-cc4ab497a987
  spec:
    replicas: 0
    selector:
      matchLabels:
        app: suite-command-center-api-shim
        pod-template-hash: 6c9d9fcb67
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-12-31T13:03:17-06:00"
          shim-server-py-rev: "1767207796"
        creationTimestamp: null
        labels:
          app: suite-command-center-api-shim
          pod-template-hash: 6c9d9fcb67
      spec:
        containers:
        - command:
          - python
          - /app/server.py
          env:
          - name: PORT
            value: "8000"
          - name: APP_NAME
            value: suite-command-center-api-shim
          image: python:3.12-slim
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: 8000
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          name: api
          ports:
          - containerPort: 8000
            name: http
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: 8000
              scheme: HTTP
            initialDelaySeconds: 2
            periodSeconds: 5
            successThreshold: 1
            timeoutSeconds: 1
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /app/server.py
            name: server-py
            readOnly: true
            subPath: server.py
          - mountPath: /app
            name: code
            readOnly: true
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: suite-command-center-api-shim
        serviceAccountName: suite-command-center-api-shim
        terminationGracePeriodSeconds: 30
        volumes:
        - configMap:
            defaultMode: 420
            items:
            - key: server.py
              path: server.py
            name: suite-command-center-api-shim-code
          name: server-py
        - configMap:
            defaultMode: 420
            name: suite-command-center-api-shim
          name: code
  status:
    observedGeneration: 3
    replicas: 0
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "11"
    creationTimestamp: "2025-12-31T23:01:21Z"
    generation: 2
    labels:
      app: suite-command-center-api-shim
      pod-template-hash: 7578fc9f57
    name: suite-command-center-api-shim-7578fc9f57
    namespace: suite
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: suite-command-center-api-shim
      uid: 8fae3472-1d7d-4499-b9a1-32fe9be2a32c
    resourceVersion: "61505070"
    uid: cb4212be-2888-4f70-8764-f58b9a2b5148
  spec:
    replicas: 0
    selector:
      matchLabels:
        app: suite-command-center-api-shim
        pod-template-hash: 7578fc9f57
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-12-31T17:01:22-06:00"
        creationTimestamp: null
        labels:
          app: suite-command-center-api-shim
          pod-template-hash: 7578fc9f57
      spec:
        containers:
        - command:
          - python
          - /app/server.py
          env:
          - name: PORT
            value: "8000"
          - name: APP_NAME
            value: suite-command-center-api-shim
          image: python:3.12-slim
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: 8000
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          name: api
          ports:
          - containerPort: 8000
            name: http
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: 8000
              scheme: HTTP
            initialDelaySeconds: 2
            periodSeconds: 5
            successThreshold: 1
            timeoutSeconds: 1
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /app
            name: code
            readOnly: true
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: suite-command-center-api-shim
        serviceAccountName: suite-command-center-api-shim
        terminationGracePeriodSeconds: 30
        volumes:
        - configMap:
            defaultMode: 420
            name: suite-command-center-api-shim
          name: code
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "5"
    creationTimestamp: "2025-12-31T19:04:28Z"
    generation: 3
    labels:
      app: suite-command-center-api-shim
      pod-template-hash: 786f88998b
    name: suite-command-center-api-shim-786f88998b
    namespace: suite
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: suite-command-center-api-shim
      uid: 8fae3472-1d7d-4499-b9a1-32fe9be2a32c
    resourceVersion: "61333044"
    uid: 3d4c8bf2-f16d-4db3-82c6-3b9d3278b3f8
  spec:
    replicas: 0
    selector:
      matchLabels:
        app: suite-command-center-api-shim
        pod-template-hash: 786f88998b
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-12-31T13:04:28-06:00"
          shim-server-py-rev: "1767207868"
        creationTimestamp: null
        labels:
          app: suite-command-center-api-shim
          pod-template-hash: 786f88998b
      spec:
        containers:
        - command:
          - python
          - /app/server.py
          env:
          - name: PORT
            value: "8000"
          - name: APP_NAME
            value: suite-command-center-api-shim
          image: python:3.12-slim
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: 8000
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          name: api
          ports:
          - containerPort: 8000
            name: http
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: 8000
              scheme: HTTP
            initialDelaySeconds: 2
            periodSeconds: 5
            successThreshold: 1
            timeoutSeconds: 1
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /app/server.py
            name: server-py
            readOnly: true
            subPath: server.py
          - mountPath: /app
            name: code
            readOnly: true
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: suite-command-center-api-shim
        serviceAccountName: suite-command-center-api-shim
        terminationGracePeriodSeconds: 30
        volumes:
        - configMap:
            defaultMode: 420
            items:
            - key: server.py
              path: server.py
            name: suite-command-center-api-shim-code
          name: server-py
        - configMap:
            defaultMode: 420
            name: suite-command-center-api-shim
          name: code
  status:
    observedGeneration: 3
    replicas: 0
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "2"
    creationTimestamp: "2025-12-31T19:03:16Z"
    generation: 2
    labels:
      app: suite-command-center-api-shim
      pod-template-hash: 7b6c7dfcb9
    name: suite-command-center-api-shim-7b6c7dfcb9
    namespace: suite
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: suite-command-center-api-shim
      uid: 8fae3472-1d7d-4499-b9a1-32fe9be2a32c
    resourceVersion: "61330685"
    uid: 86298010-30b2-418b-b2a1-f7b1e586eadc
  spec:
    replicas: 0
    selector:
      matchLabels:
        app: suite-command-center-api-shim
        pod-template-hash: 7b6c7dfcb9
    template:
      metadata:
        annotations:
          shim-server-py-rev: "1767207796"
        creationTimestamp: null
        labels:
          app: suite-command-center-api-shim
          pod-template-hash: 7b6c7dfcb9
      spec:
        containers:
        - command:
          - python
          - /app/server.py
          env:
          - name: PORT
            value: "8000"
          - name: APP_NAME
            value: suite-command-center-api-shim
          image: python:3.12-slim
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: 8000
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          name: api
          ports:
          - containerPort: 8000
            name: http
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: 8000
              scheme: HTTP
            initialDelaySeconds: 2
            periodSeconds: 5
            successThreshold: 1
            timeoutSeconds: 1
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /app/server.py
            name: server-py
            readOnly: true
            subPath: server.py
          - mountPath: /app
            name: code
            readOnly: true
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: suite-command-center-api-shim
        serviceAccountName: suite-command-center-api-shim
        terminationGracePeriodSeconds: 30
        volumes:
        - configMap:
            defaultMode: 420
            items:
            - key: server.py
              path: server.py
            name: suite-command-center-api-shim-code
          name: server-py
        - configMap:
            defaultMode: 420
            name: suite-command-center-api-shim
          name: code
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "10"
      deployment.kubernetes.io/revision-history: 1,6,8
    creationTimestamp: "2025-12-31T19:03:00Z"
    generation: 6
    labels:
      app: suite-command-center-api-shim
      pod-template-hash: 7f54bb74fb
    name: suite-command-center-api-shim-7f54bb74fb
    namespace: suite
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: suite-command-center-api-shim
      uid: 8fae3472-1d7d-4499-b9a1-32fe9be2a32c
    resourceVersion: "61436481"
    uid: 39594e14-32c7-4443-8d10-1ad14475fe64
  spec:
    replicas: 0
    selector:
      matchLabels:
        app: suite-command-center-api-shim
        pod-template-hash: 7f54bb74fb
    template:
      metadata:
        creationTimestamp: null
        labels:
          app: suite-command-center-api-shim
          pod-template-hash: 7f54bb74fb
      spec:
        containers:
        - command:
          - python
          - /app/server.py
          env:
          - name: PORT
            value: "8000"
          - name: APP_NAME
            value: suite-command-center-api-shim
          image: python:3.12-slim
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: 8000
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          name: api
          ports:
          - containerPort: 8000
            name: http
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: 8000
              scheme: HTTP
            initialDelaySeconds: 2
            periodSeconds: 5
            successThreshold: 1
            timeoutSeconds: 1
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /app
            name: code
            readOnly: true
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: suite-command-center-api-shim
        serviceAccountName: suite-command-center-api-shim
        terminationGracePeriodSeconds: 30
        volumes:
        - configMap:
            defaultMode: 420
            name: suite-command-center-api-shim
          name: code
  status:
    observedGeneration: 6
    replicas: 0
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "18"
      meta.helm.sh/release-name: suite-command-center
      meta.helm.sh/release-namespace: suite
    creationTimestamp: "2025-12-25T00:48:49Z"
    generation: 2
    labels:
      app: suite-command-center-ui
      app.kubernetes.io/instance: suite-command-center
      app.kubernetes.io/name: suite-command-center
      pod-template-hash: 55875bc89c
    name: suite-command-center-ui-55875bc89c
    namespace: suite
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: suite-command-center-ui
      uid: 31548020-dd89-4c5f-9f6f-755fa5109650
    resourceVersion: "57298128"
    uid: e062ae81-24ad-4147-9a54-5286c1aa640c
  spec:
    replicas: 0
    selector:
      matchLabels:
        app: suite-command-center-ui
        pod-template-hash: 55875bc89c
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-12-23T10:12:13-06:00"
        creationTimestamp: null
        labels:
          app: suite-command-center-ui
          app.kubernetes.io/instance: suite-command-center
          app.kubernetes.io/name: suite-command-center
          pod-template-hash: 55875bc89c
      spec:
        containers:
        - env:
          - name: NEXT_PUBLIC_API_BASE
            value: http://suite-command-center-api.suite.svc.cluster.local
          - name: HOSTNAME
            value: 0.0.0.0
          - name: PORT
            value: "3000"
          image: registry.suite.home.arpa:5000/suite-command-center-ui:latest
          imagePullPolicy: Always
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /
              port: 3000
              scheme: HTTP
            initialDelaySeconds: 15
            periodSeconds: 20
            successThreshold: 1
            timeoutSeconds: 1
          name: ui
          ports:
          - containerPort: 3000
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /
              port: 3000
              scheme: HTTP
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        nodeSelector:
          suite.home.arpa/display: "true"
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "17"
      meta.helm.sh/release-name: suite-command-center
      meta.helm.sh/release-namespace: suite
    creationTimestamp: "2025-12-23T16:12:13Z"
    generation: 2
    labels:
      app: suite-command-center-ui
      app.kubernetes.io/instance: suite-command-center
      app.kubernetes.io/name: suite-command-center
      pod-template-hash: 5f9d449fd
    name: suite-command-center-ui-5f9d449fd
    namespace: suite
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: suite-command-center-ui
      uid: 31548020-dd89-4c5f-9f6f-755fa5109650
    resourceVersion: "57290505"
    uid: 443e67cb-3a8f-4128-9e16-4d2457d18bc9
  spec:
    replicas: 0
    selector:
      matchLabels:
        app: suite-command-center-ui
        pod-template-hash: 5f9d449fd
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-12-23T10:12:13-06:00"
        creationTimestamp: null
        labels:
          app: suite-command-center-ui
          app.kubernetes.io/instance: suite-command-center
          app.kubernetes.io/name: suite-command-center
          pod-template-hash: 5f9d449fd
      spec:
        containers:
        - env:
          - name: NEXT_PUBLIC_API_BASE
            value: /api
          - name: HOSTNAME
            value: 0.0.0.0
          - name: PORT
            value: "3000"
          image: 192.168.50.248:5000/suite-command-center-ui:latest
          imagePullPolicy: Always
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /
              port: 3000
              scheme: HTTP
            initialDelaySeconds: 15
            periodSeconds: 20
            successThreshold: 1
            timeoutSeconds: 1
          name: ui
          ports:
          - containerPort: 3000
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /
              port: 3000
              scheme: HTTP
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        nodeSelector:
          suite.home.arpa/display: "true"
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "19"
      meta.helm.sh/release-name: suite-command-center
      meta.helm.sh/release-namespace: suite
    creationTimestamp: "2025-12-25T01:08:48Z"
    generation: 2
    labels:
      app: suite-command-center-ui
      app.kubernetes.io/instance: suite-command-center
      app.kubernetes.io/name: suite-command-center
      pod-template-hash: 667764b6f7
    name: suite-command-center-ui-667764b6f7
    namespace: suite
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: suite-command-center-ui
      uid: 31548020-dd89-4c5f-9f6f-755fa5109650
    resourceVersion: "57298150"
    uid: 8b4d9e50-cfd9-4a63-aa83-57bafec17d83
  spec:
    replicas: 0
    selector:
      matchLabels:
        app: suite-command-center-ui
        pod-template-hash: 667764b6f7
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-12-23T10:12:13-06:00"
        creationTimestamp: null
        labels:
          app: suite-command-center-ui
          app.kubernetes.io/instance: suite-command-center
          app.kubernetes.io/name: suite-command-center
          pod-template-hash: 667764b6f7
      spec:
        containers:
        - env:
          - name: NEXT_PUBLIC_API_BASE
            value: http://suite-command-center-api.suite.svc.cluster.local
          - name: HOSTNAME
            value: 0.0.0.0
          - name: PORT
            value: "3000"
          image: registry.suite.home.arpa:5000/suite-command-center-ui:latest
          imagePullPolicy: Always
          livenessProbe:
            failureThreshold: 3
            initialDelaySeconds: 15
            periodSeconds: 20
            successThreshold: 1
            tcpSocket:
              port: 3000
            timeoutSeconds: 1
          name: ui
          ports:
          - containerPort: 3000
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            tcpSocket:
              port: 3000
            timeoutSeconds: 1
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        nodeSelector:
          suite.home.arpa/display: "true"
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "20"
      meta.helm.sh/release-name: suite-command-center
      meta.helm.sh/release-namespace: suite
    creationTimestamp: "2025-12-25T01:08:49Z"
    generation: 2
    labels:
      app: suite-command-center-ui
      app.kubernetes.io/instance: suite-command-center
      app.kubernetes.io/name: suite-command-center
      pod-template-hash: 68bf8568bc
    name: suite-command-center-ui-68bf8568bc
    namespace: suite
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: suite-command-center-ui
      uid: 31548020-dd89-4c5f-9f6f-755fa5109650
    resourceVersion: "57307287"
    uid: b985bd54-0b7d-4a8f-8c85-2afec566dbb3
  spec:
    replicas: 0
    selector:
      matchLabels:
        app: suite-command-center-ui
        pod-template-hash: 68bf8568bc
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-12-24T19:08:49-06:00"
        creationTimestamp: null
        labels:
          app: suite-command-center-ui
          app.kubernetes.io/instance: suite-command-center
          app.kubernetes.io/name: suite-command-center
          pod-template-hash: 68bf8568bc
      spec:
        containers:
        - env:
          - name: NEXT_PUBLIC_API_BASE
            value: http://suite-command-center-api.suite.svc.cluster.local
          - name: HOSTNAME
            value: 0.0.0.0
          - name: PORT
            value: "3000"
          image: registry.suite.home.arpa:5000/suite-command-center-ui:latest
          imagePullPolicy: Always
          livenessProbe:
            failureThreshold: 3
            initialDelaySeconds: 15
            periodSeconds: 20
            successThreshold: 1
            tcpSocket:
              port: 3000
            timeoutSeconds: 1
          name: ui
          ports:
          - containerPort: 3000
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            tcpSocket:
              port: 3000
            timeoutSeconds: 1
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        nodeSelector:
          suite.home.arpa/display: "true"
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "25"
      meta.helm.sh/release-name: suite-command-center
      meta.helm.sh/release-namespace: suite
    creationTimestamp: "2025-12-27T16:01:17Z"
    generation: 2
    labels:
      app: suite-command-center-ui
      app.kubernetes.io/instance: suite-command-center
      app.kubernetes.io/name: suite-command-center
      pod-template-hash: 69f9c95b86
    name: suite-command-center-ui-69f9c95b86
    namespace: suite
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: suite-command-center-ui
      uid: 31548020-dd89-4c5f-9f6f-755fa5109650
    resourceVersion: "58694019"
    uid: 9b88be75-c07f-4632-aa98-31820346a046
  spec:
    replicas: 0
    selector:
      matchLabels:
        app: suite-command-center-ui
        pod-template-hash: 69f9c95b86
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-12-27T10:01:17-06:00"
        creationTimestamp: null
        labels:
          app: suite-command-center-ui
          app.kubernetes.io/instance: suite-command-center
          app.kubernetes.io/name: suite-command-center
          pod-template-hash: 69f9c95b86
      spec:
        containers:
        - env:
          - name: NEXT_PUBLIC_API_BASE
            value: https://command-center.suite.home.arpa
          - name: HOSTNAME
            value: 0.0.0.0
          - name: PORT
            value: "3000"
          image: registry.suite.home.arpa:5000/suite-command-center-ui:latest
          imagePullPolicy: Always
          livenessProbe:
            failureThreshold: 3
            initialDelaySeconds: 15
            periodSeconds: 20
            successThreshold: 1
            tcpSocket:
              port: 3000
            timeoutSeconds: 1
          name: ui
          ports:
          - containerPort: 3000
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            tcpSocket:
              port: 3000
            timeoutSeconds: 1
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        nodeSelector:
          suite.home.arpa/display: "true"
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "27"
      meta.helm.sh/release-name: suite-command-center
      meta.helm.sh/release-namespace: suite
    creationTimestamp: "2025-12-27T22:42:11Z"
    generation: 1
    labels:
      app: suite-command-center-ui
      pod-template-hash: 6c856bb4f8
    name: suite-command-center-ui-6c856bb4f8
    namespace: suite
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: suite-command-center-ui
      uid: 31548020-dd89-4c5f-9f6f-755fa5109650
    resourceVersion: "58857660"
    uid: 61a25626-fbc6-4328-b762-3d05fc89d7f9
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: suite-command-center-ui
        pod-template-hash: 6c856bb4f8
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-12-27T10:05:49-06:00"
        creationTimestamp: null
        labels:
          app: suite-command-center-ui
          pod-template-hash: 6c856bb4f8
      spec:
        containers:
        - image: registry.suite.home.arpa:5000/suite-command-center-ui:latest
          imagePullPolicy: Always
          name: ui
          ports:
          - containerPort: 80
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        nodeSelector:
          suite.home.arpa/display: "true"
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "26"
      meta.helm.sh/release-name: suite-command-center
      meta.helm.sh/release-namespace: suite
    creationTimestamp: "2025-12-27T16:05:49Z"
    generation: 2
    labels:
      app: suite-command-center-ui
      app.kubernetes.io/instance: suite-command-center
      app.kubernetes.io/name: suite-command-center
      pod-template-hash: 74f696847
    name: suite-command-center-ui-74f696847
    namespace: suite
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: suite-command-center-ui
      uid: 31548020-dd89-4c5f-9f6f-755fa5109650
    resourceVersion: "58857633"
    uid: afa31913-a9df-461f-be97-dc381317d0a6
  spec:
    replicas: 0
    selector:
      matchLabels:
        app: suite-command-center-ui
        pod-template-hash: 74f696847
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-12-27T10:05:49-06:00"
        creationTimestamp: null
        labels:
          app: suite-command-center-ui
          app.kubernetes.io/instance: suite-command-center
          app.kubernetes.io/name: suite-command-center
          pod-template-hash: 74f696847
      spec:
        containers:
        - env:
          - name: NEXT_PUBLIC_API_BASE
            value: https://command-center.suite.home.arpa
          - name: HOSTNAME
            value: 0.0.0.0
          - name: PORT
            value: "3000"
          image: registry.suite.home.arpa:5000/suite-command-center-ui:latest
          imagePullPolicy: Always
          livenessProbe:
            failureThreshold: 3
            initialDelaySeconds: 15
            periodSeconds: 20
            successThreshold: 1
            tcpSocket:
              port: 3000
            timeoutSeconds: 1
          name: ui
          ports:
          - containerPort: 3000
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            tcpSocket:
              port: 3000
            timeoutSeconds: 1
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        nodeSelector:
          suite.home.arpa/display: "true"
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "16"
      meta.helm.sh/release-name: suite-command-center
      meta.helm.sh/release-namespace: suite
    creationTimestamp: "2025-12-23T16:12:13Z"
    generation: 2
    labels:
      app: suite-command-center-ui
      app.kubernetes.io/instance: suite-command-center
      app.kubernetes.io/name: suite-command-center
      pod-template-hash: 7d7995f96b
    name: suite-command-center-ui-7d7995f96b
    namespace: suite
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: suite-command-center-ui
      uid: 31548020-dd89-4c5f-9f6f-755fa5109650
    resourceVersion: "56566332"
    uid: d2c0d271-bed6-4b69-bd73-3f9f3eb44c49
  spec:
    replicas: 0
    selector:
      matchLabels:
        app: suite-command-center-ui
        pod-template-hash: 7d7995f96b
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-12-23T09:44:01-06:00"
        creationTimestamp: null
        labels:
          app: suite-command-center-ui
          app.kubernetes.io/instance: suite-command-center
          app.kubernetes.io/name: suite-command-center
          pod-template-hash: 7d7995f96b
      spec:
        containers:
        - env:
          - name: NEXT_PUBLIC_API_BASE
            value: /api
          - name: HOSTNAME
            value: 0.0.0.0
          - name: PORT
            value: "3000"
          image: 192.168.50.248:5000/suite-command-center-ui:latest
          imagePullPolicy: Always
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /
              port: 3000
              scheme: HTTP
            initialDelaySeconds: 15
            periodSeconds: 20
            successThreshold: 1
            timeoutSeconds: 1
          name: ui
          ports:
          - containerPort: 3000
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /
              port: 3000
              scheme: HTTP
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        nodeSelector:
          suite.home.arpa/display: "true"
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "21"
      meta.helm.sh/release-name: suite-command-center
      meta.helm.sh/release-namespace: suite
    creationTimestamp: "2025-12-25T01:26:24Z"
    generation: 2
    labels:
      app: suite-command-center-ui
      app.kubernetes.io/instance: suite-command-center
      app.kubernetes.io/name: suite-command-center
      pod-template-hash: 85497c9b
    name: suite-command-center-ui-85497c9b
    namespace: suite
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: suite-command-center-ui
      uid: 31548020-dd89-4c5f-9f6f-755fa5109650
    resourceVersion: "57309113"
    uid: d650d595-f74b-472a-9111-54ded4a0f3df
  spec:
    replicas: 0
    selector:
      matchLabels:
        app: suite-command-center-ui
        pod-template-hash: 85497c9b
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-12-24T19:08:49-06:00"
        creationTimestamp: null
        labels:
          app: suite-command-center-ui
          app.kubernetes.io/instance: suite-command-center
          app.kubernetes.io/name: suite-command-center
          pod-template-hash: 85497c9b
      spec:
        containers:
        - env:
          - name: NEXT_PUBLIC_API_BASE
            value: https://command-center.suite.home.arpa
          - name: HOSTNAME
            value: 0.0.0.0
          - name: PORT
            value: "3000"
          image: registry.suite.home.arpa:5000/suite-command-center-ui:latest
          imagePullPolicy: Always
          livenessProbe:
            failureThreshold: 3
            initialDelaySeconds: 15
            periodSeconds: 20
            successThreshold: 1
            tcpSocket:
              port: 3000
            timeoutSeconds: 1
          name: ui
          ports:
          - containerPort: 3000
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            tcpSocket:
              port: 3000
            timeoutSeconds: 1
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        nodeSelector:
          suite.home.arpa/display: "true"
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "23"
      meta.helm.sh/release-name: suite-command-center
      meta.helm.sh/release-namespace: suite
    creationTimestamp: "2025-12-25T14:02:31Z"
    generation: 2
    labels:
      app: suite-command-center-ui
      app.kubernetes.io/instance: suite-command-center
      app.kubernetes.io/name: suite-command-center
      pod-template-hash: 9c8757b78
    name: suite-command-center-ui-9c8757b78
    namespace: suite
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: suite-command-center-ui
      uid: 31548020-dd89-4c5f-9f6f-755fa5109650
    resourceVersion: "57637136"
    uid: 6b6d9d2c-121d-4b04-b5da-7b7c87f743f3
  spec:
    replicas: 0
    selector:
      matchLabels:
        app: suite-command-center-ui
        pod-template-hash: 9c8757b78
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-12-24T19:31:07-06:00"
        creationTimestamp: null
        labels:
          app: suite-command-center-ui
          app.kubernetes.io/instance: suite-command-center
          app.kubernetes.io/name: suite-command-center
          pod-template-hash: 9c8757b78
      spec:
        containers:
        - env:
          - name: NEXT_PUBLIC_API_BASE
            value: http://suite-command-center-api.suite.svc.cluster.local
          image: registry.suite.home.arpa:5000/suite-command-center-ui:latest
          imagePullPolicy: Always
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /
              port: 3000
              scheme: HTTP
            initialDelaySeconds: 15
            periodSeconds: 20
            successThreshold: 1
            timeoutSeconds: 1
          name: ui
          ports:
          - containerPort: 3000
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /
              port: 3000
              scheme: HTTP
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        nodeSelector:
          suite.home.arpa/display: "true"
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "24"
      deployment.kubernetes.io/revision-history: "22"
      meta.helm.sh/release-name: suite-command-center
      meta.helm.sh/release-namespace: suite
    creationTimestamp: "2025-12-25T01:31:07Z"
    generation: 4
    labels:
      app: suite-command-center-ui
      app.kubernetes.io/instance: suite-command-center
      app.kubernetes.io/name: suite-command-center
      pod-template-hash: f95b6dd46
    name: suite-command-center-ui-f95b6dd46
    namespace: suite
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: suite-command-center-ui
      uid: 31548020-dd89-4c5f-9f6f-755fa5109650
    resourceVersion: "58692033"
    uid: bea31d26-769f-4315-a1e3-18271f1fc86a
  spec:
    replicas: 0
    selector:
      matchLabels:
        app: suite-command-center-ui
        pod-template-hash: f95b6dd46
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-12-24T19:31:07-06:00"
        creationTimestamp: null
        labels:
          app: suite-command-center-ui
          app.kubernetes.io/instance: suite-command-center
          app.kubernetes.io/name: suite-command-center
          pod-template-hash: f95b6dd46
      spec:
        containers:
        - env:
          - name: NEXT_PUBLIC_API_BASE
            value: https://command-center.suite.home.arpa
          - name: HOSTNAME
            value: 0.0.0.0
          - name: PORT
            value: "3000"
          image: registry.suite.home.arpa:5000/suite-command-center-ui:latest
          imagePullPolicy: Always
          livenessProbe:
            failureThreshold: 3
            initialDelaySeconds: 15
            periodSeconds: 20
            successThreshold: 1
            tcpSocket:
              port: 3000
            timeoutSeconds: 1
          name: ui
          ports:
          - containerPort: 3000
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            tcpSocket:
              port: 3000
            timeoutSeconds: 1
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        nodeSelector:
          suite.home.arpa/display: "true"
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
  status:
    observedGeneration: 4
    replicas: 0
- apiVersion: batch/v1
  kind: CronJob
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"batch/v1","kind":"CronJob","metadata":{"annotations":{},"name":"homebridge-backup","namespace":"suite"},"spec":{"jobTemplate":{"spec":{"template":{"spec":{"containers":[{"args":["set -eux\nts=$(date +%Y%m%d-%H%M%S)\ntar -czf /backups/homebridge-$ts.tgz -C /homebridge .\necho \"Wrote /backups/homebridge-$ts.tgz\"\n"],"command":["/bin/sh","-lc"],"image":"alpine:3.20","name":"backup","volumeMounts":[{"mountPath":"/homebridge","name":"hb"},{"mountPath":"/backups","name":"bkp"}]}],"restartPolicy":"OnFailure","volumes":[{"name":"hb","persistentVolumeClaim":{"claimName":"homebridge-data-longhorn"}},{"name":"bkp","persistentVolumeClaim":{"claimName":"homebridge-backups-longhorn"}}]}}}},"schedule":"15 2 * * *"}}
    creationTimestamp: "2025-09-12T12:53:26Z"
    generation: 3
    name: homebridge-backup
    namespace: suite
    resourceVersion: "32569264"
    uid: edeae8b4-b334-4b2b-844d-a26eb2224a03
  spec:
    concurrencyPolicy: Allow
    failedJobsHistoryLimit: 1
    jobTemplate:
      metadata:
        creationTimestamp: null
      spec:
        template:
          metadata:
            creationTimestamp: null
          spec:
            containers:
            - args:
              - |
                set -eux
                ts=$(date +%Y%m%d-%H%M%S)
                tar -czf /backups/homebridge-$ts.tgz -C /homebridge .
                echo "Wrote /backups/homebridge-$ts.tgz"
              command:
              - /bin/sh
              - -lc
              image: alpine:3.20
              imagePullPolicy: IfNotPresent
              name: backup
              resources: {}
              terminationMessagePath: /dev/termination-log
              terminationMessagePolicy: File
              volumeMounts:
              - mountPath: /homebridge
                name: hb
              - mountPath: /backups
                name: bkp
            dnsPolicy: ClusterFirst
            restartPolicy: OnFailure
            schedulerName: default-scheduler
            securityContext: {}
            terminationGracePeriodSeconds: 30
            volumes:
            - name: hb
              persistentVolumeClaim:
                claimName: homebridge-data-longhorn
            - name: bkp
              persistentVolumeClaim:
                claimName: homebridge-backups-longhorn
    schedule: 15 2 * * *
    successfulJobsHistoryLimit: 3
    suspend: true
  status:
    lastScheduleTime: "2025-10-17T08:12:00Z"
    lastSuccessfulTime: "2025-10-11T08:12:30Z"
- apiVersion: batch/v1
  kind: CronJob
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"batch/v1","kind":"CronJob","metadata":{"annotations":{},"creationTimestamp":"2025-11-16T18:23:54Z","generation":1,"name":"homebridge-backup-config-nightly","namespace":"suite","resourceVersion":"36958804","uid":"22fd4ffd-4ab0-4ad2-b30b-3a82147ea4f4"},"spec":{"concurrencyPolicy":"Allow","failedJobsHistoryLimit":3,"jobTemplate":{"metadata":{"creationTimestamp":null},"spec":{"backoffLimit":1,"template":{"metadata":{"creationTimestamp":null,"labels":{"job-name":"homebridge-backup-config-nightly"}},"spec":{"affinity":{"podAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":[{"labelSelector":{"matchExpressions":[{"key":"app","operator":"In","values":["homebridge"]}]},"topologyKey":"kubernetes.io/hostname"}]}},"containers":[{"args":["set -eux\nts=$(date +%Y%m%d-%H%M%S)\nmkdir -p /tmp/hb-config\ncp -a /homebridge/. /tmp/hb-config/\n# Drop HomeKit identity + cache so restores dont confuse HomeKit\nrm -rf /tmp/hb-config/persist /tmp/hb-config/accessories\ntar -czf /backups/homebridge-config-$ts.tgz -C /tmp/hb-config .\necho \"Wrote /backups/homebridge-config-$ts.tgz\"\n"],"command":["/bin/sh","-lc"],"image":"alpine:3.20","imagePullPolicy":"IfNotPresent","name":"backup-config-only","resources":{},"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","volumeMounts":[{"mountPath":"/homebridge","name":"hb"},{"mountPath":"/backups","name":"bkp"}]}],"dnsPolicy":"ClusterFirst","restartPolicy":"OnFailure","schedulerName":"default-scheduler","securityContext":{},"terminationGracePeriodSeconds":30,"volumes":[{"name":"hb","persistentVolumeClaim":{"claimName":"homebridge-data-longhorn"}},{"name":"bkp","persistentVolumeClaim":{"claimName":"homebridge-backups-longhorn"}}]}}}},"schedule":"0 3 * * *","successfulJobsHistoryLimit":3,"suspend":false},"status":{}}
    creationTimestamp: "2025-11-16T18:23:54Z"
    generation: 1
    name: homebridge-backup-config-nightly
    namespace: suite
    resourceVersion: "38677484"
    uid: 22fd4ffd-4ab0-4ad2-b30b-3a82147ea4f4
  spec:
    concurrencyPolicy: Allow
    failedJobsHistoryLimit: 3
    jobTemplate:
      metadata:
        creationTimestamp: null
      spec:
        backoffLimit: 1
        template:
          metadata:
            creationTimestamp: null
            labels:
              job-name: homebridge-backup-config-nightly
          spec:
            affinity:
              podAffinity:
                requiredDuringSchedulingIgnoredDuringExecution:
                - labelSelector:
                    matchExpressions:
                    - key: app
                      operator: In
                      values:
                      - homebridge
                  topologyKey: kubernetes.io/hostname
            containers:
            - args:
              - |
                set -eux
                ts=$(date +%Y%m%d-%H%M%S)
                mkdir -p /tmp/hb-config
                cp -a /homebridge/. /tmp/hb-config/
                # Drop HomeKit identity + cache so restores dont confuse HomeKit
                rm -rf /tmp/hb-config/persist /tmp/hb-config/accessories
                tar -czf /backups/homebridge-config-$ts.tgz -C /tmp/hb-config .
                echo "Wrote /backups/homebridge-config-$ts.tgz"
              command:
              - /bin/sh
              - -lc
              image: alpine:3.20
              imagePullPolicy: IfNotPresent
              name: backup-config-only
              resources: {}
              terminationMessagePath: /dev/termination-log
              terminationMessagePolicy: File
              volumeMounts:
              - mountPath: /homebridge
                name: hb
              - mountPath: /backups
                name: bkp
            dnsPolicy: ClusterFirst
            restartPolicy: OnFailure
            schedulerName: default-scheduler
            securityContext: {}
            terminationGracePeriodSeconds: 30
            volumes:
            - name: hb
              persistentVolumeClaim:
                claimName: homebridge-data-longhorn
            - name: bkp
              persistentVolumeClaim:
                claimName: homebridge-backups-longhorn
    schedule: 0 3 * * *
    successfulJobsHistoryLimit: 3
    suspend: false
  status: {}
- apiVersion: batch/v1
  kind: CronJob
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"batch/v1","kind":"CronJob","metadata":{"annotations":{},"name":"homebridge-backup-prune","namespace":"suite"},"spec":{"jobTemplate":{"spec":{"backoffLimit":1,"template":{"spec":{"containers":[{"args":["set -eux\ncd /backups\n\necho \"=== BEFORE ===\"\nls -lh\ndf -h .\n\necho\necho \"=== Deleting files older than 60 days ===\"\n# Adjust the -mtime value if you want a different window\nfind . -maxdepth 1 -type f -name 'homebridge*.tgz' -mtime +60 -print -delete || true\n\necho\necho \"=== AFTER ===\"\nls -lh\ndf -h .\n"],"command":["/bin/sh","-lc"],"image":"alpine:3.20","name":"prune","volumeMounts":[{"mountPath":"/backups","name":"bkp"}]}],"restartPolicy":"OnFailure","volumes":[{"name":"bkp","persistentVolumeClaim":{"claimName":"homebridge-backups-longhorn"}}]}}}},"schedule":"0 4 * * *"}}
    creationTimestamp: "2025-11-16T18:22:32Z"
    generation: 1
    name: homebridge-backup-prune
    namespace: suite
    resourceVersion: "61728373"
    uid: 6d995cc4-2a79-4af9-962d-b7cf7e24e6a7
  spec:
    concurrencyPolicy: Allow
    failedJobsHistoryLimit: 1
    jobTemplate:
      metadata:
        creationTimestamp: null
      spec:
        backoffLimit: 1
        template:
          metadata:
            creationTimestamp: null
          spec:
            containers:
            - args:
              - |
                set -eux
                cd /backups

                echo "=== BEFORE ==="
                ls -lh
                df -h .

                echo
                echo "=== Deleting files older than 60 days ==="
                # Adjust the -mtime value if you want a different window
                find . -maxdepth 1 -type f -name 'homebridge*.tgz' -mtime +60 -print -delete || true

                echo
                echo "=== AFTER ==="
                ls -lh
                df -h .
              command:
              - /bin/sh
              - -lc
              image: alpine:3.20
              imagePullPolicy: IfNotPresent
              name: prune
              resources: {}
              terminationMessagePath: /dev/termination-log
              terminationMessagePolicy: File
              volumeMounts:
              - mountPath: /backups
                name: bkp
            dnsPolicy: ClusterFirst
            restartPolicy: OnFailure
            schedulerName: default-scheduler
            securityContext: {}
            terminationGracePeriodSeconds: 30
            volumes:
            - name: bkp
              persistentVolumeClaim:
                claimName: homebridge-backups-longhorn
    schedule: 0 4 * * *
    successfulJobsHistoryLimit: 3
    suspend: false
  status:
    active:
    - apiVersion: batch/v1
      kind: Job
      name: homebridge-backup-prune-29445720
      namespace: suite
      resourceVersion: "58029936"
      uid: 8c14086f-168a-4f6b-9e75-b8c785fa5370
    - apiVersion: batch/v1
      kind: Job
      name: homebridge-backup-prune-29447160
      namespace: suite
      resourceVersion: "58567892"
      uid: c59f3bb9-4959-4288-a9ea-f0a832a4091c
    lastScheduleTime: "2026-01-01T10:00:00Z"
    lastSuccessfulTime: "2026-01-01T10:01:36Z"
- apiVersion: batch/v1
  kind: Job
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"batch/v1","kind":"Job","metadata":{"annotations":{},"name":"homebridge-backup-config-only","namespace":"suite"},"spec":{"backoffLimit":1,"template":{"metadata":{"labels":{"job-name":"homebridge-backup-config-only"}},"spec":{"affinity":{"podAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":[{"labelSelector":{"matchExpressions":[{"key":"app","operator":"In","values":["homebridge"]}]},"topologyKey":"kubernetes.io/hostname"}]}},"containers":[{"args":["set -eux\nts=$(date +%Y%m%d-%H%M%S)\nmkdir -p /tmp/hb-config\ncp -a /homebridge/. /tmp/hb-config/\nrm -rf /tmp/hb-config/persist /tmp/hb-config/accessories\ntar -czf /backups/homebridge-config-$ts.tgz -C /tmp/hb-config .\necho \"Wrote /backups/homebridge-config-$ts.tgz\"\n"],"command":["/bin/sh","-lc"],"image":"alpine:3.20","name":"backup-config-only","volumeMounts":[{"mountPath":"/homebridge","name":"hb"},{"mountPath":"/backups","name":"bkp"}]}],"restartPolicy":"OnFailure","volumes":[{"name":"hb","persistentVolumeClaim":{"claimName":"homebridge-data-longhorn"}},{"name":"bkp","persistentVolumeClaim":{"claimName":"homebridge-backups-longhorn"}}]}}}}
    creationTimestamp: "2025-11-16T16:53:06Z"
    generation: 1
    labels:
      batch.kubernetes.io/controller-uid: 1c1f2c4a-f4dd-48f5-8fa9-85e509ebfc67
      batch.kubernetes.io/job-name: homebridge-backup-config-only
      controller-uid: 1c1f2c4a-f4dd-48f5-8fa9-85e509ebfc67
      job-name: homebridge-backup-config-only
    name: homebridge-backup-config-only
    namespace: suite
    resourceVersion: "36925861"
    uid: 1c1f2c4a-f4dd-48f5-8fa9-85e509ebfc67
  spec:
    backoffLimit: 1
    completionMode: NonIndexed
    completions: 1
    manualSelector: false
    parallelism: 1
    podReplacementPolicy: TerminatingOrFailed
    selector:
      matchLabels:
        batch.kubernetes.io/controller-uid: 1c1f2c4a-f4dd-48f5-8fa9-85e509ebfc67
    suspend: false
    template:
      metadata:
        creationTimestamp: null
        labels:
          batch.kubernetes.io/controller-uid: 1c1f2c4a-f4dd-48f5-8fa9-85e509ebfc67
          batch.kubernetes.io/job-name: homebridge-backup-config-only
          controller-uid: 1c1f2c4a-f4dd-48f5-8fa9-85e509ebfc67
          job-name: homebridge-backup-config-only
      spec:
        affinity:
          podAffinity:
            requiredDuringSchedulingIgnoredDuringExecution:
            - labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - homebridge
              topologyKey: kubernetes.io/hostname
        containers:
        - args:
          - |
            set -eux
            ts=$(date +%Y%m%d-%H%M%S)
            mkdir -p /tmp/hb-config
            cp -a /homebridge/. /tmp/hb-config/
            rm -rf /tmp/hb-config/persist /tmp/hb-config/accessories
            tar -czf /backups/homebridge-config-$ts.tgz -C /tmp/hb-config .
            echo "Wrote /backups/homebridge-config-$ts.tgz"
          command:
          - /bin/sh
          - -lc
          image: alpine:3.20
          imagePullPolicy: IfNotPresent
          name: backup-config-only
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /homebridge
            name: hb
          - mountPath: /backups
            name: bkp
        dnsPolicy: ClusterFirst
        restartPolicy: OnFailure
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
        volumes:
        - name: hb
          persistentVolumeClaim:
            claimName: homebridge-data-longhorn
        - name: bkp
          persistentVolumeClaim:
            claimName: homebridge-backups-longhorn
  status:
    completionTime: "2025-11-16T16:53:46Z"
    conditions:
    - lastProbeTime: "2025-11-16T16:53:46Z"
      lastTransitionTime: "2025-11-16T16:53:46Z"
      message: Reached expected number of succeeded pods
      reason: CompletionsReached
      status: "True"
      type: SuccessCriteriaMet
    - lastProbeTime: "2025-11-16T16:53:46Z"
      lastTransitionTime: "2025-11-16T16:53:46Z"
      message: Reached expected number of succeeded pods
      reason: CompletionsReached
      status: "True"
      type: Complete
    ready: 0
    startTime: "2025-11-16T16:53:06Z"
    succeeded: 1
    terminating: 0
    uncountedTerminatedPods: {}
- apiVersion: batch/v1
  kind: Job
  metadata:
    annotations:
      batch.kubernetes.io/cronjob-scheduled-timestamp: "2025-12-26T10:00:00Z"
    creationTimestamp: "2025-12-26T10:00:00Z"
    generation: 1
    labels:
      batch.kubernetes.io/controller-uid: 8c14086f-168a-4f6b-9e75-b8c785fa5370
      batch.kubernetes.io/job-name: homebridge-backup-prune-29445720
      controller-uid: 8c14086f-168a-4f6b-9e75-b8c785fa5370
      job-name: homebridge-backup-prune-29445720
    name: homebridge-backup-prune-29445720
    namespace: suite
    ownerReferences:
    - apiVersion: batch/v1
      blockOwnerDeletion: true
      controller: true
      kind: CronJob
      name: homebridge-backup-prune
      uid: 6d995cc4-2a79-4af9-962d-b7cf7e24e6a7
    resourceVersion: "58029942"
    uid: 8c14086f-168a-4f6b-9e75-b8c785fa5370
  spec:
    backoffLimit: 1
    completionMode: NonIndexed
    completions: 1
    manualSelector: false
    parallelism: 1
    podReplacementPolicy: TerminatingOrFailed
    selector:
      matchLabels:
        batch.kubernetes.io/controller-uid: 8c14086f-168a-4f6b-9e75-b8c785fa5370
    suspend: false
    template:
      metadata:
        creationTimestamp: null
        labels:
          batch.kubernetes.io/controller-uid: 8c14086f-168a-4f6b-9e75-b8c785fa5370
          batch.kubernetes.io/job-name: homebridge-backup-prune-29445720
          controller-uid: 8c14086f-168a-4f6b-9e75-b8c785fa5370
          job-name: homebridge-backup-prune-29445720
      spec:
        containers:
        - args:
          - |
            set -eux
            cd /backups

            echo "=== BEFORE ==="
            ls -lh
            df -h .

            echo
            echo "=== Deleting files older than 60 days ==="
            # Adjust the -mtime value if you want a different window
            find . -maxdepth 1 -type f -name 'homebridge*.tgz' -mtime +60 -print -delete || true

            echo
            echo "=== AFTER ==="
            ls -lh
            df -h .
          command:
          - /bin/sh
          - -lc
          image: alpine:3.20
          imagePullPolicy: IfNotPresent
          name: prune
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /backups
            name: bkp
        dnsPolicy: ClusterFirst
        restartPolicy: OnFailure
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
        volumes:
        - name: bkp
          persistentVolumeClaim:
            claimName: homebridge-backups-longhorn
  status:
    active: 1
    ready: 0
    startTime: "2025-12-26T10:00:00Z"
    terminating: 0
    uncountedTerminatedPods: {}
- apiVersion: batch/v1
  kind: Job
  metadata:
    annotations:
      batch.kubernetes.io/cronjob-scheduled-timestamp: "2025-12-27T10:00:00Z"
    creationTimestamp: "2025-12-27T10:00:00Z"
    generation: 1
    labels:
      batch.kubernetes.io/controller-uid: c59f3bb9-4959-4288-a9ea-f0a832a4091c
      batch.kubernetes.io/job-name: homebridge-backup-prune-29447160
      controller-uid: c59f3bb9-4959-4288-a9ea-f0a832a4091c
      job-name: homebridge-backup-prune-29447160
    name: homebridge-backup-prune-29447160
    namespace: suite
    ownerReferences:
    - apiVersion: batch/v1
      blockOwnerDeletion: true
      controller: true
      kind: CronJob
      name: homebridge-backup-prune
      uid: 6d995cc4-2a79-4af9-962d-b7cf7e24e6a7
    resourceVersion: "58567897"
    uid: c59f3bb9-4959-4288-a9ea-f0a832a4091c
  spec:
    backoffLimit: 1
    completionMode: NonIndexed
    completions: 1
    manualSelector: false
    parallelism: 1
    podReplacementPolicy: TerminatingOrFailed
    selector:
      matchLabels:
        batch.kubernetes.io/controller-uid: c59f3bb9-4959-4288-a9ea-f0a832a4091c
    suspend: false
    template:
      metadata:
        creationTimestamp: null
        labels:
          batch.kubernetes.io/controller-uid: c59f3bb9-4959-4288-a9ea-f0a832a4091c
          batch.kubernetes.io/job-name: homebridge-backup-prune-29447160
          controller-uid: c59f3bb9-4959-4288-a9ea-f0a832a4091c
          job-name: homebridge-backup-prune-29447160
      spec:
        containers:
        - args:
          - |
            set -eux
            cd /backups

            echo "=== BEFORE ==="
            ls -lh
            df -h .

            echo
            echo "=== Deleting files older than 60 days ==="
            # Adjust the -mtime value if you want a different window
            find . -maxdepth 1 -type f -name 'homebridge*.tgz' -mtime +60 -print -delete || true

            echo
            echo "=== AFTER ==="
            ls -lh
            df -h .
          command:
          - /bin/sh
          - -lc
          image: alpine:3.20
          imagePullPolicy: IfNotPresent
          name: prune
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /backups
            name: bkp
        dnsPolicy: ClusterFirst
        restartPolicy: OnFailure
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
        volumes:
        - name: bkp
          persistentVolumeClaim:
            claimName: homebridge-backups-longhorn
  status:
    active: 1
    ready: 0
    startTime: "2025-12-27T10:00:00Z"
    terminating: 0
    uncountedTerminatedPods: {}
- apiVersion: batch/v1
  kind: Job
  metadata:
    annotations:
      batch.kubernetes.io/cronjob-scheduled-timestamp: "2025-12-29T10:00:00Z"
    creationTimestamp: "2025-12-29T10:00:00Z"
    generation: 1
    labels:
      batch.kubernetes.io/controller-uid: 7966e16a-444b-440a-87c4-23de8e00a31f
      batch.kubernetes.io/job-name: homebridge-backup-prune-29450040
      controller-uid: 7966e16a-444b-440a-87c4-23de8e00a31f
      job-name: homebridge-backup-prune-29450040
    name: homebridge-backup-prune-29450040
    namespace: suite
    ownerReferences:
    - apiVersion: batch/v1
      blockOwnerDeletion: true
      controller: true
      kind: CronJob
      name: homebridge-backup-prune
      uid: 6d995cc4-2a79-4af9-962d-b7cf7e24e6a7
    resourceVersion: "59813035"
    uid: 7966e16a-444b-440a-87c4-23de8e00a31f
  spec:
    backoffLimit: 1
    completionMode: NonIndexed
    completions: 1
    manualSelector: false
    parallelism: 1
    podReplacementPolicy: TerminatingOrFailed
    selector:
      matchLabels:
        batch.kubernetes.io/controller-uid: 7966e16a-444b-440a-87c4-23de8e00a31f
    suspend: false
    template:
      metadata:
        creationTimestamp: null
        labels:
          batch.kubernetes.io/controller-uid: 7966e16a-444b-440a-87c4-23de8e00a31f
          batch.kubernetes.io/job-name: homebridge-backup-prune-29450040
          controller-uid: 7966e16a-444b-440a-87c4-23de8e00a31f
          job-name: homebridge-backup-prune-29450040
      spec:
        containers:
        - args:
          - |
            set -eux
            cd /backups

            echo "=== BEFORE ==="
            ls -lh
            df -h .

            echo
            echo "=== Deleting files older than 60 days ==="
            # Adjust the -mtime value if you want a different window
            find . -maxdepth 1 -type f -name 'homebridge*.tgz' -mtime +60 -print -delete || true

            echo
            echo "=== AFTER ==="
            ls -lh
            df -h .
          command:
          - /bin/sh
          - -lc
          image: alpine:3.20
          imagePullPolicy: IfNotPresent
          name: prune
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /backups
            name: bkp
        dnsPolicy: ClusterFirst
        restartPolicy: OnFailure
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
        volumes:
        - name: bkp
          persistentVolumeClaim:
            claimName: homebridge-backups-longhorn
  status:
    completionTime: "2025-12-29T10:17:49Z"
    conditions:
    - lastProbeTime: "2025-12-29T10:17:49Z"
      lastTransitionTime: "2025-12-29T10:17:49Z"
      message: Reached expected number of succeeded pods
      reason: CompletionsReached
      status: "True"
      type: SuccessCriteriaMet
    - lastProbeTime: "2025-12-29T10:17:49Z"
      lastTransitionTime: "2025-12-29T10:17:49Z"
      message: Reached expected number of succeeded pods
      reason: CompletionsReached
      status: "True"
      type: Complete
    ready: 0
    startTime: "2025-12-29T10:00:00Z"
    succeeded: 1
    terminating: 0
    uncountedTerminatedPods: {}
- apiVersion: batch/v1
  kind: Job
  metadata:
    annotations:
      batch.kubernetes.io/cronjob-scheduled-timestamp: "2025-12-30T10:00:00Z"
    creationTimestamp: "2025-12-30T10:00:00Z"
    generation: 1
    labels:
      batch.kubernetes.io/controller-uid: 5653478b-9605-42a7-8984-2957c5016b93
      batch.kubernetes.io/job-name: homebridge-backup-prune-29451480
      controller-uid: 5653478b-9605-42a7-8984-2957c5016b93
      job-name: homebridge-backup-prune-29451480
    name: homebridge-backup-prune-29451480
    namespace: suite
    ownerReferences:
    - apiVersion: batch/v1
      blockOwnerDeletion: true
      controller: true
      kind: CronJob
      name: homebridge-backup-prune
      uid: 6d995cc4-2a79-4af9-962d-b7cf7e24e6a7
    resourceVersion: "60449584"
    uid: 5653478b-9605-42a7-8984-2957c5016b93
  spec:
    backoffLimit: 1
    completionMode: NonIndexed
    completions: 1
    manualSelector: false
    parallelism: 1
    podReplacementPolicy: TerminatingOrFailed
    selector:
      matchLabels:
        batch.kubernetes.io/controller-uid: 5653478b-9605-42a7-8984-2957c5016b93
    suspend: false
    template:
      metadata:
        creationTimestamp: null
        labels:
          batch.kubernetes.io/controller-uid: 5653478b-9605-42a7-8984-2957c5016b93
          batch.kubernetes.io/job-name: homebridge-backup-prune-29451480
          controller-uid: 5653478b-9605-42a7-8984-2957c5016b93
          job-name: homebridge-backup-prune-29451480
      spec:
        containers:
        - args:
          - |
            set -eux
            cd /backups

            echo "=== BEFORE ==="
            ls -lh
            df -h .

            echo
            echo "=== Deleting files older than 60 days ==="
            # Adjust the -mtime value if you want a different window
            find . -maxdepth 1 -type f -name 'homebridge*.tgz' -mtime +60 -print -delete || true

            echo
            echo "=== AFTER ==="
            ls -lh
            df -h .
          command:
          - /bin/sh
          - -lc
          image: alpine:3.20
          imagePullPolicy: IfNotPresent
          name: prune
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /backups
            name: bkp
        dnsPolicy: ClusterFirst
        restartPolicy: OnFailure
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
        volumes:
        - name: bkp
          persistentVolumeClaim:
            claimName: homebridge-backups-longhorn
  status:
    completionTime: "2025-12-30T10:00:19Z"
    conditions:
    - lastProbeTime: "2025-12-30T10:00:19Z"
      lastTransitionTime: "2025-12-30T10:00:19Z"
      message: Reached expected number of succeeded pods
      reason: CompletionsReached
      status: "True"
      type: SuccessCriteriaMet
    - lastProbeTime: "2025-12-30T10:00:19Z"
      lastTransitionTime: "2025-12-30T10:00:19Z"
      message: Reached expected number of succeeded pods
      reason: CompletionsReached
      status: "True"
      type: Complete
    ready: 0
    startTime: "2025-12-30T10:00:00Z"
    succeeded: 1
    terminating: 0
    uncountedTerminatedPods: {}
- apiVersion: batch/v1
  kind: Job
  metadata:
    annotations:
      batch.kubernetes.io/cronjob-scheduled-timestamp: "2026-01-01T10:00:00Z"
    creationTimestamp: "2026-01-01T10:00:00Z"
    generation: 1
    labels:
      batch.kubernetes.io/controller-uid: fff3c811-f843-4ce6-921b-910dc6c37555
      batch.kubernetes.io/job-name: homebridge-backup-prune-29454360
      controller-uid: fff3c811-f843-4ce6-921b-910dc6c37555
      job-name: homebridge-backup-prune-29454360
    name: homebridge-backup-prune-29454360
    namespace: suite
    ownerReferences:
    - apiVersion: batch/v1
      blockOwnerDeletion: true
      controller: true
      kind: CronJob
      name: homebridge-backup-prune
      uid: 6d995cc4-2a79-4af9-962d-b7cf7e24e6a7
    resourceVersion: "61728369"
    uid: fff3c811-f843-4ce6-921b-910dc6c37555
  spec:
    backoffLimit: 1
    completionMode: NonIndexed
    completions: 1
    manualSelector: false
    parallelism: 1
    podReplacementPolicy: TerminatingOrFailed
    selector:
      matchLabels:
        batch.kubernetes.io/controller-uid: fff3c811-f843-4ce6-921b-910dc6c37555
    suspend: false
    template:
      metadata:
        creationTimestamp: null
        labels:
          batch.kubernetes.io/controller-uid: fff3c811-f843-4ce6-921b-910dc6c37555
          batch.kubernetes.io/job-name: homebridge-backup-prune-29454360
          controller-uid: fff3c811-f843-4ce6-921b-910dc6c37555
          job-name: homebridge-backup-prune-29454360
      spec:
        containers:
        - args:
          - |
            set -eux
            cd /backups

            echo "=== BEFORE ==="
            ls -lh
            df -h .

            echo
            echo "=== Deleting files older than 60 days ==="
            # Adjust the -mtime value if you want a different window
            find . -maxdepth 1 -type f -name 'homebridge*.tgz' -mtime +60 -print -delete || true

            echo
            echo "=== AFTER ==="
            ls -lh
            df -h .
          command:
          - /bin/sh
          - -lc
          image: alpine:3.20
          imagePullPolicy: IfNotPresent
          name: prune
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /backups
            name: bkp
        dnsPolicy: ClusterFirst
        restartPolicy: OnFailure
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
        volumes:
        - name: bkp
          persistentVolumeClaim:
            claimName: homebridge-backups-longhorn
  status:
    completionTime: "2026-01-01T10:01:36Z"
    conditions:
    - lastProbeTime: "2026-01-01T10:01:36Z"
      lastTransitionTime: "2026-01-01T10:01:36Z"
      message: Reached expected number of succeeded pods
      reason: CompletionsReached
      status: "True"
      type: SuccessCriteriaMet
    - lastProbeTime: "2026-01-01T10:01:36Z"
      lastTransitionTime: "2026-01-01T10:01:36Z"
      message: Reached expected number of succeeded pods
      reason: CompletionsReached
      status: "True"
      type: Complete
    ready: 0
    startTime: "2026-01-01T10:00:00Z"
    succeeded: 1
    terminating: 0
    uncountedTerminatedPods: {}
- apiVersion: batch/v1
  kind: Job
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"batch/v1","kind":"Job","metadata":{"annotations":{},"name":"move-camera-uploader-data","namespace":"suite"},"spec":{"template":{"spec":{"containers":[{"command":["sh","-lc","apk add --no-cache rsync \u0026\u0026 rsync -aHAX --numeric-ids /src/ /dst/"],"image":"alpine:3.20","name":"mover","volumeMounts":[{"mountPath":"/src","name":"src"},{"mountPath":"/dst","name":"dst"}]}],"restartPolicy":"Never","volumes":[{"name":"src","persistentVolumeClaim":{"claimName":"camera-uploader-pvc"}},{"name":"dst","persistentVolumeClaim":{"claimName":"camera-uploader-rwx"}}]}}}}
    creationTimestamp: "2025-09-22T01:36:23Z"
    generation: 1
    labels:
      batch.kubernetes.io/controller-uid: ad82b46e-a870-4af6-956f-46dd153ff9ab
      batch.kubernetes.io/job-name: move-camera-uploader-data
      controller-uid: ad82b46e-a870-4af6-956f-46dd153ff9ab
      job-name: move-camera-uploader-data
    name: move-camera-uploader-data
    namespace: suite
    resourceVersion: "13124275"
    uid: ad82b46e-a870-4af6-956f-46dd153ff9ab
  spec:
    backoffLimit: 6
    completionMode: NonIndexed
    completions: 1
    manualSelector: false
    parallelism: 1
    podReplacementPolicy: TerminatingOrFailed
    selector:
      matchLabels:
        batch.kubernetes.io/controller-uid: ad82b46e-a870-4af6-956f-46dd153ff9ab
    suspend: false
    template:
      metadata:
        creationTimestamp: null
        labels:
          batch.kubernetes.io/controller-uid: ad82b46e-a870-4af6-956f-46dd153ff9ab
          batch.kubernetes.io/job-name: move-camera-uploader-data
          controller-uid: ad82b46e-a870-4af6-956f-46dd153ff9ab
          job-name: move-camera-uploader-data
      spec:
        containers:
        - command:
          - sh
          - -lc
          - apk add --no-cache rsync && rsync -aHAX --numeric-ids /src/ /dst/
          image: alpine:3.20
          imagePullPolicy: IfNotPresent
          name: mover
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /src
            name: src
          - mountPath: /dst
            name: dst
        dnsPolicy: ClusterFirst
        restartPolicy: Never
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
        volumes:
        - name: src
          persistentVolumeClaim:
            claimName: camera-uploader-pvc
        - name: dst
          persistentVolumeClaim:
            claimName: camera-uploader-rwx
  status:
    completionTime: "2025-09-27T22:44:59Z"
    conditions:
    - lastProbeTime: "2025-09-27T22:02:39Z"
      lastTransitionTime: "2025-09-27T22:02:39Z"
      message: Reached expected number of succeeded pods
      reason: CompletionsReached
      status: "True"
      type: SuccessCriteriaMet
    - lastProbeTime: "2025-09-27T22:44:59Z"
      lastTransitionTime: "2025-09-27T22:44:59Z"
      message: Reached expected number of succeeded pods
      reason: CompletionsReached
      status: "True"
      type: Complete
    failed: 3
    ready: 0
    startTime: "2025-09-22T01:36:23Z"
    succeeded: 1
    terminating: 0
    uncountedTerminatedPods: {}
kind: List
metadata:
  resourceVersion: ""
